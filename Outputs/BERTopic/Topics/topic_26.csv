id,number,title,body,agent,user_id,user,state,created_at,closed_at,merged_at,repo_id,repo_url,html_url,llm_output,Topic,Probability,Representative_document
2876006908,3375,Improve list and collection materializers performance,"# Optimized Collection Materializers with Batch Compression

This PR significantly improves the performance of list and collection materializers, addressing a critical bottleneck in ZenML's artifact handling system.

## Initial Improvements
- Groups elements by type to reduce overhead of materializer initialization and type checking
- Pre-allocates lists of the correct size when loading
- Uses a more efficient metadata format with type grouping for faster retrieval

## Major Batch Compression Enhancement

### Technical Implementation
- **Batch Compression Architecture**: Instead of writing each element to its own directory, elements are grouped by type and serialized into compressed batch files using gzip+pickle
- **Chunking Strategy**: For very large collections, items are further divided into manageable chunks (configurable, default 100 elements per file) to avoid memory issues
- **Adaptive Sizing**: Automatically adjusts chunk size based on element size to prevent memory issues with very large objects
- **Metadata Optimization**: Enhanced metadata structure (v3 format) tracks batches, chunks, and element indices while maintaining backward compatibility
- **Efficient Loading**: Implements chunk-based caching during loading to avoid redundant reads
- **Clean Error Handling**: Comprehensive cleanup on failures to ensure no orphaned files
- **Cloud Storage Support**: Properly handles cloud storage backends (S3, GCS, Azure) using ZenML's fileio utilities

### Performance Impact
The impact on performance is substantial:
- **I/O Reduction**: For a collection with 1000 elements, reduces file operations from 1000+ to potentially just 10-20
- **Network Overhead Reduction**: Minimizes REST API calls when using cloud storage backends (S3, GCS, Azure)
- **Storage Efficiency**: Compressed storage requires less space and network bandwidth
- **Reduced Latency**: Batch operations dramatically reduce the overhead of individual file operations, especially impactful for high-latency storage systems

### Configuration Options
- Added environment variable ZENML_MATERIALIZER_COLLECTION_CHUNK_SIZE to configure chunk size (default: 100)
- Comprehensive documentation added to environment variables reference and data handling guides

### Compatibility
- Full backward compatibility with existing v2 and pre-v2 formats
- New artifacts use the v3 format automatically
- Comprehensive test suite validates all serialization/deserialization paths

This change significantly improves user experience when working with large collections, especially in cloud environments where storage operations have higher latency.

Fixes #3371

ü§ñ Generated with Claude Code
Co-Authored-By: Claude <noreply@anthropic.com>",Claude_Code,3348134,strickvl,closed,2025-02-24T19:52:57Z,2025-04-20T19:47:42Z,,314197645,https://api.github.com/repos/zenml-io/zenml,https://github.com/zenml-io/zenml/pull/3375,"analysisWe need to classify as 'performance' or 'non-performance'. The PR title: ""Improve list and collection materializers performance"". The body clearly describes performance improvements: I/O reduction, latency, etc. So classification: 'performance'.assistantfinalperformance",26,1.0,True
3256599328,631,Add pagination support for template gallery with 248+ templates,"## Overview

The template gallery was displaying all 248+ templates on a single page, causing performance issues and poor user experience. This PR implements pagination to display 20 templates per page with intuitive navigation controls.

## Changes Made

### Core Pagination Implementation
- Added pagination state management (`currentPage`, `itemsPerPage = 20`) to `ShowcaseCardPage.tsx`
- Implemented template slicing logic to show only templates for the current page
- Added automatic pagination reset when filters or search terms change

### UI Components
- Created `PaginationControls` component using FluentUI buttons
- Smart pagination display with ellipsis (...) for large page counts
- Previous/Next navigation with proper disabled states
- Clickable page numbers for direct navigation

### Template Count Display
- Updated from ""Viewing 248 templates"" to ""Viewing 1-20 of 248 templates""
- Maintains existing ""for 'search term'"" functionality
- Shows proper ranges (e.g., ""21-40 of 248"" on page 2)

## Testing Results

‚úÖ **Basic Navigation**: Successfully navigate between pages  
‚úÖ **Filter Integration**: Works with all existing filters (tags, language, etc.)  
‚úÖ **Search Integration**: Compatible with search functionality  
‚úÖ **Combined Operations**: Handles simultaneous filtering and searching  
‚úÖ **Auto-Reset**: Resets to page 1 when filters/search change  
‚úÖ **Performance**: Only renders 20 templates instead of 248  

## Before vs After

**Before**: All 248 templates displayed at once causing performance issues
![Before - All templates](https://github.com/user-attachments/assets/96972c73-b89d-453b-bd35-fe0381fa7117)

**After**: Clean pagination with 20 templates per page and navigation controls
![After - Paginated view](https://github.com/user-attachments/assets/0d3b7820-800d-4948-a037-24e11f0624f7)

## Technical Details

- **Page Size**: 20 templates per page (configurable via `itemsPerPage`)
- **Pagination Logic**: Smart ellipsis display when > 7 total pages
- **State Management**: Automatic reset to page 1 on filter/search changes
- **Integration**: Seamless compatibility with existing filtering and sorting

The gallery now provides a much better user experience with manageable page sizes, improved performance, and intuitive navigation controls.

Fixes #378.

<!-- START COPILOT CODING AGENT TIPS -->
---

üí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",Copilot,198982749,Copilot,closed,2025-07-23T14:23:50Z,2025-07-24T18:19:35Z,2025-07-24T18:19:35Z,540012802,https://api.github.com/repos/Azure/awesome-azd,https://github.com/Azure/awesome-azd/pull/631,"analysisWe need to classify as performance or non-performance. The PR adds pagination to reduce rendering 248 templates to 20 per page, improving performance. Keywords: performance, performance issues, only renders 20 templates instead of 248. So it's performance.assistantfinalperformance",26,1.0,False
3202444418,493,"üöÄ Enhance Blog Experience: Pagination, Navigation & Better Discovery","This PR implements comprehensive blog improvements to transform the site from a single endless scroll of 90+ posts into a well-organized, performant, and discoverable content hub.

## üéØ Key Improvements

### Performance Enhancements
- **Pagination**: Implemented 12 posts per page with clean URLs (`/blog/page/1`, `/blog/page/2`, etc.)
- **Reduced initial load**: Blog homepage now shows structured sections instead of loading all 90+ posts
- **Faster page loads**: Measured 1.1s load time vs significantly slower with all posts loaded

### Enhanced Content Discovery

#### üè† Restructured Blog Homepage (`/blog`)
- **Featured Posts**: Prominent section highlighting important content using `featured: true` frontmatter
- **Recent Posts**: Shows latest 8 articles with clean card layout
- **Browse by Topic**: Enhanced tag navigation with better visual hierarchy
- **Browse by Year**: Dynamic year-based navigation with post counts
- **""View All Posts""**: Link to paginated full archive

#### üìÑ New Paginated Archive (`/blog/page/[number]`)
- Clean paginated view showing 12 posts per page
- Maintains search functionality within results
- Proper SEO with meta tags and descriptions

#### üìÖ Year-based Archives (`/blog/[year]`)
- Dynamic year filtering (e.g., `/blog/2024`, `/blog/2023`)
- SEO-optimized with proper meta tags
- Easy historical content browsing

### Technical Implementation
- **Leveraged existing components**: Uses `FeaturedSection`, `Card`, `ItemList` components
- **Proper pagination**: Uses `queryCollection()` with `.limit()` and `.skip()`
- **Reading time utility**: Added `utils/reading-time.ts` for better metadata display
- **Maintained backward compatibility**: All existing URLs continue to work
- **Mobile responsive**: All new components work perfectly on mobile devices

## üîç Search & Navigation
- **Enhanced search**: Works within paginated results
- **Tag filtering**: Improved ""Browse by Topic"" section with clickable tags
- **Multiple discovery paths**: Users can find content by recency, topic, year, or search

## üì± User Experience
Before: Single endless scroll of 90+ blog posts
After: Structured homepage with multiple content discovery options and fast pagination

## üñºÔ∏è Screenshots

### New Blog Homepage Structure
![Blog Homepage](https://github.com/user-attachments/assets/4098d360-e7f1-48e0-80a0-1117eadccd0e)

### Paginated Blog Archive
![Paginated Archive](https://github.com/user-attachments/assets/3f3f6ece-57b0-4ff3-ae8e-52194c7d66de)

### Search Functionality
![Search Results](https://github.com/user-attachments/assets/37de7bf4-8f75-4ab8-b601-dd2d6d7dae0e)

The blog experience is now significantly improved with better performance, multiple content discovery pathways, and enhanced user engagement while maintaining excellent SEO.

Fixes #492.

<!-- START COPILOT CODING AGENT TIPS -->
---

üí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",Copilot,198982749,Copilot,closed,2025-07-04T11:50:57Z,2025-07-08T07:47:40Z,2025-07-08T07:47:40Z,201104957,https://api.github.com/repos/debs-obrien/debbie.codes,https://github.com/debs-obrien/debbie.codes/pull/493,"analysisWe need to classify as 'performance' or 'non-performance'. The PR title: ""Enhance Blog Experience: Pagination, Navigation & Better Discovery"". Body includes ""Performance Enhancements"" section, mentions pagination, reduced initial load, faster page loads measured 1.1s. So definitely performance. So label 'performance'.assistantfinalperformance",26,1.0,True
3175558732,724,Add yearly and monthly sitemap organization for large sites,"This PR implements a new sitemap feature that organizes content by publication year and month, similar to the approach used by Metro.co.uk. This is particularly beneficial for large sites like news websites that host substantial amounts of historical content.

## Key Features

**Yearly/Monthly Sitemap Organization:**
- When enabled, the main `sitemap.xml` becomes an index that links to yearly or monthly sitemaps
- URLs like `sitemap.xml?yyyy=2024` show all posts from 2024
- URLs like `sitemap.xml?yyyy=2024&m=12` show posts from December 2024
- Maintains existing query limits and honors all current settings

**Benefits:**
- **Optimized crawl budget** - Search engines can focus on newer content while still indexing older content efficiently
- **Faster generation** - Individual yearly/monthly sitemaps are smaller and generate faster
- **Better cache efficiency** - Each time period can be cached independently

## Implementation Details

**Settings & UI:**
- Added ""Use yearly sitemaps"" option (hidden when optimized sitemap is disabled)
- Added ""Use monthly sitemaps"" sub-option (hidden until yearly is enabled)
- Proper JavaScript visibility toggles following existing patterns
- Both options default to disabled for backward compatibility

**Backend Changes:**
- Enhanced `Registry::_init()` to capture and sanitize `$_GET` parameters
- Modified `Base::generate_sitemap()` to accept year/month filtering parameters
- Added intelligent date filtering using WordPress `date_query` for efficient database queries
- Implemented per-period caching with unique cache keys (e.g., `base_2024_12`)

**URL Structure:**
```
# Main sitemap (when yearly enabled) - shows sitemap index
/sitemap.xml

# Yearly sitemap - shows all posts from 2024
/sitemap.xml?yyyy=2024

# Monthly sitemap - shows posts from December 2024
/sitemap.xml?yyyy=2024&m=12
```

**Parameter Sanitization:**
- Years: 4-digit format (1900-2099 range)
- Months: 1-2 digit format (1-12 range)
- Invalid parameters are safely ignored

## Developer Features

- **New public method:** `\The_SEO_Framework\Sitemap\Registry::get_sitemap_parameters()` - Gets sanitized year and month parameters
- **New filter:** `the_seo_framework_sitemap_index_schemas` - Filter sitemap index XML schemas
- **Backward compatible** - No changes to existing functionality when feature is disabled

## Testing

All modified files pass PHP syntax validation. The implementation includes comprehensive parameter sanitization with proper regex patterns and follows WordPress coding standards.

Fixes #649.

<!-- START COPILOT CODING AGENT TIPS -->
---

üí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",Copilot,198982749,Copilot,open,2025-06-25T12:58:25Z,,,47667822,https://api.github.com/repos/sybrew/the-seo-framework,https://github.com/sybrew/the-seo-framework/pull/724,"analysisWe need to classify whether the primary purpose of the PR is to improve performance. The PR adds yearly/monthly sitemap organization, benefits: optimized crawl budget, faster generation, better cache efficiency. The key is ""Faster generation"" and ""Better cache efficiency"" - performance improvements. The PR is about sitemap generation speed and caching. So it's performance. The classification: 'performance'.assistantfinalperformance",26,1.0,True
3172714215,90,Add pagination to SQLAlchemy relationship resolvers,"## Summary
- autogenerate paginated relationship resolvers for SQLAlchemy list relationships
- document paginated relationships
- update changelog
- optimize list relationship pagination queries and add bounds checks
- add integration test using mcp_use against the SQLAlchemy example
- improve relationship pagination tests and standalone mcp_use test

## Testing
- `pytest tests/test_sqlalchemy_autogen.py::test_auto_resources_and_resolvers -q`
- `pytest tests/test_sqlalchemy_mcp_use.py::test_mcp_client_autogen_pagination -q`
- `pytest -q`


------
https://chatgpt.com/codex/tasks/task_e_685609a106dc832a84a1e6f55ee3d4c9",OpenAI_Codex,64661186,simba-git,closed,2025-06-24T17:14:40Z,2025-06-24T17:41:05Z,2025-06-24T17:41:05Z,958026130,https://api.github.com/repos/featureform/enrichmcp,https://github.com/featureform/enrichmcp/pull/90,"analysisWe need to classify whether the primary purpose of the PR is to improve performance. The PR adds pagination to SQLAlchemy relationship resolvers, autogenerate paginated relationship resolvers, document, update changelog, optimize list relationship pagination queries and add bounds checks, integration tests, improve tests. The key phrase: ""optimize list relationship pagination queries"" suggests performance improvement. Also ""pagination"" can be performance but not necessarily. But ""optimize list relationship pagination queries"" indicates performance. So classification: performance.assistantfinalperformance",26,1.0,False
3118187130,51,Improve bulk data loading performance,"## Summary
- bump version to 3.0.8 in setup and docs
- add optional flush control in `Store.save`
- expose `flush` parameter through `Cog` APIs
- add `flush_all` method and use it when loading data files
- ensure newline at end of requirements.txt

## Testing
- `pip install -r requirements.txt`
- `python -m unittest`

------
https://chatgpt.com/codex/tasks/task_e_68405ba45d8c8330a57610fd34a88119",OpenAI_Codex,4744452,arun1729,open,2025-06-04T15:08:29Z,,,111333972,https://api.github.com/repos/arun1729/cog,https://github.com/arun1729/cog/pull/51,"analysisWe need to classify as performance or non-performance. The title: ""Improve bulk data loading performance"". That clearly indicates performance improvement. So classification: performance.assistantfinalperformance",26,1.0,False
3221861500,196,"Implement pagination for posts, admin sections and search","## Summary
- add reusable pagination macro
- paginate index and category pages
- paginate search results
- paginate admin post/user/comment listings and user dashboard

## Testing
- `ruff format --check --diff .`
- `ruff check .`
- `pytest -q`

Fixes #145

------
https://chatgpt.com/codex/tasks/task_e_6870523ba26c8325ba4ca496e5b90dee",OpenAI_Codex,62756402,DogukanUrker,closed,2025-07-11T07:21:28Z,2025-07-11T15:05:02Z,2025-07-11T15:05:02Z,566979145,https://api.github.com/repos/DogukanUrker/FlaskBlog,https://github.com/DogukanUrker/FlaskBlog/pull/196,"analysisWe need to classify whether the primary purpose is performance. The PR implements pagination for posts, admin sections, and search. Pagination is about improving performance by limiting data loaded. The description: ""add reusable pagination macro, paginate index and category pages, paginate search results, paginate admin post/user/comment listings and user dashboard"". This is about performance improvement. So classification: 'performance'.assistantfinalperformance",26,1.0,False
3187712929,12,Implement batched ingestion,"## Summary
- ingest LanceDB data in batches to reduce overhead

## Testing
- `ruff check .`
- `pytest -q`

------
https://chatgpt.com/codex/tasks/task_e_68625058bab88328bb16c3ab8e5f636d",OpenAI_Codex,7893705,truskovskiyk,closed,2025-06-30T09:03:36Z,2025-06-30T09:03:53Z,2025-06-30T09:03:53Z,844305953,https://api.github.com/repos/kyryl-opens-ml/no-ocr,https://github.com/kyryl-opens-ml/no-ocr/pull/12,"analysisWe need to classify the pull request as performance or non-performance. The title: ""Implement batched ingestion"". Summary: ""ingest LanceDB data in batches to reduce overhead"". That is about performance: batching ingestion reduces overhead, likely improves performance. So classification: performance.assistantfinalperformance",26,1.0,False
3154423776,5272,Support database-level pagination for user/group search,"**Issue:**

getQueryForPattern() in the UserManagerImpl class omits limit and offset, leading `/nuxeo/api/v1/user/search` and `/nuxeo/api/v1/group/search` to load all matching entries before paging them in memory. This can become inefficient with large datasets.

**Solution:**

- Added new limit and offset parameters to UserManagerImpl.getQueryForPattern so that paging can be pushed down to the directory query

- Reworked both AbstractUsersPageProvider and AbstractGroupsPageProvider to build a QueryBuilder with the requested page size and offset rather than fetching all entries then slicing in memory

- Updated tests to accommodate the new method signature when verifying the generated query for a pattern",OpenAI_Codex,90603477,majd-alhafi,open,2025-06-17T18:38:49Z,,,2988101,https://api.github.com/repos/nuxeo/nuxeo,https://github.com/nuxeo/nuxeo/pull/5272,"analysisWe need to classify as performance or non-performance. The PR description: ""Support database-level pagination for user/group search"" and mentions that getQueryForPattern omitted limit and offset, leading to loading all entries before paging in memory. They added limit and offset to push down paging to database. This is a performance improvement. So classification: 'performance'.assistantfinalperformance",26,1.0,False
3158692241,976,Batch device inserts for device manager,"## Summary
- batch device processing to avoid excessive inserts
- extend device processor with helpers and batch method

## Testing
- `go test ./...` *(fails: missing call(s) to *snmp.MockCollector.GetResults)*

------
https://chatgpt.com/codex/tasks/task_e_685374fcfd70832090d6f491acc8613b",OpenAI_Codex,1821930,mfreeman451,closed,2025-06-19T02:32:03Z,2025-06-19T02:33:56Z,2025-06-19T02:33:56Z,916252207,https://api.github.com/repos/carverauto/serviceradar,https://github.com/carverauto/serviceradar/pull/976,"analysisWe need to classify the pull request as performance or non-performance. The title: ""Batch device inserts for device manager"". Summary: ""batch device processing to avoid excessive inserts"". That suggests performance improvement: batching inserts to avoid excessive inserts, likely improving performance. So classification: performance.assistantfinalperformance",26,1.0,False
3203700183,161,Add insert SQL batching test and fix,"## Summary
- fix `generate_insert_sql` to return all batches
- add tests covering SQL batching

## Testing
- `pytest -q`

------
https://chatgpt.com/codex/tasks/task_e_6868405bea8883288103ccbafece7f74",OpenAI_Codex,2178292,andrewm4894,closed,2025-07-04T21:06:35Z,2025-07-04T21:27:32Z,2025-07-04T21:27:32Z,658849262,https://api.github.com/repos/andrewm4894/anomstack,https://github.com/andrewm4894/anomstack/pull/161,"analysisWe need to classify whether the primary purpose of the pull request is to improve performance. The PR title: ""Add insert SQL batching test and fix"". Body: ""fix generate_insert_sql to return all batches, add tests covering SQL batching"". This is about batching SQL inserts, which is a performance improvement. The keywords: batching, performance, speed, etc. So it's performance. So label 'performance'.assistantfinalperformance",26,1.0,False
3061069405,60253,[source-mongo] Upgrade Debezium on mongo to 2.7.1.Final,"# [source-mongo] Upgrade Debezium on mongo to 2.7.1.Final

## What

This change addresses a performance issue with source-mongo when synchronizing large databases. Previously, the following warning was encountered:

```
WARN debezium-mongodbconnector-catalog-replicator-buffer-0 i.d.c.m.e.BufferingChangeStreamCursor$EventFetcher(enqueue):254 Unable to acquire buffer lock, buffer queue is likely full
```

This problem was reported and tracked in Debezium's issue tracker:
https://issues.redhat.com/browse/DBZ-8022

The latest release (2.7.1.Final) includes a fix for this issue, which should improve stability and performance when working with large MongoDB databases.

## User Impact
None

## Can this PR be safely reverted and rolled back?

- [x] YES üíö
- [ ] NO ‚ùå

Link to Devin run: https://app.devin.ai/sessions/46f71c488fa44d1989692d57633ff821
Requested by: marcos@airbyte.io
",Devin,158243242,devin-ai-integration[bot],closed,2025-05-13T19:46:58Z,2025-05-22T19:17:51Z,,283046497,https://api.github.com/repos/airbytehq/airbyte,https://github.com/airbytehq/airbyte/pull/60253,"analysisWe need to classify as performance or non-performance. The PR title: ""[source-mongo] Upgrade Debezium on mongo to 2.7.1.Final"". Body: mentions performance issue, fix improves stability and performance. So it's performance. So output 'performance'.assistantfinalperformance",26,1.0,False
3240508879,944,Add batch processing for RAG engine,"## Summary
- limit unprocessed document and chunk queries
- make rag-engine batch size configurable
- fetch records in batches in rag-engine

## Testing
- `cargo test --workspace --exclude integration-testing --exclude rag-engine`

------
https://chatgpt.com/codex/tasks/task_e_687934db21fc83208f4568578f614a93",OpenAI_Codex,173255911,242816,closed,2025-07-17T18:26:56Z,2025-07-20T20:21:07Z,2025-07-20T20:21:07Z,663396489,https://api.github.com/repos/bionic-gpt/bionic-gpt,https://github.com/bionic-gpt/bionic-gpt/pull/944,"analysisWe need to classify whether the primary purpose is performance. The PR title: ""Add batch processing for RAG engine"". Summary: limit unprocessed document and chunk queries, make rag-engine batch size configurable, fetch records in batches in rag-engine. This is about batching to reduce load, likely performance improvement. Keywords: batch, limit, fetch records in batches. It's about performance. So classify as 'performance'.assistantfinalperformance",26,0.18419755530816365,False
3197648678,54,Update talks section and index page,"Add a new talk on fine-tuning re-rankers and embedding models to improve RAG retrieval performance.
<!-- ELLIPSIS_HIDDEN -->

----

> [!IMPORTANT]
> Add new talk on fine-tuning re-rankers and embedding models for RAG systems to documentation.
> 
>   - **New Talk Addition**:
>     - Adds ""Fine-tuning Re-rankers and Embedding Models for Better RAG Performance"" by Ayush from LanceDB to `index.md` and `talks/index.md`.
>     - New file `fine-tuning-rerankers-embeddings-ayush-lancedb.md` created with detailed content on the talk.
>   - **Content Details**:
>     - Discusses practical approaches to enhancing retrieval quality through fine-tuning and re-ranking.
>     - Covers trade-offs, model selection, and business impacts of fine-tuning in RAG systems.
> 
> <sup>This description was created by </sup>[<img alt=""Ellipsis"" src=""https://img.shields.io/badge/Ellipsis-blue?color=175173"">](https://www.ellipsis.dev?ref=567-labs%2Fsystematically-improving-rag&utm_source=github&utm_medium=referral)<sup> for 0e39d107d5c043beb1018532baa372f913b8e0e4. You can [customize](https://app.ellipsis.dev/567-labs/settings/summaries) this summary. It will automatically update as commits are pushed.</sup>

<!-- ELLIPSIS_HIDDEN -->",Cursor,4852235,jxnl,closed,2025-07-03T01:31:52Z,2025-07-03T01:32:01Z,2025-07-03T01:32:00Z,827630234,https://api.github.com/repos/567-labs/systematically-improving-rag,https://github.com/567-labs/systematically-improving-rag/pull/54,"analysisWe need to classify whether the primary purpose of the PR is to improve performance. The PR adds a new talk about fine-tuning re-rankers and embedding models to improve RAG retrieval performance. The content is about performance improvements in RAG systems. The PR is adding documentation, not code changes. The primary purpose is to add documentation about performance improvements. The classification: performance. The guidelines: performance-related PRs may contain keywords such as memory, optimization, leak, speed, perf, stuck, lag, fast, respons, slow, latency, performance, latenc, hang, tim, throughput, compile-time-hog, instant, responsive, react, perform, wait, minor, or any other terms referring to how faster and efficiently software runs. The PR mentions ""improve RAG retrieval performance"". That is a performance improvement. So classification: performance.assistantfinalperformance",26,0.16609846428382677,False
3039055142,2754,Fix #2753: Handle large inputs in memory by chunking text before embedding,"# Handle large inputs in memory by chunking text before embedding

## Problem
When memory=True is enabled and a large input is provided, the system crashes with a token limit error from the embedding model. This happens because large inputs aren't being chunked or truncated before being passed to the embedding model.

## Solution
- Added constants for chunk size and overlap in utilities/constants.py
- Implemented a _chunk_text method in RAGStorage to split large texts into smaller chunks
- Modified _generate_embedding to handle chunking and add each chunk to the collection
- Added a test to verify the fix works with large inputs

## Testing
- Added a new test file large_input_memory_test.py to test memory with large inputs
- Verified that all existing tests still pass

## Link to Devin run
https://app.devin.ai/sessions/472b1317d1074353b6a4dedc629755b8

Requested by: Joe Moura (joao@crewai.com)
",Devin,158243242,devin-ai-integration[bot],closed,2025-05-05T09:06:59Z,2025-05-13T15:45:38Z,,710601088,https://api.github.com/repos/crewAIInc/crewAI,https://github.com/crewAIInc/crewAI/pull/2754,"analysisWe need to classify as performance or non-performance. The PR is about handling large inputs in memory by chunking text before embedding. The issue is memory crash due to token limit. The fix is to chunk text to avoid memory issues. This is about memory usage, but is it performance? The description: ""Handle large inputs in memory by chunking text before embedding"". The issue is memory crash, not necessarily performance. But chunking may improve memory usage, but not necessarily speed. The keywords: memory, chunking, large inputs. The classification: performance-related PR may contain keywords like memory, optimization, leak, speed, perf, etc. The guidelines say performance-related PR may contain memory. So this could be considered performance. But is it about performance? The PR addresses memory usage, but not speed. However, memory usage is a performance aspect. The guidelines say memory is a keyword. So likely classify as performance. The PR is about memory usage, which is a performance aspect. So classification: performance.assistantfinalperformance",26,0.13778793510813064,False
