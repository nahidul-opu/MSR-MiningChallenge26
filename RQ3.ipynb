{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb475010",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modules.utilities import *\n",
    "from modules.constants import *\n",
    "from modules import CliffsDelta\n",
    "from scipy.stats import shapiro\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "plt.rcParams.update(mpl_params)\n",
    "pio.templates.default = \"custom_matplotlib_like\"\n",
    "\n",
    "TOPIC_DIR = \"./Outputs/BERTopic/Topics\"\n",
    "DATA_DIR = \"./Outputs/PerformancePRs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4579b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_df = read_aidev(FileName.POP_PR_TASK_TYPE)\n",
    "perf_df = pd.read_csv(os.path.join(DATA_DIR, \"POP_PULL_Requests_LLM_filtered_final.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1638509a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "body",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "agent",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "closed_at",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "merged_at",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "repo_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "repo_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "html_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "479685d2-7326-47f7-befb-cedd4e1c2ff0",
       "rows": [
        [
         "0",
         "3164503419",
         "40",
         "Fix Claude animation flickering with vt10x-inspired terminal state deduplication",
         "## üéØ Problem: Claude's Thinking Animation Causes Terminal Flickering\n\nWhen using Claude in the terminal, rapid escape sequences during the \"thinking\" animation cause visual chaos:\n- Cursor jumps left-right-left-right üîÑ\n- Bottom lines flicker aggressively ‚ö°\n- Text appears and disappears creating a strobe effect üì∫\n- Makes Claude unusable in terminal environments üòµ\n\nThe root cause: Claude sends `\\x1b[2K\\x1b[1A` (clear line + cursor up) sequences **every 20ms**, overwhelming the terminal with 193 redundant updates!\n\n## üß† Solution: Learn from the Masters - vt10x Terminal Emulation\n\nInstead of fighting Claude's animation, we studied how professional terminal emulators handle rapid updates. The **vt10x library** revealed the secret sauce:\n\n### üî¨ **The Science Behind Smooth Terminals**\n```go\n// Before: Naive approach - send every update\nptyOutput ‚Üí terminalBuffer ‚Üí websocket (193 updates! üî•)\n\n// After: vt10x-inspired state deduplication  \nptyOutput ‚Üí dirtyTracking ‚Üí changeFlags ‚Üí sequenceID ‚Üí debounce ‚Üí websocket (53 updates ‚ú®)\n```\n\n## üöÄ **Performance Revolution**\n\n| Metric | Before | After | Improvement |\n|--------|--------|-------|-------------|\n| WebSocket updates | 193 | 53 | **72% reduction** |\n| Animation smoothness | Flickering mess | Buttery smooth | **Visual perfection** |\n| CPU overhead | High churn | Optimized | **Efficient processing** |\n| Terminal compatibility | Broken | Perfect | **Zero regressions** |\n\n## üõ† **Technical Wizardry**\n\n### **1. Dirty Line Tracking (vt10x-style)**\n```go\ndirty []bool  // Track exactly which lines changed\nanydirty bool // Quick dirty check without scanning\n```\n\n### **2. Change Flag System**\n```go\nconst (\n    ChangedScreen uint32 = 1 << iota  // Content changed\n    ChangedCursor                     // Cursor moved  \n    ChangedTitle                      // Title updated\n    ChangedSize                       // Terminal resized\n)\n```\n\n### **3. Sequence-Based Deduplication** \n```go\nsequenceID uint64  // Monotonic counter\n// If sequenceID matches ‚Üí identical state ‚Üí skip update!\n```\n\n### **4. Smart Debouncing (Node.js-inspired)**\n```go\n// Simple 50ms timer - let rapid updates settle\ntime.AfterFunc(50*time.Millisecond, sendFinalState)\n```\n\n## üéÆ **The Node.js Secret Weapon**\n\nWe discovered the working Node.js version uses **XTerm.js** which has built-in sophisticated state management. Our Go implementation now matches this approach:\n\n```typescript\n// Node.js: XTerm.js handles complexity internally\nptyData ‚Üí xterm.headless ‚Üí 50ms debounce ‚Üí websocket\n\n// Go: We replicated the internal magic  \nptyData ‚Üí vt10x-style-buffer ‚Üí 50ms debounce ‚Üí websocket\n```\n\n## üîß **What Changed**\n\n### **Core Files Transformed:**\n- **`terminal/buffer.go`**: Added vt10x dirty tracking + change flags\n- **`termsocket/manager.go`**: Simplified to Node.js-style debouncing  \n- **`api/raw_websocket.go`**: NEW goterm-style direct PTY streaming\n- **`session/manager.go`**: Direct PTY callbacks bypass file I/O\n\n### **Performance Optimizations:**\n- **Incremental updates**: Only send changed lines, not entire screen\n- **State caching**: Reuse identical snapshots via sequence comparison\n- **Memory efficiency**: Reuse buffers instead of allocating new ones\n- **Event-driven I/O**: 1ms epoll/kqueue timeouts for instant response\n\n## üß™ **Battle-Tested Results**\n\n```bash\n# Before: Flickering nightmare\n$ claude\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ  ‚Üê Flickers every 20ms\n‚îÇ >               ‚îÇ  ‚Üê Cursor jumps around  \n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ  ‚Üê Text strobes on/off\n\n# After: Smooth as silk  \n$ claude\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ  ‚Üê Stable animation\n‚îÇ > thinking...   ‚îÇ  ‚Üê Smooth cursor\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ  ‚Üê No flicker artifacts\n```\n\n## üéØ **Test Plan**\n\n- [x] **Build success**: All Go packages compile cleanly\n- [x] **WebSocket monitoring**: Confirmed 72% update reduction  \n- [x] **State deduplication**: Sequence IDs prevent duplicates\n- [x] **Terminal compatibility**: All escape sequences work perfectly\n- [ ] **Side-by-side comparison**: Go vs Node.js visual parity\n- [ ] **Application testing**: nano, vim, htop, claude all smooth\n\n## üèÜ **The Bottom Line**\n\nThis isn't just a bug fix - it's a **terminal performance revolution**! By applying lessons from professional terminal emulators like vt10x, we've transformed a flickering mess into a buttery-smooth experience that rivals the best terminal applications.\n\n**Claude's thinking animation now works beautifully in the terminal! üéâ**\n\n---\n*ü§ñ Engineered with precision by [Claude Code](https://claude.ai/code)*\n\n*Co-Authored-By: Claude <noreply@anthropic.com>*",
         "Claude_Code",
         "2891702",
         "hjanuschka",
         "closed",
         "2025-06-20T22:47:18Z",
         "2025-06-21T11:51:22Z",
         null,
         "1002552148",
         "https://api.github.com/repos/amantus-ai/vibetunnel",
         "https://github.com/amantus-ai/vibetunnel/pull/40",
         "fix"
        ],
        [
         "1",
         "3273233066",
         "1037",
         "feat: implement comprehensive species tracking system with seasonal/yearly detection badges",
         "## Summary\nThis PR implements a comprehensive species tracking system that displays visual badges on the DailySummaryCard to indicate when species are new, new this year, or new this season. The implementation includes proper database queries, caching, and UI enhancements.\n\n## Key Features\n\n### üè∑Ô∏è Species Tracking Badges\n- **‚≠ê Star Icon**: Species detected for the first time ever (lifetime new)\n- **üìÖ Calendar Icon**: Species detected for the first time this year \n- **üçÉ Leaf Icon**: Species detected for the first time this season\n- Each badge type has configurable time windows (default: 14 days lifetime, 30 days yearly, 21 days seasonal)\n\n### üóÑÔ∏è Database Enhancements\n- **New Method**: `GetSpeciesFirstDetectionInPeriod()` - retrieves first detection of each species within a date range\n- **Improved Queries**: Separate queries for lifetime vs. seasonal/yearly tracking for better accuracy\n- **Better Performance**: Optimized database queries with proper indexing\n\n### üìä API Improvements  \n- **Enhanced Analytics**: `/api/v2/analytics/species/daily` now includes tracking status fields\n- **Date-based Status**: Species status computed relative to selected date, not current date\n- **Comprehensive Response**: Added `is_new_species`, `is_new_this_year`, `is_new_this_season` fields\n\n### üé® Frontend Updates\n- **Animated Icons**: Smooth CSS animations for badge appearance/disappearance  \n- **Smart Display**: Badges only shown when species qualify for \"new\" status\n- **Responsive Design**: Icons adapt to different screen sizes\n- **Accessibility**: Proper tooltips and semantic markup\n\n### üß™ Testing & Quality\n- **Comprehensive Tests**: 15+ test scenarios covering edge cases\n- **Integration Tests**: Real database interactions with SQLite\n- **Mock Implementations**: Complete test helpers for all datastore methods\n- **Race Condition Testing**: Concurrent access validation\n\n## Technical Implementation\n\n### Database Schema\n```sql\n-- New method for period-specific queries\nGetSpeciesFirstDetectionInPeriod(startDate, endDate, limit, offset)\n-- Returns first detection of each species within the date range\n```\n\n### Configuration\n```yaml\nrealtime:\n  species_tracking:\n    enabled: true\n    new_species_window_days: 14    # Lifetime tracking window\n    yearly_tracking:\n      enabled: true\n      window_days: 30              # Yearly tracking window  \n    seasonal_tracking:\n      enabled: true\n      window_days: 21              # Seasonal tracking window\n```\n\n### API Response Format\n```json\n{\n  \"species\": [\n    {\n      \"common_name\": \"Eurasian Blackcap\",\n      \"is_new_species\": true,        # ‚≠ê Star badge\n      \"is_new_this_year\": false,     # üìÖ Calendar badge\n      \"is_new_this_season\": true,    # üçÉ Leaf badge\n      \"days_since_first\": 2,\n      \"days_this_year\": 45,\n      \"days_this_season\": 2\n    }\n  ]\n}\n```\n\n## Bug Fixes\n- **Seasonal Data Loading**: Fixed issue where seasonal tracking showed all species as \"new this season\"\n- **Date Calculations**: Corrected DaysThisYear computation for accurate year tracking\n- **Cache Invalidation**: Fixed cache not clearing on year/season transitions\n- **Mock Updates**: Updated all test mocks to include new interface methods\n\n## Files Changed\n- **Frontend**: DailySummaryCard.svelte, DashboardPage.svelte, types, styles\n- **Backend**: Species tracker, analytics API, datastore methods, configuration\n- **Tests**: Comprehensive unit, integration, and mock tests\n- **Documentation**: Updated configuration examples and API documentation\n\n## Testing\n- ‚úÖ All existing tests pass\n- ‚úÖ New integration tests with real database\n- ‚úÖ Mock implementations updated\n- ‚úÖ Manual testing with API endpoints\n- ‚úÖ Race condition testing for concurrent access\n\n## Breaking Changes\nNone - all changes are backward compatible.\n\n## Migration Notes\n- New configuration options are optional with sensible defaults\n- Database schema changes are additive (new method only)\n- API response includes new fields but doesn't remove existing ones\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n## Summary by CodeRabbit\n\n* **New Features**\n  * Introduced multi-period species tracking with lifetime, yearly, and seasonal windows.\n  * Added badges and animated icons for new species in dashboards.\n  * Enhanced daily species summary and detection responses with tracking metadata and season info.\n  * Notifications generated for new species detections.\n\n* **Performance Improvements**\n  * Optimized dashboard with caching, memoized URL builders, and incremental updates.\n  * Added composite database indexes for faster species tracking queries.\n\n* **Configuration**\n  * Added configurable species tracking options: window durations, yearly resets, seasonal definitions.\n\n* **Bug Fixes**\n  * Improved modal overlay behavior to prevent accidental closure.\n\n* **Documentation**\n  * Updated comments and accessibility notes.\n\n* **Tests**\n  * Added extensive unit and integration tests for species tracking, seasonal/yearly transitions, notifications, and database analytics.\n\n* **Chores**\n  * Added new icons and CSS animations for UI feedback.\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
         "Claude_Code",
         "7030001",
         "tphakala",
         "closed",
         "2025-07-29T11:21:11Z",
         "2025-07-29T13:49:45Z",
         "2025-07-29T13:49:45Z",
         "707764474",
         "https://api.github.com/repos/tphakala/birdnet-go",
         "https://github.com/tphakala/birdnet-go/pull/1037",
         "feat"
        ],
        [
         "2",
         "3219880512",
         "10340",
         "feat(backend): Integrate GCS file storage with automatic expiration for Agent File Input",
         "## Summary\n\nThis PR introduces a complete cloud storage infrastructure and file upload system that agents can use instead of passing base64 data directly in inputs, while maintaining backward compatibility for the builder's node inputs.\n\n### Problem Statement\n\nCurrently, when agents need to process files, they pass base64-encoded data directly in the input, which has several limitations:\n1. **Size limitations**: Base64 encoding increases file size by ~33%, making large files impractical\n2. **Memory usage**: Large base64 strings consume significant memory during processing\n3. **Network overhead**: Base64 data is sent repeatedly in API requests\n4. **Performance impact**: Encoding/decoding base64 adds processing overhead\n\n### Solution\n\nThis PR introduces a complete cloud storage infrastructure and new file upload workflow:\n1. **New cloud storage system**: Complete `CloudStorageHandler` with async GCS operations\n2. **New upload endpoint**: Agents upload files via `/files/upload` and receive a `file_uri` \n3. **GCS storage**: Files are stored in Google Cloud Storage with user-scoped paths\n4. **URI references**: Agents pass the `file_uri` instead of base64 data\n5. **Block processing**: File blocks can retrieve actual file content using the URI\n\n### Changes Made\n\n#### New Files Introduced:\n- **`backend/util/cloud_storage.py`** - Complete cloud storage infrastructure (545 lines)\n- **`backend/util/cloud_storage_test.py`** - Comprehensive test suite (471 lines)\n\n#### Backend Changes:\n- **New cloud storage infrastructure** in `backend/util/cloud_storage.py`:\n  - Complete `CloudStorageHandler` class with async GCS operations\n  - Support for multiple cloud providers (GCS implemented, S3/Azure prepared)\n  - User-scoped and execution-scoped file storage with proper authorization\n  - Automatic file expiration with metadata-based cleanup\n  - Path traversal protection and comprehensive security validation\n  - Async file operations with proper error handling and logging\n\n- **New `UploadFileResponse` model** in `backend/server/model.py`:\n  - Returns `file_uri` (GCS path like `gcs://bucket/users/{user_id}/file.txt`)\n  - Includes `file_name`, `size`, `content_type`, `expires_in_hours`\n  - Proper Pydantic schema instead of dictionary response\n\n- **New `upload_file` endpoint** in `backend/server/routers/v1.py`:\n  - Complete new endpoint for file upload with cloud storage integration\n  - Returns GCS path URI directly as `file_uri`\n  - Supports user-scoped file storage for proper isolation\n  - Maintains fallback to base64 data URI when GCS not configured\n  - File size validation, virus scanning, and comprehensive error handling\n\n#### Frontend Changes:\n- **Updated API client** in `frontend/src/lib/autogpt-server-api/client.ts`:\n  - Modified return type to expect `file_uri` instead of `signed_url`\n  - Supports the new upload workflow\n\n- **Enhanced file input component** in `frontend/src/components/type-based-input.tsx`:\n  - **Builder nodes**: Still use base64 for immediate data retention without expiration\n  - **Agent inputs**: Use the new upload endpoint and pass `file_uri` references\n  - Maintains backward compatibility for existing workflows\n\n#### Test Updates:\n- **New comprehensive test suite** in `backend/util/cloud_storage_test.py`:\n  - 27 test cases covering all cloud storage functionality\n  - Tests for file storage, retrieval, authorization, and cleanup\n  - Tests for path validation, security, and error handling\n  - Coverage for user-scoped, execution-scoped, and system storage\n\n- **New upload endpoint tests** in `backend/server/routers/v1_test.py`:\n  - Tests for GCS path URI format (`gcs://bucket/path`)\n  - Tests for base64 fallback when GCS not configured\n  - Validates file upload, virus scanning, and size limits\n  - Tests user-scoped file storage and access control\n\n### Benefits\n\n1. **New Infrastructure**: Complete cloud storage system with enterprise-grade features\n2. **Scalability**: Supports larger files without base64 size penalties\n3. **Performance**: Reduces memory usage and network overhead with async operations\n4. **Security**: User-scoped file storage with comprehensive access control and path validation\n5. **Flexibility**: Maintains base64 support for builder nodes while providing URI-based approach for agents\n6. **Extensibility**: Designed for multiple cloud providers (GCS, S3, Azure)\n7. **Reliability**: Automatic file expiration, cleanup, and robust error handling\n8. **Backward compatibility**: Existing builder workflows continue to work unchanged\n\n### Usage\n\n**For Agent Inputs:**\n```typescript\n// 1. Upload file\nconst response = await api.uploadFile(file);\n// 2. Pass file_uri to agent\nconst agentInput = { file_input: response.file_uri };\n```\n\n**For Builder Nodes (unchanged):**\n```typescript\n// Still uses base64 for immediate data retention\nconst nodeInput = { file_input: \"data:image/jpeg;base64,...\" };\n```\n\n### Checklist üìã\n\n#### For code changes:\n- [x] I have clearly listed my changes in the PR description\n- [x] I have made a test plan\n- [x] I have tested my changes according to the test plan:\n  - [x] All new cloud storage tests pass (27/27)\n  - [x] All upload file tests pass (7/7)\n  - [x] Full v1 router test suite passes (21/21)\n  - [x] All server tests pass (126/126)\n  - [x] Backend formatting and linting pass\n  - [x] Frontend TypeScript compilation succeeds\n  - [x] Verified GCS path URI format (`gcs://bucket/path`)\n  - [x] Tested fallback to base64 data URI when GCS not configured\n  - [x] Confirmed file upload functionality works in UI\n  - [x] Validated response schema matches Pydantic model\n  - [x] Tested agent workflow with file_uri references\n  - [x] Verified builder nodes still work with base64 data\n  - [x] Tested user-scoped file access control\n  - [x] Verified file expiration and cleanup functionality\n  - [x] Tested security validation and path traversal protection\n\n#### For configuration changes:\n- [x] No new configuration changes required\n- [x] `.env.example` remains compatible \n- [x] `docker-compose.yml` remains compatible\n- [x] Uses existing GCS configuration from media storage\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "76959103",
         "majdyz",
         "closed",
         "2025-07-10T15:52:56Z",
         "2025-07-18T03:20:54Z",
         "2025-07-18T03:20:54Z",
         "614765452",
         "https://api.github.com/repos/Significant-Gravitas/AutoGPT",
         "https://github.com/Significant-Gravitas/AutoGPT/pull/10340",
         "feat"
        ],
        [
         "3",
         "2876006908",
         "3375",
         "Improve list and collection materializers performance",
         "# Optimized Collection Materializers with Batch Compression\n\nThis PR significantly improves the performance of list and collection materializers, addressing a critical bottleneck in ZenML's artifact handling system.\n\n## Initial Improvements\n- Groups elements by type to reduce overhead of materializer initialization and type checking\n- Pre-allocates lists of the correct size when loading\n- Uses a more efficient metadata format with type grouping for faster retrieval\n\n## Major Batch Compression Enhancement\n\n### Technical Implementation\n- **Batch Compression Architecture**: Instead of writing each element to its own directory, elements are grouped by type and serialized into compressed batch files using gzip+pickle\n- **Chunking Strategy**: For very large collections, items are further divided into manageable chunks (configurable, default 100 elements per file) to avoid memory issues\n- **Adaptive Sizing**: Automatically adjusts chunk size based on element size to prevent memory issues with very large objects\n- **Metadata Optimization**: Enhanced metadata structure (v3 format) tracks batches, chunks, and element indices while maintaining backward compatibility\n- **Efficient Loading**: Implements chunk-based caching during loading to avoid redundant reads\n- **Clean Error Handling**: Comprehensive cleanup on failures to ensure no orphaned files\n- **Cloud Storage Support**: Properly handles cloud storage backends (S3, GCS, Azure) using ZenML's fileio utilities\n\n### Performance Impact\nThe impact on performance is substantial:\n- **I/O Reduction**: For a collection with 1000 elements, reduces file operations from 1000+ to potentially just 10-20\n- **Network Overhead Reduction**: Minimizes REST API calls when using cloud storage backends (S3, GCS, Azure)\n- **Storage Efficiency**: Compressed storage requires less space and network bandwidth\n- **Reduced Latency**: Batch operations dramatically reduce the overhead of individual file operations, especially impactful for high-latency storage systems\n\n### Configuration Options\n- Added environment variable ZENML_MATERIALIZER_COLLECTION_CHUNK_SIZE to configure chunk size (default: 100)\n- Comprehensive documentation added to environment variables reference and data handling guides\n\n### Compatibility\n- Full backward compatibility with existing v2 and pre-v2 formats\n- New artifacts use the v3 format automatically\n- Comprehensive test suite validates all serialization/deserialization paths\n\nThis change significantly improves user experience when working with large collections, especially in cloud environments where storage operations have higher latency.\n\nFixes #3371\n\nü§ñ Generated with Claude Code\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "3348134",
         "strickvl",
         "closed",
         "2025-02-24T19:52:57Z",
         "2025-04-20T19:47:42Z",
         null,
         "314197645",
         "https://api.github.com/repos/zenml-io/zenml",
         "https://github.com/zenml-io/zenml/pull/3375",
         "feat"
        ],
        [
         "4",
         "3142181649",
         "19",
         "Replace CLI subprocess approach with Claude Code SDK",
         "## Description\n\nReplace the current CLI subprocess execution approach with the Claude Code SDK for better performance, type safety, and error handling. This is a clean replacement that maintains the same interface while providing significant performance improvements.\n\n## Type of Change\n\nPlease add the appropriate label(s) to this PR and check the relevant box(es):\n\n- [ ] üêõ `bug` - Bug fix (non-breaking change which fixes an issue)\n- [x] ‚ú® `feature` - New feature (non-breaking change which adds functionality)\n- [ ] üí• `breaking` - Breaking change (fix or feature that would cause existing functionality to not work as expected)\n- [ ] üìö `documentation` - Documentation update\n- [x] ‚ö° `performance` - Performance improvement\n- [ ] üî® `refactor` - Code refactoring\n- [ ] üß™ `test` - Adding or updating tests\n- [ ] üîß `chore` - Maintenance, dependencies, tooling\n\n## Changes Made\n\n- **Complete replacement**: CLI subprocess execution ‚Üí Claude Code SDK\n- **Same interface**: `executeClaudeCommand` function maintains identical signature\n- **Identical output**: Same JSON message structure (`system`, `assistant`, `result` types)\n- **Simplified implementation**: No feature flags, fallbacks, or complex configuration\n- **Working directory**: Maintains project root execution behavior\n- **Dependencies**: Added `npm:@anthropic-ai/claude-code` to deno.lock\n\n## Testing\n\n- [x] Tests pass locally (`make test`)\n- [x] Code is formatted (`make format`)\n- [x] Code is linted (`make lint`)\n- [x] Type checking passes (`make typecheck`)\n- [x] All quality checks pass (`make check`)\n- [x] Manual testing performed - Verified SDK produces identical JSON output format\n\n## Checklist\n\n- [x] My code follows the project's style guidelines\n- [x] I have performed a self-review of my own code\n- [x] I have commented my code, particularly in hard-to-understand areas\n- [ ] I have made corresponding changes to the documentation\n- [ ] I have added/updated tests for my changes\n- [x] All tests pass\n\n## Screenshots (if applicable)\n\nN/A - Backend implementation change with no UI modifications.\n\n## Additional Notes\n\nThis addresses issue #18 with a clean, simple replacement approach:\n\n**Performance Benefits:**\n- Eliminates process spawning overhead for each request\n- Direct memory access instead of IPC communication\n- Native JavaScript error handling\n\n**Compatibility:**\n- Zero breaking changes to API\n- Identical JSON output format maintained\n- Same function interface for minimal integration impact\n\n**Simplicity:**\n- No feature flags or configuration complexity\n- Clean, focused implementation\n- Easier to maintain and understand\n\nCloses #18\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "80381",
         "sugyan",
         "closed",
         "2025-06-13T04:05:15Z",
         "2025-06-13T14:14:33Z",
         "2025-06-13T14:14:33Z",
         "999285986",
         "https://api.github.com/repos/sugyan/claude-code-webui",
         "https://github.com/sugyan/claude-code-webui/pull/19",
         "feat"
        ],
        [
         "5",
         "3200679276",
         "4304",
         "Implement lazy loading for RegistryInstance to improve latency in operations where the registry does not need to be read",
         "üë® \r\n\r\nBefore:\r\n\r\n```\r\njulia> @time Pkg.instantiate()\r\n  0.390297 seconds (1.95 M allocations: 148.381 MiB, 16.29% gc time, 31.03% compilation time: 68% of which was recompilation)\r\n```\r\n\r\nAfter:\r\n```\r\njulia> @time Pkg.instantiate()\r\n  0.161872 seconds (456.14 k allocations: 27.898 MiB, 9.75% gc time, 86.52% compilation time: 60% of which was recompilation)\r\n```\r\n\r\n\r\n-----\r\n\r\nü§ñ \r\n\r\n- Change RegistryInstance to mutable struct with lazily loaded fields\r\n- Defer expensive operations (decompression, Registry.toml parsing) until needed\r\n- Add ensure_registry_loaded\\!() to trigger loading on first access\r\n- Use getproperty() to automatically load when accessing name, uuid, repo, description, or pkgs\r\n- Fix #4301 by reducing initial registry creation overhead\r\n\r\nü§ñ Generated with [Claude Code](https://claude.ai/code)\r\n\r\nCo-Authored-By: Claude <noreply@anthropic.com>\r\n",
         "Claude_Code",
         "1282691",
         "KristofferC",
         "closed",
         "2025-07-03T21:18:03Z",
         "2025-07-04T08:34:04Z",
         "2025-07-04T08:34:04Z",
         "82341193",
         "https://api.github.com/repos/JuliaLang/Pkg.jl",
         "https://github.com/JuliaLang/Pkg.jl/pull/4304",
         "perf"
        ],
        [
         "6",
         "3201567268",
         "17613",
         "stm32/eth: Improve Ethernet driver with link detection and static IP support.",
         "## Summary\n\nThis PR implements comprehensive improvements to the STM32 Ethernet driver, addressing several critical usability issues and adding important features for robust network connectivity.\n\n**Key improvements:**\n- ‚úÖ Automatic cable connect/disconnect detection with proper LWIP integration\n- ‚úÖ Fixed `active()` method to return interface state instead of link status\n- ‚úÖ Enable static IP configuration before interface activation\n- ‚úÖ Eliminated blocking timeouts when activating without cable connected\n- ‚úÖ Fixed network initialization order to allow instantiation in boot.py\n- ‚úÖ Fixed DHCP timing issues for reliable IP acquisition\n\n## Testing\n\nTested on NUCLEO_H563ZI board with STM32H563 MCU:\n- Cable connect/disconnect detection works reliably\n- Static IP configuration before `active(True)` works correctly\n- `active(True)` returns immediately even without cable\n- DHCP works correctly with various link timing scenarios\n- Network interfaces can be instantiated in boot.py\n- All test scripts pass successfully\n\nTest scripts included:\n- `test_eth_ipv6.py` - IPv6 support validation\n- `test_eth_link_changes.py` - Link detection functionality\n- `test_eth_active_method.py` - Interface state management\n- `test_eth_static_ip_before_active.py` - Static IP workflow\n- `test_eth_active_without_cable.py` - Non-blocking startup\n\n## Trade-offs and Alternatives\n\n**Code size increase:** ~300 lines added for improved functionality\n- This is justified by the significant usability improvements\n- Most additions are for proper state management and error handling\n\n**Alternative approaches considered:**\n- Polling link status in interrupt handler - rejected for efficiency\n- Keeping blocking PHY init - rejected for poor user experience\n- Different DHCP timing - current approach is most robust\n\n## Detailed Changes\n\n### 1. Link State Detection and Interface Management\n- Added PHY interrupt register support for future hardware interrupts\n- Implemented on-demand PHY polling for cable state changes\n- Added proper LWIP `netif_set_link_up/down()` integration\n- Fixed `active()` to return interface enabled state, not link status\n\n### 2. Static IP and Non-blocking PHY\n- Restructured LWIP initialization for early netif setup\n- Removed blocking PHY autonegotiation loops\n- Allow static IP configuration before `active(True)`\n- PHY configuration happens asynchronously when link established\n\n### 3. PHY Lifecycle Optimization\n- Moved PHY init from MAC init to interface start\n- Added proper PHY shutdown on interface stop\n- Optimized status checks to poll once then use cached state\n- Removed redundant periodic polling\n\n### 4. Network Initialization Order Fix\n- Moved `mod_network_init()` before boot.py execution\n- Allows `network.LAN()` instantiation in boot.py\n- Maintains compatibility with `network.country()` and `network.hostname()`\n\n### 5. DHCP Timing Fix\n- Poll link status before attempting DHCP start\n- Start DHCP when link comes up if no static IP\n- Handle DHCP correctly across link state changes\n\n## Performance Improvements\n\n < /dev/null |  Operation | Before | After | Improvement |\n|-----------|--------|-------|-------------|\n| `network.LAN()` | ~100ms | ~50ms | 2x faster |\n| `active(True)` with cable | ~2s | ~100ms | 20x faster |\n| `active(True)` without cable | 10s timeout | ~100ms | 100x faster |\n| Link detection | Manual only | Automatic | Real-time |\n\n## Backward Compatibility\n\nAll changes maintain 100% backward compatibility:\n- Existing code continues to work unchanged\n- API signatures remain identical\n- Only behavioral improvements, no breaking changes\n\n## Example Usage\n\n```python\n# In boot.py - now works\\!\nimport network\n\n# Configure network settings\nnetwork.country('US')\nnetwork.hostname('my-device')\n\n# Create and configure interface\neth = network.LAN()\n\n# Configure static IP before activation\neth.ipconfig(addr='192.168.1.100', mask='255.255.255.0', gw='192.168.1.1')\n\n# Activate interface - returns immediately\neth.active(True)\n\n# Or use DHCP\neth.ipconfig(dhcp4=True)\n\n# Check connection status\nif eth.isconnected():\n    print('Connected with IP:', eth.ipconfig('addr4'))\n```\n\n## Documentation\n\nComprehensive documentation included:\n- Implementation report with technical details\n- Test scripts demonstrating all features\n- Network initialization order analysis\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "3318786",
         "andrewleech",
         "open",
         "2025-07-04T06:53:52Z",
         null,
         null,
         "15337142",
         "https://api.github.com/repos/micropython/micropython",
         "https://github.com/micropython/micropython/pull/17613",
         "feat"
        ],
        [
         "7",
         "3250080019",
         "24542",
         "[fix][broker]Fix thread safety issues in BucketDelayedDeliveryTracker with StampedLock optimistic reads",
         "### Motivation\r\n\r\nFixes #23190\r\n\r\nBucketDelayedDeliveryTracker had thread safety issues in frequently called methods like `containsMessage()` and `nextDeliveryTime()` that could lead to race conditions, incorrect duplicate detection, and scheduling inconsistencies under high concurrency loads.\r\n\r\nThe issue manifested as:\r\n- Race conditions in `containsMessage()` leading to incorrect duplicate detection\r\n- Concurrent access issues in `nextDeliveryTime()` causing scheduling inconsistencies\r\n- Potential data corruption under high concurrency scenarios\r\n\r\n### Modifications\r\n\r\n- **Added StampedLock for high-performance concurrency control**\r\n  - Implemented optimistic read pattern for frequently called read operations\r\n  - Provides lock-free fast path when no concurrent writes are occurring\r\n  - Falls back gracefully to read locks when validation fails\r\n\r\n- **Applied optimistic reads to critical methods:**\r\n  - `containsMessage()` - Used for duplicate message detection\r\n  - `nextDeliveryTime()` - Called frequently for message scheduling\r\n\r\n- **Maintained existing write operation synchronization**\r\n  - Write operations continue to use `synchronized` for simplicity and safety\r\n  - Mixed approach optimal for typical read-heavy delayed delivery workloads\r\n\r\n- **Removed unused data structure**\r\n  - Eliminated unused `immutableBucketsMap` field to reduce memory overhead\r\n  - All bucket operations use the existing `immutableBuckets` RangeMap\r\n\r\n### Performance Improvements\r\n\r\nBenchmark results show excellent performance across various concurrency scenarios:\r\n- **Single-threaded reads**: ~305 million ops/s\r\n- **High concurrency (16 threads)**: ~2.6 billion ops/s  \r\n- **Mixed read/write ratios**: Consistent performance from 10:90 to 90:10\r\n- **Optimistic read success rate**: Very high under typical read-heavy workloads\r\n\r\n### Thread Safety Strategy\r\n\r\n- **Read operations**: Use StampedLock optimistic reads for maximum performance\r\n- **Write operations**: Continue using synchronized for safety and simplicity\r\n- **Data structures**: Leverage existing thread-safe collections (ConcurrentHashMap, etc.)\r\n\r\n### Verifying this change\r\n\r\n- **Added comprehensive thread safety test**: `BucketDelayedDeliveryTrackerThreadSafetyTest`\r\n- **Created performance benchmark**: `BucketDelayedDeliveryTrackerSimpleBenchmark` \r\n- **All existing tests pass**\r\n- **No functional changes** - maintains full backward compatibility\r\n\r\n### Does this pull request potentially affect one of the following parts:\r\n\r\nIf the box was checked, please highlight the changes:\r\n\r\n- [ ] Dependencies (add or upgrade a dependency)\r\n- [ ] The public API\r\n- [ ] The schema\r\n- [ ] The default behavior\r\n- [ ] The cluster topology\r\n- [ ] The ARM (kafka compatibility, producer/consumer compatibility)\r\n\r\n### Documentation\r\n\r\n- [ ] `doc` <!-- Your PR contains doc changes -->\r\n- [ ] `doc-required` <!-- Your PR changes impact docs and you will update later -->\r\n- [x] `doc-not-needed` <!-- Your PR changes do not impact docs -->\r\n- [ ] `doc-complete` <!-- Docs have been already added -->\r\n\r\n### Matching PR in forked repository\r\n\r\nPR in forked repository: [Link](https://github.com/Apurva007/pulsar/pull/7)\r\n\r\nü§ñ Generated with [Claude Code](https://claude.ai/code)\r\n\r\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "10327630",
         "Apurva007",
         "closed",
         "2025-07-21T21:21:39Z",
         "2025-07-22T06:17:01Z",
         "2025-07-22T06:17:01Z",
         "62117812",
         "https://api.github.com/repos/apache/pulsar",
         "https://github.com/apache/pulsar/pull/24542",
         "fix"
        ],
        [
         "8",
         "3250477735",
         "397",
         "Optimize nancorrmatrix and nancovmatrix for cache locality",
         "Refactor `nancorrmatrix` and `nancovmatrix` to process observations sequentially. This improves cache locality by reducing random memory access patterns, leading to better performance.\n\nThe previous implementation iterated over variable pairs, then observations, resulting in scattered memory access. The new approach iterates over observations first, loading an entire observation into cache, then processing all variable pairs for that observation. This reduces cache misses significantly.\n\nAlso adds new benchmark parameters to test these functions with larger inputs.\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\n",
         "Claude_Code",
         "5635139",
         "max-sixty",
         "closed",
         "2025-07-22T00:19:55Z",
         "2025-07-22T00:28:17Z",
         "2025-07-22T00:28:17Z",
         "25501620",
         "https://api.github.com/repos/numbagg/numbagg",
         "https://github.com/numbagg/numbagg/pull/397",
         "perf"
        ],
        [
         "9",
         "3260887009",
         "1164",
         "Fix startup errors and implement real-time Effect streaming",
         "## Summary\nFixes the \"Session not found\" error on app startup and implements real-time Effect-based streaming to replace 50ms polling.\n\n## Key Changes\n\n### 1. Fix \"Session not found\" Error\n- **Problem**: App showed \"Session not found\" dialog on every startup\n- **Root cause**: Chat panes were persisted but sessions are ephemeral \n- **Solution**: Filter out chat panes on rehydration from localStorage\n- **Result**: Clean app startup with no error dialogs\n\n### 2. Implement Effect-Based Streaming  \n- **Problem**: Messages appeared all at once instead of streaming in real-time\n- **Root cause**: PR #1160 with Effect streaming was never merged\n- **Solution**: Extracted working streaming implementation and integrated it\n- **Key techniques**:\n  - Uses `Effect.forkDaemon` to prevent fiber interruption\n  - Direct `Effect.runPromise` with `Effect.provide` instead of ManagedRuntime\n  - Simplified session management without complex Fiber tracking\n  - Queue holds payload directly instead of TauriEvent wrapper\n- **Result**: Messages now stream in real-time as they're received from Claude\n\n### 3. Additional Fixes\n- **React setState warnings**: Wrapped state updates in `setTimeout` to avoid render-time mutations\n- **Text input during initialization**: Removed `isInitializing` check to allow typing while session starts\n- **Responsive pane height**: Made `DEFAULT_CHAT_HEIGHT` responsive to viewport size\n- **Clean logging**: Removed debug console.log statements for production use\n- **Rust backend**: Updated to emit Tauri events for real-time streaming\n\n## Technical Details\n\n### Backend Changes\n- Added `app_handle` to `ClaudeManager` and `ClaudeSession`\n- Emit `claude:{sessionId}:message` events for each message\n- Modified `create_session` to accept and store app handle\n\n### Frontend Changes\n- Added Effect streaming services: `TauriEventService`, `ClaudeStreamingService`\n- Created `useClaudeStreaming` hook for React integration\n- Added `SessionStreamManager` component to handle streaming per session\n- Removed 50ms polling mechanism entirely\n\n### Effect Streaming Architecture\n```typescript\n// Service layer with proper error handling\nconst ServiceLayer = Layer.provideMerge(ClaudeStreamingServiceLive, TauriEventLayer);\n\n// Stream processing with daemon fork\nyield* pipe(\n  service.getMessageStream(session),\n  Stream.tap(message => updateUI(message)),\n  Stream.runDrain,\n  Effect.forkDaemon // Key: prevents fiber interruption\n);\n```\n\n## Test Plan\n- [x] App starts without \"Session not found\" error\n- [x] Messages stream in real-time (not all at once)\n- [x] Can type in chat input while session initializes  \n- [x] Pane height adapts to viewport size\n- [x] No React setState warnings in console\n- [x] Clean console output (no debug logs)\n- [x] Chat sessions persist messages across app usage\n- [x] Multiple concurrent sessions work correctly\n\n## Before/After\n**Before**: 50ms polling, messages appear all at once, \"Session not found\" errors\n**After**: Real-time streaming, messages appear as they're typed, clean startup\n\nFixes #1163\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "14167547",
         "AtlantisPleb",
         "closed",
         "2025-07-24T18:50:34Z",
         "2025-07-24T20:00:28Z",
         "2025-07-24T20:00:28Z",
         "715683924",
         "https://api.github.com/repos/OpenAgentsInc/openagents",
         "https://github.com/OpenAgentsInc/openagents/pull/1164",
         "fix"
        ],
        [
         "10",
         "3188858394",
         "834",
         "feat: implement async notification and telemetry system (Phase 1-3)",
         "## Summary\n\nThis PR implements the first three phases of the async notification and telemetry system as outlined in #833. It introduces a non-blocking event bus architecture that decouples error reporting from notification/telemetry processing, preventing any blocking operations during error handling.\n\n## Related Issues\n\n- Implements phases 1-3 of #833 (Async notification/telemetry system)\n- Addresses performance concerns from #825 (Error handling optimization)\n- Includes error deduplication from #827 (Reduce telemetry noise)\n\n## Changes\n\n### Phase 1: Core Event Bus Infrastructure ‚úÖ\n- Created `internal/events` package with non-blocking event bus\n- Implemented worker pool pattern with configurable workers (default: 4)\n- Added `TryPublish()` method that never blocks (drops events if buffer full)\n- Comprehensive unit tests with 100% coverage\n- Structured logging with `internal/logging` package\n- Atomic operations for thread-safe metrics\n\n### Phase 2: Error Deduplication System ‚úÖ\n- Hash-based deduplication with configurable TTL (default: 5 minutes)\n- LRU eviction for memory-bounded cache (max 10,000 entries)\n- Periodic cleanup goroutine for expired entries\n- Comprehensive deduplication metrics (hit rate, suppression count)\n- Reduces telemetry volume by suppressing duplicate errors\n\n### Phase 3: Error Package Integration ‚úÖ\n- Enhanced `EnhancedError` to implement `ErrorEvent` interface\n- Created `EventPublisher` interface to avoid circular dependencies\n- Adapter pattern connects errors and events packages\n- Maintains backward compatibility - falls back to sync processing if event bus not initialized\n- Verified no circular dependencies through compilation tests\n\n## Architecture\n\n```\nerrors package ‚Üí EventBus ‚Üí Deduplication ‚Üí notification workers (future)\n                                         ‚Üò ‚Üí telemetry workers (future)\n```\n\n### Key Design Principles\n\n1. **Zero-cost when disabled**: No overhead when telemetry/notifications are off\n2. **Non-blocking guarantees**: `TryPublish()` never blocks, uses select with default\n3. **No circular dependencies**: Uses interfaces to decouple packages\n4. **Backward compatible**: Falls back to legacy sync processing\n5. **Production ready**: Proper error handling, metrics, and tests\n\n## Performance Characteristics\n\n- Error creation overhead: < 100ns when telemetry disabled (maintains #825 optimizations)\n- Event publishing: Non-blocking with overflow protection\n- Deduplication: O(1) hash lookup with < 100ns overhead\n- Memory usage: Bounded by configuration (10k events max)\n- Zero goroutine leaks verified\n\n## Testing\n\n- Comprehensive unit tests for all components\n- Integration tests verify no circular dependencies\n- Fixed deadlock issues in error hooks\n- Proper test isolation and cleanup\n- All tests pass without timeouts or race conditions\n\n## Configuration\n\nThe system supports configuration through the new event bus config:\n\n```go\ntype Config struct {\n    BufferSize    int                    // Event buffer size (default: 10,000)\n    Workers       int                    // Worker goroutines (default: 4)\n    Enabled       bool                   // Enable event bus (default: true)\n    Deduplication *DeduplicationConfig   // Deduplication settings\n}\n\ntype DeduplicationConfig struct {\n    Enabled         bool          // Enable deduplication (default: true)\n    TTL             time.Duration // Duplicate window (default: 5m)\n    MaxEntries      int          // Max cache size (default: 10,000)\n    CleanupInterval time.Duration // Cleanup frequency (default: 1m)\n}\n```\n\n## Next Steps\n\nThis PR lays the foundation for async processing. Future phases will:\n- Phase 4: Migrate notification system to use event bus workers\n- Phase 5: Migrate telemetry system with batching and circuit breakers\n- Phase 6: Remove legacy sync processing code\n- Phase 7: Add monitoring and production tuning\n\n## Breaking Changes\n\nNone. The system maintains full backward compatibility.\n\n## Checklist\n\n- [x] Tests pass\n- [x] Linter passes (`golangci-lint run`)\n- [x] No circular dependencies\n- [x] Backward compatible\n- [x] Performance requirements met\n- [x] Documentation updated\n\n## How to Test\n\n1. Run tests: `go test ./internal/events/... ./internal/errors/...`\n2. Verify no circular dependencies compile\n3. Check deduplication with repeated errors\n4. Confirm non-blocking behavior under load\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n## Summary by CodeRabbit\n\n* **New Features**\n  * Introduced an asynchronous event bus system for non-blocking error event processing with deduplication and metrics.\n  * Added error deduplication to suppress duplicate error events within a configurable time window.\n  * Provided integration between error reporting and the event bus for improved decoupling and extensibility.\n  * Added new error accessors for retrieving underlying error and message details.\n\n* **Bug Fixes**\n  * Improved thread safety and encapsulation in error context handling.\n\n* **Tests**\n  * Added comprehensive unit and integration tests for event bus, deduplication, and error-event integration.\n\n* **Refactor**\n  * Updated error category handling to use string values for improved consistency.\n  * Improved synchronization and state management in error hook and telemetry logic.\n\n* **Documentation**\n  * Expanded best practices and lessons learned on defensive coding, testing, atomic usage, performance, and error handling.\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
         "Claude_Code",
         "7030001",
         "tphakala",
         "closed",
         "2025-06-30T15:10:13Z",
         "2025-06-30T15:35:07Z",
         "2025-06-30T15:35:07Z",
         "707764474",
         "https://api.github.com/repos/tphakala/birdnet-go",
         "https://github.com/tphakala/birdnet-go/pull/834",
         "feat"
        ],
        [
         "11",
         "3090065215",
         "19",
         "Add Claude CLI support with Strategy Pattern architecture (v0.6.0)",
         "## üöÄ Major Enhancement: Claude CLI Support & Strategy Pattern Architecture\n\nThis PR introduces comprehensive Claude CLI support with a robust Strategy Pattern architecture, bringing the MCP installer to v0.6.0 with significant performance and extensibility improvements.\n\n## ‚ú® New Features\n\n### Claude CLI Integration\n- **Automatic Detection**: Detects if `claude` CLI is available at startup\n- **Immediate Availability**: Servers installed via CLI are available instantly (no restart required)\n- **Graceful Fallback**: Falls back to Claude Desktop config if CLI unavailable\n- **Enhanced UX**: Clear feedback on installation method and availability status\n\n### Strategy Pattern Architecture\n- **Extensible Design**: Clean interface ready for multiple installation environments\n- **Performance Optimized**: Early strategy detection (1 call vs 4 calls per operation)\n- **Future-Ready**: Prepared for Docker, Kubernetes, VS Code Extensions, and more\n- **Maintainable**: Eliminated conditional branching duplication throughout codebase\n\n## üèóÔ∏è Technical Improvements\n\n### Architecture Changes\n- Added `InstallationStrategy` interface with concrete implementations:\n  - `ClaudeCliStrategy` - For `claude` CLI installations\n  - `ClaudeDesktopStrategy` - For traditional config file approach\n- Global strategy initialization at server startup\n- Unified installation interface across all environments\n\n### Performance Enhancements\n- **Before**: 4 `hasClaudeCLI()` calls per installation operation\n- **After**: 1 `hasClaudeCLI()` call per server startup\n- Eliminated redundant environment detection\n- Streamlined installation flow\n\n### Code Quality\n- Removed legacy `installToClaudeCLI`/`installToClaudeDesktop` functions\n- Simplified conditional logic throughout the codebase\n- Better separation of concerns\n- Enhanced error handling and user feedback\n\n## üì¶ Installation & Usage\n\n### For Claude CLI (New - Recommended):\n```bash\nclaude mcp add mcp-installer npx --args @o2alexanderfedin/mcp-installer\n```\n\n### For Claude Desktop (Existing):\n```json\n{\n  \"mcpServers\": {\n    \"mcp-installer\": {\n      \"command\": \"npx\",\n      \"args\": [\"@o2alexanderfedin/mcp-installer\"]\n    }\n  }\n}\n```\n\n## üîÑ Backward Compatibility\n\n‚úÖ **No Breaking Changes**: All existing Claude Desktop installations continue to work exactly as before\n‚úÖ **Enhanced Experience**: Existing users get improved performance and better error messages\n‚úÖ **Seamless Migration**: No action required for current users\n\n## üß™ Testing\n\n- ‚úÖ TypeScript compilation passes\n- ‚úÖ Build system works correctly  \n- ‚úÖ Module loads without runtime errors\n- ‚úÖ Backward compatibility verified\n- ‚úÖ Strategy pattern functionality confirmed\n\n## üìã Commits Included\n\n1. **Add Claude CLI support with automatic detection and fallback** (`8e50814`)\n   - Core Claude CLI integration\n   - Automatic detection logic\n   - Enhanced README documentation\n\n2. **Remove unused function to fix TypeScript compilation** (`dd6e4a9`)\n   - Clean up legacy code\n   - Fix compilation issues\n\n3. **Refactor installation logic using Strategy Pattern** (`a778373`)\n   - Complete Strategy Pattern implementation\n   - Performance optimizations\n   - Code simplification\n\n4. **Bump version to 0.6.0** (`ce7ed5c`)\n   - Version update for release\n\n## üéØ Future Roadmap\n\nThis architecture enables easy addition of new installation environments:\n- Docker containers (`docker run` commands)\n- Kubernetes deployments (`kubectl apply`)\n- VS Code Extensions (`.vscode/settings.json`)\n- JetBrains IDEs (plugin configuration)\n- Cloud deployments (AWS Lambda, Google Cloud Functions)\n\n---\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "77516945",
         "o2alexanderfedin",
         "open",
         "2025-05-26T05:38:39Z",
         null,
         null,
         "894640711",
         "https://api.github.com/repos/anaisbetts/mcp-installer",
         "https://github.com/anaisbetts/mcp-installer/pull/19",
         "feat"
        ],
        [
         "12",
         "3133544722",
         "42",
         "Fix: Remove unnecessary async declarations from synchronous methods",
         "## Summary\n- Removed unnecessary `async` declarations from all manager methods that don't contain any `await` statements\n- Fixed test fixture to not await the now-synchronous `cleanup()` method\n- Improved code clarity by accurately representing the synchronous nature of Meilisearch client operations\n\n## Problem\nThe codebase had all manager methods marked as `async` even though they were using the synchronous Meilisearch Python client and contained no actual asynchronous operations. This created confusion about the execution model and added unnecessary overhead.\n\n## Solution\n1. Removed `async` keyword from all manager methods in:\n   - `indexes.py` (6 methods)\n   - `documents.py` (7 methods)\n   - `settings.py` (3 methods)\n   - `tasks.py` (4 methods)\n   - `keys.py` (5 methods)\n   - `monitoring.py` (3 methods)\n   - `client.py` (5 methods)\n   - `server.py` (2 methods: `update_connection` and `cleanup`)\n\n2. Removed corresponding `await` keywords from all calls to these methods in `server.py`\n\n3. Fixed test fixture in `test_mcp_client.py` to not await the `cleanup()` method\n\n## Test Results\n- All tests that were passing before continue to pass\n- No new test failures introduced by these changes\n- Tests confirm that the synchronous operations work correctly\n\n## Impact\n- **Improved code clarity**: Methods now accurately represent their synchronous nature\n- **Better performance**: Removes unnecessary coroutine overhead\n- **No breaking changes**: The MCP protocol handlers remain async as required\n\nThis is a pure refactoring with no functional changes.\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n\n## Summary by CodeRabbit\n\n- **Refactor**\n  - Converted all asynchronous methods in the Meilisearch management components to synchronous methods for a more consistent interface.\n- **Tests**\n  - Updated test cleanup procedures to match the new synchronous method calls.\n\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
         "Claude_Code",
         "10537452",
         "tpayet",
         "closed",
         "2025-06-10T13:09:48Z",
         "2025-06-13T07:47:57Z",
         "2025-06-13T07:47:56Z",
         "907425333",
         "https://api.github.com/repos/meilisearch/meilisearch-mcp",
         "https://github.com/meilisearch/meilisearch-mcp/pull/42",
         "fix"
        ],
        [
         "13",
         "3138362649",
         "1847",
         "‚ú® feat: implement MODEXP precompile (EIP-198) with EIP-2565 gas optimization",
         "## Summary\n\n- Implements MODEXP precompile at address 0x05 \n- Full EIP-198 compliance with modular exponentiation\n- EIP-2565 gas calculation optimization\n- Comprehensive test suite with edge cases\n- Gas overflow protection and input validation\n\n## Key Features\n\n- Efficient gas calculation with complexity analysis\n- Proper handling of zero cases (0^0 = 1, base^0 = 1)\n- Input validation and DoS protection\n- Big-endian integer parsing for Ethereum compatibility\n- Comprehensive test coverage including edge cases\n\n## Test Results\n\nAll Zig tests pass ()\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "35039927",
         "roninjin10",
         "closed",
         "2025-06-11T23:40:21Z",
         "2025-06-12T02:24:02Z",
         "2025-06-12T02:24:02Z",
         "601475124",
         "https://api.github.com/repos/evmts/tevm-monorepo",
         "https://github.com/evmts/tevm-monorepo/pull/1847",
         "feat"
        ],
        [
         "14",
         "3141541564",
         "882",
         "Direct FFI Integration for idb_companion",
         "## Summary\n\nThis PR introduces a Direct FFI (Foreign Function Interface) integration as a lightweight alternative to the gRPC-based architecture. This enables direct function calls from Rust to Objective-C with microsecond latency.\n\n## Key Benefits\n\n- **Performance**: 500x faster than gRPC (microseconds vs milliseconds)\n- **Size**: 40x smaller binary (~500KB vs ~20MB)\n- **Simplicity**: No async runtime, no protobuf serialization\n- **Zero dependencies**: Just the Foundation framework\n\n## What's Included\n\n### Core Implementation\n- `idb_direct.h` - C interface definition\n- `idb_direct_simple.m` - Stub implementation for testing\n- `idb_direct.m` - Full implementation (with framework API updates needed)\n- Rust FFI bindings with safe wrappers\n\n### Documentation\n- [Direct FFI Advantages](rust-client-simple/DIRECT_FFI_ADVANTAGES.md)\n- [Implementation Plan](rust-client-simple/DIRECT_FFI_IMPLEMENTATION_PLAN.md)\n- [Embedded Companion Plan](rust-client-simple/EMBEDDED_COMPANION_PLAN.md)\n\n### CI/CD\n- New GitHub workflow for FFI builds\n- Automated artifact packaging\n\n## Testing\n\n```bash\ncd rust-client-simple\ncargo build --features ffi --bin idb-tap-ffi\n./target/debug/idb-tap-ffi\n```\n\n## Current Status\n\n- ‚úÖ FFI interface defined and working\n- ‚úÖ Rust bindings complete\n- ‚úÖ Stub implementation for testing\n- üöß Real implementation needs framework API compatibility fixes\n\n## Next Steps\n\n1. Resolve framework API compatibility issues\n2. Complete real touch event implementation\n3. Add screenshot support\n4. Performance benchmarking vs gRPC\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "40346430",
         "arkavo-com",
         "closed",
         "2025-06-12T20:58:00Z",
         "2025-06-12T20:59:11Z",
         null,
         "41870517",
         "https://api.github.com/repos/facebook/idb",
         "https://github.com/facebook/idb/pull/882",
         "feat"
        ],
        [
         "15",
         "3245346788",
         "195",
         "feat: simplify Node.js runtime with Hono v1.17.0 absolute path support",
         "## Summary\n- Update @hono/node-server from v1.15.0 to v1.17.0 for absolute path support  \n- Simplify Node.js runtime implementation by removing complex relative path calculations\n- Improve code maintainability and eliminate working directory dependencies\n\n## Type of Change\n\nPlease add the appropriate label(s) to this PR and check the relevant box(es):\n\n- [ ] üêõ `bug` - Bug fix (non-breaking change which fixes an issue)\n- [x] ‚ú® `feature` - New feature (non-breaking change which adds functionality)\n- [ ] üí• `breaking` - Breaking change (fix or feature that would cause existing functionality to not work as expected)\n- [ ] üìö `documentation` - Documentation update\n- [x] ‚ö° `performance` - Performance improvement\n- [ ] üî® `refactor` - Code refactoring\n- [ ] üß™ `test` - Adding or updating tests\n- [ ] üîß `chore` - Maintenance, dependencies, tooling\n\n## Changes Made\n\n- **Dependency Update**: Upgraded `@hono/node-server` to v1.17.0 which adds absolute path support\n- **Code Simplification**: Replaced 10 lines of complex relative path calculation with 1 line of absolute path\n- **Import Cleanup**: Removed unused `relative` import from `node:path`\n- **Improved Robustness**: Static file serving no longer depends on working directory\n\n## Before/After Comparison\n\n### Before (10 lines of complex logic)\n```typescript\nconst staticAbsPath = join(__dirname, \"../static\");\nlet staticRelPath = relative(process.cwd(), staticAbsPath);\nif (staticRelPath === \"\") {\n  staticRelPath = \".\";\n}\n```\n\n### After (1 line, simple and clear)\n```typescript\nconst staticPath = join(__dirname, \"../static\");\n```\n\n## Testing\n\n- [x] Tests pass locally (`make test`)\n- [x] Code is formatted (`make format`)\n- [x] Code is linted (`make lint`)\n- [x] Type checking passes (`make typecheck`)\n- [x] All quality checks pass (`make check`)\n- [x] Manual testing performed: Verified static file serving works with absolute paths\n\n## Checklist\n\n- [x] My code follows the project's style guidelines\n- [x] I have performed a self-review of my own code\n- [x] I have commented my code, particularly in hard-to-understand areas\n- [x] I have made corresponding changes to the documentation\n- [x] I have added/updated tests for my changes\n- [x] All tests pass\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "80381",
         "sugyan",
         "closed",
         "2025-07-19T14:33:10Z",
         "2025-07-19T14:41:39Z",
         "2025-07-19T14:41:39Z",
         "999285986",
         "https://api.github.com/repos/sugyan/claude-code-webui",
         "https://github.com/sugyan/claude-code-webui/pull/195",
         "feat"
        ],
        [
         "16",
         "3159415433",
         "83",
         "fix: memory leaks and server stability issues",
         "## Summary\nThis PR addresses critical memory leaks and stability issues in the Zen MCP server that were causing server crashes during heavy usage, requiring frequent reinstallation.\n\n### Fixed Issues\n- **Memory leaks in GeminiModelProvider**: Added bounded token cache with automatic cleanup (max 100 entries, LRU-style cleanup)\n- **Background thread race conditions**: Fixed cleanup worker thread shutdown handling in storage backend\n- **Silent exception swallowing**: Replaced silent exception handling with proper logging in server.py\n\n### Technical Details\n- **Token Cache Management**: Implemented cache size limits, cleanup methods, and performance monitoring\n- **Thread Safety**: Improved background thread lifecycle management with graceful shutdown\n- **Error Visibility**: Enhanced error logging to help diagnose future issues\n\n### Testing\n- ‚úÖ All 583 unit tests pass (100%)\n- ‚úÖ All simulator tests pass\n- ‚úÖ Code quality checks pass (ruff, black, isort)\n- ‚úÖ Memory usage monitoring and cleanup verified\n\nThese changes ensure the MCP server can handle long-running sessions and heavy usage without memory leaks or stability issues.\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "2609417",
         "dsaluja",
         "open",
         "2025-06-19T08:15:56Z",
         null,
         null,
         "998428732",
         "https://api.github.com/repos/BeehiveInnovations/zen-mcp-server",
         "https://github.com/BeehiveInnovations/zen-mcp-server/pull/83",
         "fix"
        ],
        [
         "17",
         "3275149041",
         "1884",
         "N-API Go html-to-markdown",
         "## Summary\n- Replace unstable koffi FFI with robust N-API implementation\n- Add hybrid fallback system: N-API ‚Üí koffi ‚Üí JavaScript\n- Integrate N-API build into Docker and CI pipeline\n\n## Key Features\n- üõ°Ô∏è Memory safe: Eliminates CGO mutex deadlocks and corruption\n- ‚ö° High performance: Direct C++ interface, no FFI overhead\n- üîÑ Thread safe: Built-in N-API thread safety mechanisms\n- üì¶ Zero config: Automatic fallback if modules unavailable\n- üéØ Compatible: Drop-in replacement for existing parseMarkdown()\n\n## Technical Details\n- Go static library with timeout protection (30s)\n- C++ N-API wrapper with sync/async interfaces\n- Multi-stage Docker build for automated compilation\n- Comprehensive test suite and validation scripts\n- Smart module loading with graceful degradation\n\n## Files Added\n- `sharedLibs/go-html-to-md-napi/` - Complete N-API module\n- `validate-html-conversion.js` - Integration test suite\n- Updated Dockerfile with N-API build stage\n- Hybrid html-to-markdown.ts with intelligent fallback\n\n## Migration Path\n1. N-API module loads automatically if available\n2. Falls back to existing koffi implementation\n3. Final fallback to JavaScript TurndownService\n4. Zero breaking changes to existing code\n\nThis resolves the koffi-related runtime panics and provides a stable,\nhigh-performance HTML-to-Markdown conversion system.\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\n    \n<!-- This is an auto-generated description by cubic. -->\n---\n\n## Summary by cubic\nReplaced the unstable koffi FFI HTML-to-Markdown integration with a new N-API Go module, adding a hybrid fallback system (N-API ‚Üí koffi ‚Üí JavaScript) and updating the Docker and CI build to support the new module.\n\n- **New Features**\n  - Added a memory-safe, thread-safe N-API wrapper for the Go HTML-to-Markdown library with both sync and async interfaces.\n  - Automatic fallback to koffi or JavaScript if the N-API module is unavailable.\n  - Integrated N-API build and validation into Docker and CI.\n  - Included a test suite and validation script to ensure conversion reliability.\n\n<!-- End of auto-generated description by cubic. -->\n\n",
         "Claude_Code",
         "66118807",
         "mogery",
         "open",
         "2025-07-29T22:34:55Z",
         null,
         null,
         "787076358",
         "https://api.github.com/repos/mendableai/firecrawl",
         "https://github.com/mendableai/firecrawl/pull/1884",
         "feat"
        ],
        [
         "18",
         "3254647682",
         "59071",
         "skip unnecessary alias-check in collect(::AbstractArray) from copyto\\!",
         "As discussed on Slack with @MasonProtter & @jakobnissen, `collect` currently does a usually cheap - but sometimes expensive - aliasing check (via `unalias`->`mightalias`->`dataid` -> `objectid`) before copying contents over; this check is unnecessary, however, since the source array is newly created and cannot possibly alias the input.\n\nThis PR fixes that by swapping from `copyto\\!` to `copyto_unaliased\\!` in the `_collect_indices` implementations where the swap is straightforward (e.g., it is not so straightforward for the fallback `_collect_indices(indsA, A)`, so I skipped it there).\n\nThis improves the following example substantially:\n```julia\nstruct GarbageVector{N} <: AbstractVector{Int}\n    v :: Vector{Int}\n    garbage :: NTuple{N, Int}\nend\nGarbageVector{N}(v::Vector{Int}) where N = GarbageVector{N}(v, ntuple(identity, Val(N)))\nBase.getindex(gv::GarbageVector, i::Int) = gv.v[i]\nBase.size(gv::GarbageVector) = size(gv.v)\n\nusing BenchmarkTools\nv = rand(Int, 10)\ngv = GarbageVector{100}(v)\n@btime collect($v);  # 30 ns (v1.10.4)  -> 30 ns (PR)\n@btime collect($gv); # 179 ns (v1.10.4) -> 30 ns (PR)\n```\n\nRebased version of JuliaLang/julia#55748\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "1814174",
         "ChrisRackauckas",
         "closed",
         "2025-07-23T02:52:46Z",
         "2025-07-23T23:55:54Z",
         null,
         "1644196",
         "https://api.github.com/repos/JuliaLang/julia",
         "https://github.com/JuliaLang/julia/pull/59071",
         "perf"
        ],
        [
         "19",
         "3166199077",
         "60",
         "feat: Phase 7.1 - Basket Asset Performance Tracking",
         "## Summary\n\nThis PR implements Phase 7.1 of the roadmap - Basket Asset Performance Tracking. This adds comprehensive performance analytics for basket assets including returns, volatility, Sharpe ratio, and maximum drawdown calculations.\n\n## What's Changed\n\n### Models & Database\n- Created `BasketPerformance` model to store performance metrics by period\n- Created `ComponentPerformance` model to track individual asset contributions\n- Added database migrations with proper indexes and constraints\n\n### Services\n- Implemented `BasketPerformanceService` for calculating performance metrics:\n  - Returns (absolute and percentage)\n  - Volatility (standard deviation of returns)\n  - Sharpe ratio (risk-adjusted returns)\n  - Maximum drawdown\n  - Component attribution analysis\n- Added support for multiple time periods (hour, day, week, month, quarter, year)\n\n### API Endpoints\n- `GET /api/v2/baskets/{code}/performance` - Get current performance\n- `GET /api/v2/baskets/{code}/performance/history` - Historical performance data\n- `GET /api/v2/baskets/{code}/performance/summary` - Performance summary\n- `GET /api/v2/baskets/{code}/performance/components` - Component breakdown\n- `GET /api/v2/baskets/{code}/performance/top-performers` - Best performing components\n- `GET /api/v2/baskets/{code}/performance/worst-performers` - Worst performing components\n- `POST /api/v2/baskets/{code}/performance/calculate` - Calculate performance\n- `GET /api/v2/baskets/{code}/performance/compare` - Compare with other baskets\n\n### Admin Dashboard\n- Added performance widgets to basket asset management\n- Real-time performance charts and metrics\n- Component performance visualization\n\n### Commands & Automation\n- Created `basket:calculate-performance` artisan command\n- Scheduled hourly performance calculations for all active baskets\n\n### Tests\n- Comprehensive test coverage for all new features\n- Performance calculation accuracy tests\n- API endpoint tests\n\n## Technical Notes\n- Performance calculations use industry-standard formulas\n- Sharpe ratio assumes 2% risk-free rate (configurable)\n- All calculations handle edge cases (insufficient data, missing values)\n- Caching implemented for frequently accessed performance data\n\n## Test Plan\n- [x] All unit tests pass\n- [x] All feature tests pass\n- [x] Manual testing of API endpoints\n- [x] Admin dashboard functionality verified\n- [x] Performance calculations validated against expected values\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "5859318",
         "YOzaz",
         "closed",
         "2025-06-22T19:18:39Z",
         "2025-06-23T07:06:14Z",
         "2025-06-23T07:06:14Z",
         "842589907",
         "https://api.github.com/repos/FinAegis/core-banking-prototype-laravel",
         "https://github.com/FinAegis/core-banking-prototype-laravel/pull/60",
         "feat"
        ],
        [
         "20",
         "3212206965",
         "900",
         "feat: add buffer pool for audio conversion",
         "## Summary\r\nThis PR implements a float32 buffer pool for audio conversion operations, targeting the second memory allocation hotspot identified in our profiling analysis.\r\n\r\n## Changes\r\n- Implemented `Float32Pool` using `sync.Pool` for thread-safe buffer reuse\r\n- Modified `convert16BitToFloat32` to use the pool for standard buffer sizes\r\n- Added pool initialization during BirdNET startup\r\n- Implemented proper buffer lifecycle management with return after prediction\r\n- Added comprehensive unit tests, benchmarks, and fuzz tests\r\n- Created documentation explaining the implementation\r\n\r\n## Performance Impact\r\n```\r\nBenchmarkAudioConversionComparison/Original-16     4591    352197 ns/op    581647 B/op    1 allocs/op\r\nBenchmarkAudioConversionComparison/WithPool-16    12958     92816 ns/op        69 B/op    1 allocs/op\r\n```\r\n\r\n### Improvements:\r\n- **Memory allocation**: Reduced by 99.99% (581KB ‚Üí 69 bytes)\r\n- **Performance**: 3.8x faster (352Œºs ‚Üí 93Œºs)\r\n- **Hit rate**: 99.98% in steady state operation\r\n\r\n## Testing\r\n- ‚úÖ Unit tests for pool operations and concurrency\r\n- ‚úÖ Fuzz tests for conversion correctness\r\n- ‚úÖ Benchmarks showing significant improvements\r\n- ‚úÖ All linter issues resolved\r\n\r\n## Design Decisions\r\n1. **Standard size only**: Pool only handles standard 3-second buffers (144,384 samples)\r\n2. **Early return**: Buffers returned immediately after BirdNET prediction\r\n3. **Graceful fallback**: Non-standard sizes allocate normally\r\n4. **No clearing**: Audio data doesn't require security clearing\r\n\r\nü§ñ Generated with [Claude Code](https://claude.ai/code)\r\n\r\nCo-Authored-By: Claude <noreply@anthropic.com>\r\n\r\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n## Summary by CodeRabbit\n\n* **New Features**\n  * Introduced an optimized float32 buffer pool to improve memory efficiency during audio processing.\n  * Added automatic reuse of float32 buffers for 16-bit audio conversions, reducing memory allocations and potential garbage collection pauses.\n\n* **Documentation**\n  * Added detailed documentation on the float32 buffer pool, including usage, performance benefits, and integration details.\n\n* **Tests**\n  * Added comprehensive unit, fuzz, and benchmark tests for audio conversion and buffer pool functionality, covering correctness, performance, and concurrency scenarios.\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
         "Claude_Code",
         "7030001",
         "tphakala",
         "closed",
         "2025-07-08T11:43:33Z",
         "2025-07-08T12:26:54Z",
         "2025-07-08T12:26:54Z",
         "707764474",
         "https://api.github.com/repos/tphakala/birdnet-go",
         "https://github.com/tphakala/birdnet-go/pull/900",
         "feat"
        ],
        [
         "21",
         "3212306696",
         "2307",
         "Fix: Resolve browser multiplication issue in Puppeteer MCP server",
         "## Problem\nThe Puppeteer MCP server was creating multiple Chrome browser instances with each tool call instead of reusing existing instances, leading to resource exhaustion and performance issues.\n\n### Symptoms\n- Chrome process count growing with each Puppeteer tool call\n- System resource exhaustion (memory, CPU)\n- Performance degradation over time\n- Multiple browser windows opening in non-headless mode\n\n## Root Cause\nThe `ensureBrowser()` function had several critical issues:\n1. **Flawed browser restart logic**: New browsers were launched without properly closing existing ones\n2. **No browser health validation**: Dead browser instances were not detected\n3. **Missing process cleanup**: Orphaned Chrome processes accumulated\n4. **Race conditions**: Multiple concurrent tool calls could trigger multiple browser launches\n\n## Solution\nThis PR implements a comprehensive fix with the following improvements:\n\n### 1. Browser Health Monitoring\n- Added `isBrowserHealthy()` function to validate browser connectivity and responsiveness\n- Checks both connection status and ability to retrieve pages with timeout protection\n\n### 2. Launch Concurrency Protection\n- Implemented `browserLaunching` flag to prevent concurrent browser launches\n- Ensures only one browser launch can occur at a time\n- Subsequent calls wait for the launch to complete\n\n### 3. Enhanced Graceful Cleanup\n- Improved browser closing with 5-second timeout protection\n- Falls back to process-level cleanup if graceful close fails\n- Added 500ms delay after cleanup to ensure proper resource release\n\n### 4. Process Signal Handlers\n- Added handlers for SIGINT, SIGTERM, SIGHUP, and uncaught exceptions\n- Ensures proper cleanup on server shutdown\n- Prevents orphaned processes on unexpected exits\n\n### 5. Chrome Process Cleanup\n- Implemented `cleanupChromeProcesses()` to kill orphaned Chrome instances\n- Uses platform-specific commands to ensure cleanup\n- Called on both normal and error paths\n\n## Testing\nTested the fix extensively:\n- ‚úÖ Multiple rapid tool calls (navigate, screenshot, evaluate)\n- ‚úÖ Verified stable browser count (no multiplication)\n- ‚úÖ Tested server restart scenarios\n- ‚úÖ Confirmed backward compatibility\n- ‚úÖ All existing functionality preserved\n\n### Before Fix\n- Started with 6 Chrome processes\n- After 4 tool calls: 15 processes\n- After 7 tool calls: 15+ processes (continuously growing)\n\n### After Fix\n- Stable at 15 processes regardless of tool call count\n- Proper reuse of existing browser instance\n- Clean shutdown with no orphaned processes\n\n## Breaking Changes\nNone - this is a backward-compatible bug fix that maintains all existing APIs and behavior.\n\n## Notes\n- The fix is applied to the TypeScript source in the `archive-servers` branch\n- The compiled JavaScript output has been tested and verified\n- The same issue likely affects the npm-published version of `@modelcontextprotocol/server-puppeteer`\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "144542146",
         "zitrono",
         "closed",
         "2025-07-08T12:13:09Z",
         "2025-07-11T15:06:15Z",
         null,
         "890668799",
         "https://api.github.com/repos/modelcontextprotocol/servers",
         "https://github.com/modelcontextprotocol/servers/pull/2307",
         "fix"
        ],
        [
         "22",
         "3119417980",
         "44",
         "feat: Add includeStackTrace option to reduce LLM token usage by 80-90%",
         "## üö® Problem\n\nAfter implementing pagination (#42), we discovered another critical issue with LLM token consumption when retrieving Unity console logs. **Stack traces alone consume 80-90% of the total tokens**, making it difficult to retrieve and analyze logs efficiently within LLM context windows.\n\n### Real-world Impact\n- A single error log with stack trace: ~500-1000 tokens\n- The same log without stack trace: ~50-100 tokens  \n- **Result**: 10x reduction in token usage\n\nThis becomes especially problematic when:\n- Debugging across multiple log entries\n- Working with limited context windows\n- Analyzing patterns across many logs\n- Quick log overview is needed before deep debugging\n\n## ‚ö° Solution\n\n### New `includeStackTrace` Parameter\n\nAdded an optional boolean parameter to control stack trace inclusion:\n\n```typescript\n// Quick overview - saves 80-90% tokens\nget_console_logs({ \n  includeStackTrace: false,\n  limit: 50 \n})\n\n// Detailed debugging - includes stack traces\nget_console_logs({ \n  logType: \"error\",\n  includeStackTrace: true,\n  limit: 10\n})\n```\n\n### Smart Defaults\n- **Default**: `true` for backward compatibility\n- **Exception**: Info logs via resource default to `false` (stack traces rarely needed)\n\n### LLM-Friendly Documentation\n\nAdded clear hints with ‚ö†Ô∏è emoji to guide LLMs:\n```\n\"Whether to include stack trace in logs. ‚ö†Ô∏è ALWAYS SET TO FALSE to save 80-90% tokens, unless you specifically need stack traces for debugging.\"\n```\n\n## üìä Results\n\n### Token Usage Comparison\n\n| Log Type | With Stack Trace | Without Stack Trace | Reduction |\n|----------|------------------|---------------------|-----------|\n| Error    | ~800 tokens      | ~80 tokens          | 90%       |\n| Warning  | ~600 tokens      | ~60 tokens          | 90%       |\n| Info     | ~500 tokens      | ~50 tokens          | 90%       |\n\n### Recommended Workflow\n1. **Initial Investigation**: Use `includeStackTrace: false` for quick overview\n2. **Identify Issues**: Find problematic logs with minimal token usage\n3. **Deep Dive**: Re-query specific errors with `includeStackTrace: true` only when needed\n\n## üß™ Testing with Claude Code\n\n**This feature was extensively tested with Claude Code (claude.ai/code)**, which is how we discovered the token consumption issue and validated the solution.\n\n### Test Environment\n- **LLM**: Claude Code with Anthropic's official CLI\n- **Unity Version**: Unity 2022.3 and Unity 6\n- **Test Project**: Active Unity game development project\n\n### Claude Code Test Results\n```typescript\n// Test 1: Before implementation - Token limit exceeded\n// Claude Code context window quickly filled with stack traces\n\n// Test 2: After implementation - Successful analysis\n// Claude Code could analyze 100+ logs without hitting token limits\n\n// Real conversation with Claude Code:\nUser: \"get shader error by using tool\"\nClaude: *uses get_console_logs with includeStackTrace: false*\n// Successfully retrieved and analyzed errors within token limits\n```\n\n### Why Claude Code Testing Matters\n- **Real-world LLM constraints**: Tested against actual token limits\n- **Practical workflows**: Validated the natural debugging flow\n- **Immediate feedback**: Claude Code's responses confirmed token savings\n- **User experience**: Smooth interaction without \"token exceeded\" errors\n\n## üìã Technical Details\n\n### Unity Side Changes\n- `ConsoleLogsService.cs`: Added conditional stack trace inclusion\n- `IConsoleLogsService.cs`: Updated interface signature\n- `GetConsoleLogsResource.cs`: Added `includeStackTrace` parameter handling\n\n### Node.js Side Changes  \n- `getConsoleLogsTool.ts`: Added parameter to Zod schema with detailed description\n- `getConsoleLogsResource.ts`: Extended URL template and parameter extraction\n\n### Key Implementation Details\n- **Backward Compatible**: Defaults to `true` to maintain existing behavior\n- **Flexible Control**: Can be set per request based on debugging needs\n- **Memory Efficient**: No additional memory overhead (filtering only)\n- **Clear Documentation**: LLM-optimized descriptions guide proper usage\n\n## üîç Why This Matters\n\n### For LLM-based Development Tools (like Claude Code)\n- **More Context**: Can analyze 10x more logs within token limits\n- **Faster Iteration**: Quick overview before detailed investigation\n- **Better UX**: Reduced \"token limit exceeded\" errors\n- **Natural Workflow**: Matches how developers actually debug\n\n### For Developers Using MCP Unity\n- **Efficient Debugging**: Start broad, then narrow down\n- **Cost Savings**: Reduced API token consumption\n- **Improved Workflow**: Natural progression from overview to details\n\n### Use Case Examples (from Claude Code testing)\n\n1. **Quick Health Check**\n   ```typescript\n   // See last 100 logs without overwhelming context\n   get_console_logs({ includeStackTrace: false, limit: 100 })\n   ```\n\n2. **Shader Error Investigation** (actual test case)\n   ```typescript\n   // First: Find shader compilation errors\n   get_console_logs({ logType: \"error\", includeStackTrace: false, limit: 20 })\n   // Found: \"Shader error in 'Custom/MaskedTransparency'\"\n   \n   // Then: Get details if needed\n   get_console_logs({ logType: \"error\", includeStackTrace: true, limit: 5 })\n   ```\n\n3. **Pattern Analysis**\n   ```typescript\n   // Analyze warning patterns across many entries\n   get_console_logs({ logType: \"warning\", includeStackTrace: false, limit: 50 })\n   ```\n\n## Breaking Changes\n\n**None** - Fully backward compatible. Existing code continues to work unchanged.\n\n## Future Considerations\n\nThis implementation opens possibilities for:\n- Selective stack trace inclusion (e.g., first N lines only)  \n- Compressed stack trace formats\n- Smart stack trace summarization\n\nHowever, the current boolean approach provides immediate value with minimal complexity.\n\n## Summary\n\nThis PR addresses a critical usability issue discovered through real-world usage with Claude Code. By adding a simple `includeStackTrace` parameter, we enable LLM-based tools to work effectively with Unity console logs without constantly hitting token limits. The 80-90% reduction in token usage transforms the debugging experience from frustrating to smooth.\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "27694",
         "Saqoosha",
         "closed",
         "2025-06-04T23:56:12Z",
         "2025-06-05T08:41:19Z",
         "2025-06-05T08:41:19Z",
         "948148972",
         "https://api.github.com/repos/CoderGamester/mcp-unity",
         "https://github.com/CoderGamester/mcp-unity/pull/44",
         "feat"
        ],
        [
         "23",
         "3124293906",
         "107",
         "feat: Add --preplanned flag to use existing plan files",
         "Implements the --preplanned flag requested in issue #78, providing a cleaner\r\nalternative to PR #95 that better handles multi-directory workflows.\r\n\r\n## Key features:\r\n\r\n- **--preplanned** flag with **--preplanned-file** option (default: tfplan.bin)\r\n- **Multi-directory support**: Each directory uses its own plan file\r\n- **Auto-detection**: .json extension = direct read, otherwise use terraform show\r\n- **All-or-nothing validation**: All directories must have plan files\r\n- **Performance benefit**: Skip expensive terraform plan operations\r\n- **Enterprise-friendly**: Works with remote state and complex setups\r\n\r\n## Usage examples:\r\n\r\n```bash\r\n# Single directory with default filename\r\nterraform plan -out=tfplan.bin\r\ntfautomv --preplanned\r\n\r\n# Multiple directories\r\n(cd dir1 && terraform plan -out=tfplan.bin)\r\n(cd dir2 && terraform plan -out=tfplan.bin)\r\ntfautomv --preplanned dir1 dir2\r\n\r\n# Custom filename\r\nterraform plan -out=my-plan.bin\r\ntfautomv --preplanned --preplanned-file=my-plan.bin\r\n\r\n# JSON plans (pre-converted)\r\nterraform plan -out=tfplan.bin\r\nterraform show -json tfplan.bin > tfplan.json\r\ntfautomv --preplanned --preplanned-file=tfplan.json\r\n```\r\n\r\n## Implementation details:\r\n\r\n- New `GetPlanFromFile()` function in terraform package\r\n- Concurrent plan file reading (same pattern as existing `getPlans()`)\r\n- Clear error messages for missing files or validation failures\r\n- Comprehensive test coverage including 4 new e2e tests\r\n- Full documentation with examples for all use cases\r\n\r\n## Credit\r\n\r\nThis builds on the pioneering work by @atthematyo in PR #95, who first explored implementing plan file support and identified the key use cases. Thank you for the valuable contribution that helped shape this feature\\!\r\n\r\nAddresses issue #78.\r\n\r\nü§ñ Generated with [Claude Code](https://claude.ai/code)\r\n\r\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "22616578",
         "busser",
         "closed",
         "2025-06-06T10:02:14Z",
         "2025-06-06T10:21:59Z",
         "2025-06-06T10:21:58Z",
         "482225540",
         "https://api.github.com/repos/busser/tfautomv",
         "https://github.com/busser/tfautomv/pull/107",
         "feat"
        ],
        [
         "24",
         "3124595999",
         "388",
         "Add Python stub file generation with documentation parsing",
         "### Summary\n\nThis PR adds comprehensive Python stub file (.pyi) generation for the LVGL MicroPython bindings, providing full IDE support with autocompletion, type hints, and rich documentation.\n\n**Key Features:**\n- üöÄ **Fast Parallel Processing**: 6 seconds vs. minutes (uses all CPU cores)\n- üìù **Rich Documentation**: Automatic extraction from 1400+ LVGL functions  \n- üéØ **IDE Integration**: Full autocompletion and type hints (.pyi files)\n- ‚ö° **Separate Build**: Doesn't slow down main MicroPython builds\n- üîß **Smart Formatting**: Bullet points, text wrapping, proper Python conventions\n- üîó **Source Navigation**: File:line references to original C implementation\n\nThe implementation includes:\n1. **Stub Generation**: Creates `.pyi` files with proper Python type hints\n2. **Documentation Parsing**: Extracts Doxygen comments from C headers using parallel processing\n3. **Smart Parameter Handling**: Converts `obj` to `self` for class methods\n4. **Performance Optimization**: Processes 209 header files in ~6 seconds using all CPU cores\n5. **Source References**: Adds file:line references for navigation to C implementation\n\n### Testing\n\nTested on Unix port with full stub generation:\n- Processes 209 LVGL header files using parallel processing\n- Extracts documentation from 1423 functions\n- Generates type hints for 41 widget classes and 64 enums\n- Produces comprehensive `.pyi` files for IDE consumption\n\nThe generated stubs provide full autocompletion and documentation in modern Python IDEs like VS Code, PyCharm, etc.\n\n### Trade-offs and Alternatives\n\n**Trade-offs:**\n- Adds ~6 seconds to generate full documentation (but as separate optional target)\n- Increases repository size slightly with documentation files\n\n**Alternatives considered:**\n- External documentation parsing libraries (rejected to minimize dependencies)\n- Manual stub file maintenance (rejected due to maintenance burden)\n- No documentation extraction (rejected as it provides significant developer value)\n\nThe implementation uses custom regex-based Doxygen parsing to avoid external dependencies while providing exactly the functionality needed for LVGL's documentation format.\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "3318786",
         "andrewleech",
         "open",
         "2025-06-06T12:10:03Z",
         null,
         null,
         "167166039",
         "https://api.github.com/repos/lvgl/lv_binding_micropython",
         "https://github.com/lvgl/lv_binding_micropython/pull/388",
         "feat"
        ],
        [
         "25",
         "3235395709",
         "34529",
         "Fix file save blocking on entry refresh for improved hot reload performance",
         "## Summary\n\nFixes file save operations blocking on filesystem entry refresh, which was causing hot reload systems to detect file changes later than other editors like VS Code or Sublime Text.\n\n## Changes\n\nModified `LocalWorktree::write_file` in `crates/worktree/src/worktree.rs` to make the `refresh_entry` call non-blocking by moving it to a background task. The save operation now completes immediately after the file write, with filesystem state refresh happening asynchronously.\n\n## Root Cause\n\nThe issue was in the save flow where:\n1. File gets written to disk (`write.await?`)\n2. Save completion waits for `refresh_entry().await?` to finish\n3. `refresh_entry` sends a scan request to background thread and waits\n4. Only then does the save operation return success\n\nThis blocking behavior delayed the save completion signal that hot reload tools rely on.\n\n## Solution\n\n- Start refresh task without awaiting it\n- Spawn refresh in background with `.detach()`\n- Return success immediately after file write\n- Use existing entry state when available\n\n## Testing\n\nUser reported that the fix resolved the hot reload delay issue after building and testing the changes.\n\n## Related Issue\n\nCloses #34527\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "27272",
         "sausaw",
         "closed",
         "2025-07-16T10:36:19Z",
         "2025-07-16T10:40:17Z",
         null,
         "340547520",
         "https://api.github.com/repos/zed-industries/zed",
         "https://github.com/zed-industries/zed/pull/34529",
         "fix"
        ],
        [
         "26",
         "3269032263",
         "79",
         "Add SIMD optimizations for 23.5% performance improvement",
         "## Summary\n\nThis PR implements comprehensive SIMD optimizations for the probe code search engine, addressing the challenge that **BM25 SIMD wasn't providing expected performance gains due to sparse vector characteristics**. Instead of abandoning SIMD, we pivoted to target string processing operations where SIMD acceleration excels.\n\n### The Journey: From BM25 to String Processing SIMD\n\n**Initial Challenge:** After implementing BM25 SIMD optimizations, we discovered they weren't delivering meaningful performance improvements. The core issue was that BM25 operates on sparse vectors (most terms have zero scores), making vectorized operations less effective than anticipated.\n\n**Strategic Pivot:** Rather than abandon SIMD entirely, we analyzed the codebase to identify workloads that could genuinely benefit from SIMD acceleration. We found that string processing operations - tokenization and pattern matching - were ideal candidates as they process dense character data where SIMD truly shines.\n\n**Implementation Approach:** We implemented two separate architect-driven solutions:\n1. SIMD-accelerated camelCase splitting in tokenization\n2. SIMD-accelerated multi-term pattern matching\n\n**Evolution to Production:** The implementation evolved through several key phases:\n- Initial SIMD tokenization showing 7.2% improvement\n- Integration challenges with parallel processing requiring Arc wrappers\n- Hybrid pattern matching combining SIMD with ripgrep fallbacks\n- Thread safety improvements replacing environment variable manipulation\n- Default-enabled configuration with opt-out flags\n\n### Performance Improvements\n\n#### Detailed Performance Analysis\n\n**Test Environment:**\n- Query: \"yaml workflow agent multi-agent user input\"\n- Target: ~/go/src/semantic-kernel/ (large codebase)\n- Method: Built binaries comparison (cargo build --release)\n\n**Comprehensive Timing Breakdown:**\n\n| Metric | Old Version | New Version (SIMD) | Improvement | Time Saved |\n|--------|-------------|-------------------|-------------|------------|\n| **Total Time** | 1053.97ms | 929.82ms | **11.8%** | **124.15ms** |\n| File Scanning | 24.44ms (2.3%) | 23.63ms (2.5%) | 3.3% | 0.81ms |\n| **Term Matching** | 867.00ms (82.3%) | 719.75ms (77.4%) | **17.0%** | **147.25ms** |\n| AST Parsing | 118.65ms (11.3%) | 139.02ms (14.9%) | -17.2% | -20.37ms |\n| Ranking | 35.42ms (3.4%) | 39.49ms (4.2%) | -11.5% | -4.07ms |\n| Result Formatting | 8.46ms (0.8%) | 7.93ms (0.9%) | 6.3% | 0.53ms |\n\n**Key Insights:**\n- **Massive term matching improvement:** 17.0% faster (147.25ms saved)\n- **Overall performance gain:** 11.8% improvement despite some overhead\n- **Primary bottleneck addressed:** Term matching (82.3% ‚Üí 77.4% of total time)\n\n#### SIMD Tokenization Benchmark\n\n**Simple Query Performance:**\n```\nQuery: \"agent workflow\"\nTarget: ~/go/src/semantic-kernel/\n\nBefore SIMD tokenization: 841.74ms\nAfter SIMD tokenization: 780.90ms\nImprovement: 7.2% (60.84ms faster)\n```\n\n#### Comparative Strategy Analysis\n\n**Hybrid vs Always-SIMD vs Always-Ripgrep Testing:**\n```\nPattern Matching Strategy Comparison:\n‚îú‚îÄ‚îÄ Hybrid (SIMD + Ripgrep): 13.9% improvement (best overall)\n‚îú‚îÄ‚îÄ Always-SIMD: 11.2% improvement  \n‚îî‚îÄ‚îÄ Always-Ripgrep: baseline performance\n\nConclusion: Hybrid approach optimal for diverse pattern complexity\n```\n\n### SIMD Features Implemented\n\n#### 1. SIMD-Accelerated Tokenization (`src/search/simd_tokenization.rs`)\n- Fast camelCase boundary detection using character classification tables\n- SIMD-accelerated ASCII character processing with 256-element lookup table\n- Smart fallback to scalar implementation for Unicode or complex patterns like OAuth2, XML, HTTP\n- Thread-safe configuration system replacing environment variable manipulation\n- Handles complex patterns: `XMLHttpRequest` ‚Üí `[\"xml\", \"http\", \"request\"]`\n\n#### 2. SIMD Pattern Matching (`src/search/simd_pattern_matching.rs`)\n- Multi-pattern string matching using memchr and aho-corasick\n- **Hybrid Intelligence:** Automatically detects pattern complexity and chooses optimal strategy:\n  - SIMD for simple literal patterns (faster)\n  - Ripgrep for complex regex patterns (maintains compatibility)\n- Pattern complexity analysis checks for regex metacharacters like `\\b`, `(?i)`\n- Seamless integration with existing search pipeline\n\n#### 3. Enhanced SIMD Ranking (`src/search/result_ranking.rs`)\n- Element-wise SIMD multiplication for BM25 scoring using SimSIMD\n- Optimized sparse-to-dense vector conversion reducing memory allocations\n- Memory allocation optimization for better cache performance\n- Thread-safe configuration without environment variable races\n\n### Architecture Improvements & Problem Solving\n\n#### Thread Safety Crisis & Resolution\n**Problem:** Initial implementation used `std::env::set_var()` for recursive call prevention, causing thread safety issues in concurrent scenarios.\n\n**Solution:** Implemented `SimdConfig` struct with explicit configuration passing:\n```rust\npub struct SimdConfig {\n    pub simd_enabled: bool,\n    pub in_recursive_call: bool,\n}\n```\nThis eliminated all environment variable manipulation and race conditions.\n\n#### Merge Strategy Evolution\n**Challenge:** Rebasing the feature branch on main created complex merge conflicts.\n\n**Resolution:** Switched from rebase to merge strategy, which provided cleaner conflict resolution. Used a specialized agent to handle complex `search_runner.rs` conflicts, resulting in the optimal hybrid SIMD/ripgrep implementation.\n\n#### C# Language Support Fix\n**Issue Discovered:** During benchmarking, found that C# files were showing \"unknown\" language.\n\n**Root Cause:** Missing C# mapping in formatter and tree-sitter compatibility issue.\n\n**Fix:** Added proper C# language detection and fixed unsafe transmute operations.\n\n### Technical Deep Dive\n\n#### Character Classification Table Optimization\n```rust\n// SIMD lookup table for fast ASCII character classification\nstatic CHAR_CLASS_TABLE: [u8; 256] = [\n    // Each byte: bit 0 = uppercase, bit 1 = lowercase, bit 2 = digit\n    // Enables SIMD boundary detection in single table lookup\n];\n```\n\n#### Hybrid Pattern Selection Logic\n```rust\nlet use_simd = crate::search::simd_pattern_matching::is_simd_pattern_matching_enabled()\n    && pattern_strings.iter().all(|p| \\!p.contains(r\"\\b\") && \\!p.contains(\"(?i)\"));\n```\n\n#### Configuration System Design\n- **Default Behavior:** SIMD enabled by default for maximum performance\n- **Opt-out Flags:** `DISABLE_SIMD_TOKENIZATION=1`, `DISABLE_SIMD_PATTERN_MATCHING=1`, `DISABLE_SIMD_RANKING=1`\n- **Graceful Fallback:** Automatic detection of SIMD capability and intelligent degradation\n\n### Dependencies & Integration\n\n**New Dependencies:**\n- `memchr = \"2.7\"` - SIMD-accelerated string searching (used by ripgrep internally)\n- `wide = \"0.7\"` - SIMD vector operations for character classification\n- `aho-corasick = \"1.1\"` - Multi-pattern string matching with SIMD acceleration\n\n**Integration Points:**\n- Seamless integration with existing tokenization pipeline\n- Backward-compatible API with configuration parameter addition\n- Zero breaking changes to public interfaces\n\n### Quality Assurance & Testing\n\n#### Comprehensive Test Coverage\n- **Equivalence Testing:** SIMD results must match scalar implementations exactly\n- **Thread Safety Testing:** Concurrent execution with different configurations\n- **Complex Pattern Testing:** XMLHttpRequest, OAuth2Provider, parseJSON2HTML5\n- **Performance Regression Testing:** Automated benchmarking against baseline\n\n#### Error Resolution Journey\n- **Character table size mismatch:** Fixed 257‚Üí256 element array\n- **Private function access:** Resolved import scope issues\n- **Type mismatches:** Fixed f64‚Üíf32 conversions for SimSIMD\n- **Merge conflicts:** Strategic resolution preserving both SIMD and ripgrep benefits\n- **Test failures:** Fixed boundary detection for complex camelCase patterns\n\n### Production Readiness\n\n#### Backward Compatibility\n- Full backward compatibility maintained\n- Graceful degradation on platforms without SIMD support\n- No breaking changes to public APIs\n- Existing tests pass with SIMD optimizations enabled\n\n#### Performance Validation\n- **Real-world Testing:** Benchmarks against actual codebases (semantic-kernel)\n- **Multiple Query Types:** Both simple and complex query patterns tested\n- **Consistent Improvements:** 7.2% to 17.0% improvements across different scenarios\n\n### Future Implications\n\nThis implementation demonstrates that **strategic SIMD application** yields better results than broad SIMD adoption. By focusing on string processing operations where SIMD naturally excels, we achieved significant performance improvements while maintaining code clarity and reliability.\n\nThe hybrid approach preserves the benefits of both worlds: SIMD speed for simple operations and ripgrep's sophisticated regex engine for complex patterns.\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "14009",
         "buger",
         "closed",
         "2025-07-28T09:35:31Z",
         "2025-07-28T13:49:09Z",
         "2025-07-28T13:49:09Z",
         "943383028",
         "https://api.github.com/repos/buger/probe",
         "https://github.com/buger/probe/pull/79",
         "feat"
        ],
        [
         "27",
         "2905716327",
         "9027",
         "refactor(twap): implement strategy pattern for accumulator updates",
         "This commit refactors the TWAP module to use the strategy pattern more thoroughly for its accumulator updates. Previously, the strategy pattern was only used for TWAP computation but not for the accumulator updates.\r\n\r\nKey changes:\r\n- Add `updateAccumulators` method to the twapStrategy interface\r\n- Implement strategy-specific accumulator update logic for both arithmetic and geometric strategies\r\n- Modify `getInterpolatedRecord` to use the provided strategy's accumulator update method\r\n- Update remaining code to use the appropriate strategy for accumulator updates\r\n- Maintain backward compatibility in exported functions and existing code paths\r\n\r\nWith this change, geometric accumulator calculations are now only performed when using the geometric strategy, making the system more efficient by avoiding unnecessary calculations for the arithmetic strategy.\r\n\r\nü§ñ Generated with [Claude Code](https://claude.ai/code)\r\nCo-Authored-By: Claude <noreply@anthropic.com>\r\n\r\nCloses: #7113 ",
         "Claude_Code",
         "6440154",
         "ValarDragon",
         "closed",
         "2025-03-09T22:29:23Z",
         "2025-03-21T00:03:05Z",
         null,
         "304841810",
         "https://api.github.com/repos/osmosis-labs/osmosis",
         "https://github.com/osmosis-labs/osmosis/pull/9027",
         "refactor"
        ],
        [
         "28",
         "2912546402",
         "448",
         "Add GitHub API caching to prevent rate limiting",
         "- Create GitHub API caching script that handles authenticated and unauthenticated requests\r\n- Update Dockerfile to include the script in the container\r\n- Update init-firewall.sh to use cached GitHub API data\r\n- Modify devcontainer.json to run cache script before build and mount cache directory\r\n\r\nü§ñ Generated with [Claude Code](https://claude.ai/code)\r\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "1021104",
         "8enmann",
         "closed",
         "2025-03-12T03:51:34Z",
         "2025-05-06T17:50:00Z",
         null,
         "937253475",
         "https://api.github.com/repos/anthropics/claude-code",
         "https://github.com/anthropics/claude-code/pull/448",
         "feat"
        ],
        [
         "29",
         "3241840766",
         "147",
         "feat: Add support for multiple tool calls in a single message",
         "## Description\n<\\!-- Provide a brief description of the changes in this PR -->\n\nThis PR adds support for executing multiple tool calls within a single message, significantly improving efficiency for tool-based environments and agent workflows. Agents can now make multiple tool calls in one turn instead of requiring separate round-trips for each tool.\n\n## Type of Change\n<\\!-- Mark the relevant option with an \"x\" -->\n- [ ] Bug fix (non-breaking change which fixes an issue)\n- [x] New feature (non-breaking change which adds functionality)\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\n- [ ] Documentation update\n- [x] Test improvement\n\n## Testing\n<\\!-- Describe the tests you ran to verify your changes -->\n- [x] All existing tests pass\n- [x] New tests have been added to cover the changes\n- [x] Tests have been run locally with `python -m pytest tests/`\n\n### Test Coverage\n<\\!-- If applicable, mention the test coverage for new code -->\n- Current coverage: 100% for new functionality\n- Coverage after changes: Comprehensive edge case coverage including error handling, malformed input, and performance scenarios\n\n## Checklist\n- [x] My code follows the style guidelines of this project\n- [x] I have performed a self-review of my own code\n- [ ] I have commented my code, particularly in hard-to-understand areas\n- [ ] I have made corresponding changes to the documentation\n- [x] My changes generate no new warnings (tested with `-W error` flags and manual verification)\n- [x] Any dependent changes have been merged and published\n\n## Additional Notes\n<\\!-- Add any additional notes, screenshots, or context about the PR here -->\n\n### Key Features\n- **Multiple tool execution**: Parse and execute multiple `<tool>` tags in one message\n- **Backward compatibility**: Single tool calls work exactly as before (no breaking changes)\n- **Error resilience**: If one tool fails, others continue executing\n- **Smart formatting**: Multiple results labeled with tool names for clarity\n\n### Error Handling Details\nWhen one tool fails among multiple tools:\n1. **Execution continues**: Remaining tools are still executed sequentially\n2. **Error isolation**: Failed tool returns error message, but doesn't stop processing\n3. **Complete results**: All results (successful and failed) are included in the response\n4. **Clear identification**: Each tool result is labeled with the actual tool name\n\nExample behavior with mixed success/failure:\n```\nadd_tool result:\n15\n\ninvalid_tool result:\nError: Unknown tool 'invalid_tool'. Please format your tool call as...\n\nsearch_tool result:\nFound results for: example query\n```\n\n### Technical Implementation\n- Added `XMLParser.parse_all()` method using `re.findall()` for multiple tag extraction\n- Enhanced `ToolEnv.env_response()` to handle sequential tool execution with per-tool error handling\n- Tool results labeled with actual tool names (e.g., \"add_tool result:\" vs \"Tool 1 result:\")\n- Maintains state consistency through sequential execution\n- Comprehensive error handling for mixed valid/invalid tool scenarios\n\n### Usage Example\n```xml\n<think>I need to use multiple tools efficiently</think>\n<tool>{\"name\": \"search_tool\", \"args\": {\"query\": \"example\"}}</tool>\n<tool>{\"name\": \"calculate_tool\", \"args\": {\"a\": 5, \"b\": 10}}</tool>\n<tool>{\"name\": \"format_tool\", \"args\": {\"text\": \"result\"}}</tool>\n```\n\nResults in:\n```\nsearch_tool result:\nSearch results for example\n\ncalculate_tool result:\n15\n\nformat_tool result:\nFormatted: RESULT\n```\n\n### Performance\nTested with 15+ concurrent tool calls with no performance degradation. Sequential execution ensures tool state consistency while providing significant efficiency gains for agent workflows.\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "6443210",
         "PastaPastaPasta",
         "open",
         "2025-07-18T04:47:18Z",
         null,
         null,
         "920603619",
         "https://api.github.com/repos/willccbb/verifiers",
         "https://github.com/willccbb/verifiers/pull/147",
         "feat"
        ],
        [
         "30",
         "3226043406",
         "4902",
         "feat: lazy load CLI command actions for improved startup performance",
         "## Summary\n\nThis PR implements lazy loading for CLI command actions as outlined in TODO.md, resulting in a **15.7% overall improvement** in CLI startup performance.\n\n### Key Changes:\n- Separated command registration (lightweight) from action execution (heavyweight)\n- Applied dynamic imports for all command actions\n- Optimized checkNodeVersion to remove heavy imports\n- Kept main.ts completely unchanged as required\n\n## Performance Results\n\n### Overall Performance\n- **Main branch average:** 971.84ms\n- **Feature branch average:** 819.00ms\n- **Improvement:** 152.84ms (15.7% faster)\n\n### Top 5 Most Improved Commands\n\n| Command | Main (ms) | Feature (ms) | Improvement (ms) | % Faster |\n|---------|-----------|--------------|------------------|----------|\n| validate | 988.45 | 820.17 | 168.28 | 17.0% |\n| init | 998.59 | 831.59 | 167.00 | 16.7% |\n| export | 991.45 | 826.09 | 165.36 | 16.7% |\n| show | 990.22 | 826.54 | 163.68 | 16.5% |\n| share | 985.84 | 823.22 | 162.62 | 16.5% |\n\n### All Commands Performance Comparison\n\n| Command | Main (ms) | Feature (ms) | Improvement (ms) |\n|---------|-----------|--------------|------------------|\n| help | 950.48 | 803.65 | 146.83 |\n| eval | 965.16 | 812.03 | 153.13 |\n| eval help | 962.44 | 809.09 | 153.35 |\n| init | 998.59 | 831.59 | 167.00 |\n| view | 961.37 | 807.18 | 154.19 |\n| list | 965.70 | 809.64 | 156.06 |\n| show | 990.22 | 826.54 | 163.68 |\n| auth login | 965.89 | 806.39 | 159.50 |\n| auth logout | 965.12 | 808.45 | 156.67 |\n| auth whoami | 960.51 | 808.14 | 152.37 |\n| cache clear | 973.60 | 822.12 | 151.48 |\n| config show | 967.38 | 812.36 | 155.02 |\n| delete | 963.28 | 810.41 | 152.87 |\n| export | 991.45 | 826.09 | 165.36 |\n| import | 959.79 | 809.01 | 150.78 |\n| share | 985.84 | 823.22 | 162.62 |\n| validate | 988.45 | 820.17 | 168.28 |\n| debug | 969.55 | 819.36 | 150.19 |\n| model-scan | 975.96 | 823.60 | 152.36 |\n| generate dataset | 989.25 | 833.66 | 155.59 |\n| generate assertions | 980.55 | 827.68 | 152.87 |\n\n## Commands Refactored\n\n- ‚úÖ eval\n- ‚úÖ init  \n- ‚úÖ view\n- ‚úÖ generate (dataset, assertions)\n- ‚úÖ share\n- ‚úÖ show\n- ‚úÖ list\n- ‚úÖ cache\n- ‚úÖ config\n- ‚úÖ auth\n- ‚úÖ delete\n- ‚úÖ export\n- ‚úÖ import\n- ‚úÖ validate\n- ‚úÖ debug\n- ‚úÖ modelScan\n\n## Testing\n\nAll CI checks pass:\n- ‚úÖ Build\n- ‚úÖ Lint\n- ‚úÖ Format\n- ‚úÖ Tests\n- ‚úÖ Circular dependencies check\n- ‚úÖ Python tests\n- ‚úÖ Integration tests\n\n## Breaking Changes\n\nNone - all changes are internal optimizations that maintain the same external API.\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "7235481",
         "mldangelo",
         "open",
         "2025-07-13T02:47:49Z",
         null,
         null,
         "633927609",
         "https://api.github.com/repos/promptfoo/promptfoo",
         "https://github.com/promptfoo/promptfoo/pull/4902",
         "feat"
        ],
        [
         "31",
         "3226627949",
         "94",
         "feat(cpu-threading): integrate CLI with threading system and unify TTS API",
         "## Summary\n- **üî• Major Update**: Integrates CLI modes with CPU-specific ONNX Runtime threading optimization\n- Unifies TTS API architecture by removing dual constructor patterns  \n- Implements comprehensive logging system with flexible output destinations\n- Adds chunking boundary safety fix and global CLI speed parameter support\n- Updates documentation with latest benchmark data and enhanced configuration options\n\n## Key Changes\n\n### CLI Threading Integration ‚≠ê\n- **CLI modes now leverage CPU threading optimizations** for optimal performance\n- CLI automatically uses single instance with intelligent CPU threading (ignores `--instances` with informative logging)\n- **API Unification**: Removed old `TTSKoko::new()` method, renamed `new_with_instances` to `new` everywhere\n- All TTS creation now uses unified `TTSKoko::new(path, data, instances)` signature\n- Added \"WIP: to be supported in future\" messaging for CLI parallel processing\n\n### CPU Threading Optimization\n- Detects available CPU cores and calculates optimal thread distribution per instance\n- Prevents memory bandwidth contention through intelligent core allocation\n- Adds comprehensive performance warnings for multiple instances on CPU\n- Implements platform-aware optimizations (CPU vs GPU execution providers)\n\n### Enhanced Logging System\n- **Comprehensive CLI logging options**: `--log cli/file/all/none` with custom `--log-file` paths  \n- **Rich HTTP request/response logging** with timing, headers, and payload tracking\n- Structured logging with request IDs and slow request warnings (>5s)\n- Daily log rotation and non-blocking file appenders\n\n### Performance & Reliability Improvements\n- **Chunking boundary fix**: Prevents index out of bounds in break word processing\n- **Global CLI speed parameter**: `--speed` now properly applies to OpenAI server mode as default\n- **Updated benchmark data**: Latest performance metrics showing 4-instance optimal at 13.7s total time\n- **CoreML context**: Documents node limitation issues causing CPU fallback on Apple Silicon\n\n### Documentation Updates\n- **July 15th release entry** highlighting CLI optimization and enhanced logging  \n- **Logging configuration section** with comprehensive examples\n- **Updated benchmark table** with latest test results (1/2/4/8 instance comparisons)\n- **Enhanced parallel processing notes** reflecting CLI integration with threading system\n\n## Performance Results\n| Instances | TTFA | Total Time | Notes |\n|-----------|------|------------|--------|\n| 1 | 1.87s | 25.1s | Optimal for real-time |\n| 2 | 2.15s | 16.0s | Balanced performance |  \n| 4 | 3.56s | 13.7s | **Best throughput** |\n| 8 | 7.73s | 14.7s | Diminishing returns |\n\n## Breaking Changes\n- **API Change**: `TTSKoko::new()` removed, all constructors now require instance count parameter\n- **CLI Behavior**: CLI modes ignore `--instances > 1` with informative logging (WIP message displayed)\n\n## Test Plan\n- [x] Verify CLI threading integration works correctly\n- [x] Test API unification maintains compatibility  \n- [x] Confirm logging options work across all destinations\n- [x] Validate chunking boundary fix prevents crashes\n- [x] Test global speed parameter in OpenAI server mode\n- [x] Verify performance improvements with benchmark testing\n- [x] Confirm documentation accuracy reflects actual changes\n\n## Migration Guide\n```rust\n// Before\nlet tts = TTSKoko::new(&model_path, &data_path).await;\n\n// After  \nlet tts = TTSKoko::new(&model_path, &data_path, 1).await;\n```\n\n## Rationale\nCLI processes text sequentially without chunking logic, making multiple instances counterproductive. Server mode has intelligent chunking that can effectively utilize parallel instances. This change optimizes CLI for immediate use while preserving server scalability.\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "1172235",
         "miteshashar",
         "open",
         "2025-07-13T16:21:50Z",
         null,
         null,
         "915610024",
         "https://api.github.com/repos/lucasjinreal/Kokoros",
         "https://github.com/lucasjinreal/Kokoros/pull/94",
         "feat"
        ],
        [
         "32",
         "2986072834",
         "202",
         "Add customizable PostgreSQL connection pool settings",
         "- Create explicit connection pool with configurable settings\r\n- Use settings for min_size, max_size, and max_idle\r\n- Update documentation with examples\r\n- Add to README feature list\r\n\r\nü§ñ Generated with [Claude Code](https://claude.ai/code)\r\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "8251002",
         "JoshuaC215",
         "closed",
         "2025-04-10T15:28:26Z",
         "2025-04-11T05:02:46Z",
         "2025-04-11T05:02:46Z",
         "838093526",
         "https://api.github.com/repos/JoshuaC215/agent-service-toolkit",
         "https://github.com/JoshuaC215/agent-service-toolkit/pull/202",
         "feat"
        ],
        [
         "33",
         "3255598859",
         "32771",
         "chore(ci): Make the core CICD workflows failfast (#32768)",
         "## Summary\r\n\r\nImplements fail-fast behavior in dotCMS core CI/CD workflows to provide immediate feedback when tests fail and optimize resource usage. This change transforms the pipeline from running all tests regardless of failures to stopping immediately on first failure.\r\n\r\n## Key Changes\r\n\r\n### üöÄ **Fail-Fast Strategy Implementation**\r\n- **Modified**: `.github/workflows/cicd_comp_test-phase.yml`\r\n  - Changed test matrix strategy from `fail-fast: false` to `fail-fast: true`\r\n  - Replaced static test suite definitions with dynamic matrix generation\r\n  - Implemented two-job architecture: `setup-matrix` ‚Üí `test-matrix`\r\n\r\n### üìã **Centralized Test Configuration**\r\n- **Added**: `.github/test-matrix.yml` (156 lines)\r\n  - Single source of truth for all test configurations\r\n  - Global defaults (timeout, runner, Maven options)\r\n  - Test type specifications for:\r\n    - Integration tests (6 suites: MainSuite 1a/1b, 2a/2b, 3a, Junit5Suite1)\r\n    - Postman tests (11 collections including AI, content-types, graphql, etc.)\r\n    - Karate tests\r\n    - E2E tests (2 suites: core, edit-content)\r\n\r\n### üîß **Technical Implementation**\r\n- Dynamic matrix generation using `mikefarah/yq@v4.47.1` for YAML parsing\r\n- JavaScript-based configuration processing\r\n- Proper combination of `base_maven_args` with suite-specific arguments\r\n- Support for different test parameter patterns across test types\r\n\r\n## Impact\r\n\r\n### Before (fail-fast: false)\r\n- Integration tests would all run even if MainSuite 1a failed\r\n- Postman collections continued executing after failures\r\n- E2E tests ran to completion regardless of earlier failures\r\n- **Result**: Slower feedback (30+ min), wasted resources, harder debugging\r\n\r\n### After (fail-fast: true)  \r\n- **Immediate cancellation** of all parallel tests when any test fails\r\n- **Faster feedback** for developers (5-10 min to failure detection)\r\n- **Resource savings** by not running unnecessary tests\r\n- **Clear failure signals** for easier root cause identification\r\n\r\n## Workflows Affected\r\n\r\nThis change improves all main CI/CD workflows:\r\n- ‚úÖ `cicd_1-pr.yml` - Pull Request validation\r\n- ‚úÖ `cicd_2-merge-queue.yml` - Merge queue processing\r\n- ‚úÖ `cicd_3-trunk.yml` - Trunk/main branch builds\r\n- ‚úÖ `cicd_4-nightly.yml` - Nightly builds  \r\n- ‚úÖ `cicd_5-lts.yml` - LTS releases\r\n\r\n## Test Plan\r\n\r\n- [x] Verify matrix generation produces correct test configurations\r\n- [x] Confirm fail-fast behavior stops tests immediately on failure\r\n- [x] Test all workflow types (PR, merge-queue, trunk, nightly, LTS)\r\n- [x] Validate Maven argument combination logic\r\n- [x] Ensure backward compatibility with existing test suite structure\r\n\r\n## Additional Benefits\r\n\r\n1. **Developer Experience**: Immediate feedback reduces context switching\r\n2. **CI/CD Efficiency**: Optimized resource usage and faster pipeline completion\r\n3. **Maintainability**: Centralized configuration eliminates duplication\r\n4. **Debugging**: Clear failure points improve troubleshooting\r\n5. **Consistency**: Same behavior across all workflow types\r\n\r\nü§ñ Generated with [Claude Code](https://claude.ai/code)\r\n\r\nCo-Authored-By: Claude <noreply@anthropic.com>\n\nThis PR fixes: #32768",
         "Claude_Code",
         "1236198",
         "spbolton",
         "closed",
         "2025-07-23T09:17:05Z",
         "2025-07-24T15:09:39Z",
         "2025-07-24T15:09:39Z",
         "3729629",
         "https://api.github.com/repos/dotCMS/core",
         "https://github.com/dotCMS/core/pull/32771",
         "chore"
        ],
        [
         "34",
         "3256172444",
         "695",
         "feat: Support llm-based message summarization by introducing Transformer mechanism",
         "Design doc: https://www.notion.so/Fast-Model-Summarization-for-Large-Tool-Output-21f18f5dfd9b8045b7faf3368b6bf6ac\r\n\r\n  Summary\r\n\r\n  - Adds transformer architecture for processing tool outputs before LLM consumption\r\n  - Implements llm_summarize transformer using fast secondary models to summarize lengthy outputs\r\n  - Provides global configuration via --fast-model and --summarize-threshold flags\r\n  - Enables tool-level configuration in both YAML and Python toolsets\r\n  - Maintains backward compatibility - existing tools work unchanged\r\n\r\n  Key Features\r\n\r\n  Global Configuration:\r\n  - --fast-model: Optional fast model for summarization (e.g., gpt-4o-mini)\r\n  - --summarize-threshold: Minimum character count to trigger summarization (default: 1000)\r\n\r\n  Tool Integration:\r\n  - YAML tools support transformer_configs with customizable prompts and thresholds\r\n  - Python toolsets can configure transformers during tool initialization\r\n  - Kubernetes toolsets updated with optimized summarization for kubectl commands\r\n\r\n  Smart Behavior:\r\n  - Only processes outputs exceeding the threshold\r\n  - Falls back gracefully when fast model unavailable\r\n  - Preserves searchable keywords and error details in summaries\r\n\r\n  Files Changed\r\n\r\n  - Core Infrastructure: holmes/core/transformers/ - Complete transformer system\r\n  - Configuration: Enhanced holmes/config.py with new global options\r\n  - Tool Integration: Updated toolset manager and execution pipeline\r\n  - Documentation: New docs/transformers.md with comprehensive usage guide\r\n  - Examples: Updated Kubernetes and AKS toolsets with transformer configs\r\n  - Testing: Extensive test coverage (2,000+ new test lines)\r\n\r\n  Benefits\r\n\r\n  - Reduced context usage for large outputs (kubectl, logs, metrics)\r\n  - Improved performance by summarizing before primary LLM processing\r\n  - Cost optimization using fast models for preprocessing\r\n  - Better accuracy by avoiding truncation of important information\r\n\r\n  ü§ñ Generated with https://claude.ai/code\r\n\r\n  Co-Authored-By: Claude noreply@anthropic.com",
         "Claude_Code",
         "36728755",
         "nilo19",
         "open",
         "2025-07-23T12:23:37Z",
         null,
         null,
         "808146034",
         "https://api.github.com/repos/robusta-dev/holmesgpt",
         "https://github.com/robusta-dev/holmesgpt/pull/695",
         "feat"
        ],
        [
         "35",
         "3257102140",
         "4363",
         "Primitives for raw OCaml block access",
         "## Summary\r\n\r\nThis PR extracts the Flambda2 parts of the block indices work from PR #4017 (rtjoa.block-indices). It adds two new primitives that will enable faster field access in unusual use cases, similar to Obj.raw_field but with better performance.\r\n\r\n## Changes\r\n\r\n- **Read_offset**: Binary primitive that reads from a memory location at a given offset\r\n- **Write_offset**: Ternary primitive that writes to a memory location at a given offset\r\n\r\nBoth primitives include:\r\n- Proper type kinds and mutability/allocation mode tracking\r\n- Placeholder CMM translations (add offset to base pointer, then load/store)\r\n- Code size estimates\r\n- Basic simplification support\r\n\r\nThis is a draft PR as these primitives will need user-facing wrappers before they can be used.\r\n\r\nü§ñ Generated with [Claude Code](https://claude.ai/code)\r\n\r\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "1315488",
         "mshinwell",
         "open",
         "2025-07-23T17:03:02Z",
         null,
         null,
         "312271526",
         "https://api.github.com/repos/oxcaml/oxcaml",
         "https://github.com/oxcaml/oxcaml/pull/4363",
         "feat"
        ],
        [
         "36",
         "3193198936",
         "841",
         "feat(telemetry): implement performance testing framework (Phase 8)",
         "## Summary\n\nThis PR implements Phase 8 of the telemetry system migration (#833), focusing on comprehensive performance testing and validation. The primary goal was to ensure the telemetry system has minimal performance impact when disabled (<100ns) while providing robust testing capabilities.\n\n## Key Achievements\n\n### üéØ Performance Goals Met\n- **2.4 nanoseconds** per operation when telemetry is disabled (target: <100ns)\n- **Zero memory allocations** on the disabled path\n- Atomic flag checking optimized to 1.3ns\n\n### üß™ Testing Infrastructure\n- **MockTransport**: Thread-safe Sentry transport implementation for testing\n- **Test Helpers**: Unified testing interface for both `testing.T` and `testing.B`\n- **Integration Tests**: Complete end-to-end telemetry flow validation\n- **Performance Benchmarks**: Comprehensive benchmark suite\n\n## What's Changed\n\n### MockTransport Implementation\n- Implements full `sentry.Transport` interface\n- Thread-safe event capture and retrieval\n- Helper methods for test assertions\n- Support for async event verification\n\n### Test Coverage\n- ‚úÖ Telemetry system unit tests\n- ‚úÖ Integration tests with error package\n- ‚úÖ End-to-end flow tests\n- ‚úÖ Privacy compliance verification\n- ‚úÖ Concurrent operation tests\n- ‚úÖ Performance benchmarks\n\n### Performance Optimizations\n- Atomic flag for fast telemetry state checking\n- Optimized capture functions with early returns\n- Zero-allocation path when disabled\n\n## Performance Results\n\n```\nBenchmarkOptimizedTelemetryDisabled/FastCaptureError-4     496724498    2.423 ns/op    0 B/op    0 allocs/op\nBenchmarkOptimizedTelemetryDisabled/FastCaptureMessage-4   491951907    2.448 ns/op    0 B/op    0 allocs/op\nBenchmarkOptimizedTelemetryDisabled/AtomicCheck-4          897079670    1.346 ns/op    0 B/op    0 allocs/op\n```\n\n## Testing Guidelines\n\n### Using MockTransport\n```go\nconfig, cleanup := telemetry.InitForTesting(t)\ndefer cleanup()\n\n// Your test code here\ntelemetry.CaptureError(err, \"component\")\n\n// Verify\ntelemetry.AssertEventCount(t, config.MockTransport, 1, 100*time.Millisecond)\n```\n\n### Performance Testing\n```go\n// Use optimized functions in production code\nif telemetry.IsTelemetryEnabled() {\n    telemetry.CaptureError(err, component)\n}\n```\n\n## Files Changed\n- `internal/telemetry/mock_transport.go` - MockTransport implementation\n- `internal/telemetry/test_helpers.go` - Testing utilities\n- `internal/telemetry/integration_test.go` - Integration tests\n- `internal/telemetry/e2e_test.go` - End-to-end tests\n- `internal/telemetry/benchmark_test.go` - Performance benchmarks\n- `internal/telemetry/optimized_capture.go` - Performance optimizations\n- `internal/telemetry/optimized_benchmark_test.go` - Optimized benchmarks\n\n## Related Issues\n- Implements Phase 8 of #833\n- Continues work from PR #839 (Phase 7)\n\n## Checklist\n- [x] Tests pass\n- [x] Linter passes\n- [x] Performance targets met\n- [x] Documentation updated\n- [x] No breaking changes\n\n## Next Steps\nPhase 9 will focus on documentation and examples to help developers integrate with the new telemetry system.\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n## Summary by CodeRabbit\n\n* **New Features**\n  * Introduced a mock transport for capturing and inspecting telemetry events in tests.\n  * Added optimized functions for fast telemetry state checks and event capturing.\n  * Provided utilities for initializing and asserting telemetry events in test environments.\n  * Added a recommended asynchronous telemetry worker with rate limiting and circuit breaker for reliable error reporting.\n  * Integrated telemetry state cache updates on settings changes to ensure accurate telemetry enablement status.\n\n* **Tests**\n  * Added comprehensive unit, integration, end-to-end, and benchmark tests for telemetry, including privacy scrubbing, concurrency, and performance scenarios.\n  * Included helpers for verifying event content, count, levels, and tags during testing.\n  * Validated asynchronous and synchronous telemetry error reporting behaviors and non-blocking guarantees.\n<!-- end of auto-generated comment: release notes by coderabbit.ai -->",
         "Claude_Code",
         "7030001",
         "tphakala",
         "closed",
         "2025-07-01T17:00:54Z",
         "2025-07-01T18:11:08Z",
         "2025-07-01T18:11:08Z",
         "707764474",
         "https://api.github.com/repos/tphakala/birdnet-go",
         "https://github.com/tphakala/birdnet-go/pull/841",
         "feat"
        ],
        [
         "37",
         "3128534413",
         "7",
         "Implement Salsa-based incremental compilation",
         "## Summary\nThis PR implements Salsa-based incremental compilation infrastructure for the rue compiler, enabling IDE-friendly incremental updates.\n\n## Changes\n- **Salsa Database Setup**: Added basic `RueDatabase` type alias using Salsa's `DatabaseImpl`\n- **Incremental File Parsing**: Implemented `parse_file` as a Salsa tracked function that automatically caches results\n- **Comprehensive Testing**: Added tests to verify incremental behavior works correctly (caching unchanged results)\n- **API Fixes**: Updated example file to use current API and added `PartialEq` to `ParseError` for Salsa compatibility\n\n## Key Benefits\n- **Fast Recompilation**: Only recomputes changed files and their dependents\n- **IDE Support**: Foundation for Language Server Protocol implementation\n- **Memory Efficient**: Automatic result caching and invalidation\n- **Expression-level Granularity**: Future support for fine-grained incremental computation\n\n## Testing\n- All existing tests continue to pass\n- New incremental compilation tests verify caching behavior\n- Both Buck2 and Cargo builds work correctly\n\n## Architecture\n```rust\n// Salsa input (can be modified)\n#[salsa::input]\npub struct SourceFile { /* path, text */ }\n\n// Salsa tracked function (automatically cached)\n#[salsa::tracked]\npub fn parse_file(db: &dyn Database, file: SourceFile) -> Result<Arc<CstRoot>, Arc<ParseError>>\n\n// Usage - Salsa handles caching automatically\nlet result = parse_file(&db, file);\nfile.set_text(&mut db).to(new_content); // Invalidates cache\nlet new_result = parse_file(&db, file); // Recomputes only if needed\n```\n\n## Next Steps\nThis establishes the foundation for:\n- Semantic analysis queries\n- Type checking\n- Name resolution\n- Code generation\n- LSP implementation\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "27786",
         "steveklabnik",
         "closed",
         "2025-06-08T17:00:06Z",
         "2025-06-08T17:20:43Z",
         "2025-06-08T17:20:43Z",
         "996507585",
         "https://api.github.com/repos/steveklabnik/rue",
         "https://github.com/steveklabnik/rue/pull/7",
         "feat"
        ],
        [
         "38",
         "3221072168",
         "7714",
         "Replace [KnownBuiltin] string-based comparisons with enum-based system",
         "This PR replaces the inefficient string-based `[KnownBuiltin]` identification system with a fast enum-based approach, addressing performance issues and improving type safety throughout the Slang compiler.\n\n## Problem\n\nThe current `KnownBuiltin` attribute system uses string comparisons to identify intrinsic functions:\n\n```cpp\n// Before: Inefficient string comparison\nif (getBuiltinFuncName(callee) != UnownedStringSlice::fromLiteral(\"GeometryStreamAppend\"))\n```\n\nThis approach has several issues:\n- **Performance**: O(n) string comparisons vs O(1) integer comparisons\n- **Type Safety**: No compile-time validation of builtin names\n- **Maintainability**: Magic strings scattered throughout codebase\n\n## Solution\n\nImplemented a centralized enum-based system:\n\n```cpp\n// After: Fast enum comparison  \nif (getBuiltinFuncEnum(callee) != KnownBuiltinDeclName::GeometryStreamAppend)\n```\n\n### Key Changes\n\n1. **Added `KnownBuiltinDeclName` enum** in `slang-ast-support-types.h` covering all 10 known builtins:\n   - Geometry shaders: `GeometryStreamAppend`, `GeometryStreamRestart`\n   - Vertex processing: `GetAttributeAtVertex`, `DispatchMesh`  \n   - CUDA cooperation: `saturated_cooperation`, `saturated_cooperation_using`\n   - Autodiff: `IDifferentiable`, `IDifferentiablePtr`, `IDifferentiablePtrType`, `NullDifferential`\n\n2. **Updated `IRKnownBuiltinDecoration`** to store `IRIntLit` (enum value) instead of `IRStringLit`\n\n3. **Dual API approach**:\n   - New `getBuiltinFuncEnum()` for performance-critical code\n   - Legacy `getBuiltinFuncName()` maintained for backward compatibility\n\n4. **Updated all comparison sites** across 6 IR processing files to use enum comparisons\n\n### Benefits\n\n- **Performance**: Enum comparisons are significantly faster than string comparisons\n- **Type Safety**: Compile-time validation prevents typos in builtin names\n- **Maintainability**: Centralized enum definition makes adding new builtins easier\n\n## Testing\n\n- ‚úÖ All 284 language-feature tests pass\n- ‚úÖ IR processing and geometry shader tests validated\n- ‚úÖ Added specific test for KnownBuiltin attribute processing\n- ‚úÖ Maintains 100% backward compatibility\n\nThe implementation provides substantial performance improvements while preserving all existing functionality.\n\nFixes #7667.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-11T00:30:43Z",
         "2025-07-15T12:08:53Z",
         "2025-07-15T12:08:53Z",
         "93882897",
         "https://api.github.com/repos/shader-slang/slang",
         "https://github.com/shader-slang/slang/pull/7714",
         "feat"
        ],
        [
         "39",
         "3221235980",
         "1918",
         "Implement pre-computed etag support for mbtiles sources",
         "This PR implements more performant etag support by allowing mbtiles backends to supply pre-computed etags when available, eliminating unnecessary CPU usage from computing xxhash over tile data.\n\n## Background\n\nCDNs rely heavily on etags (usually a hash) to identify if tiles have changed. Many `.mbtiles` files already store tiles with pre-computed hashes using two tables - one stores `z, x, y, hash` columns, and another table stores `hash, data blob`. Currently, Martin computes etags by running a non-cryptographical hash function over the output even when pre-computed hashes are available, causing unnecessary CPU usage.\n\n## Changes Made\n\n### 1. Enhanced Source Trait\n- Added `get_tile_etag()` method with default implementation returning `None`\n- Added `Sync` bound for thread safety\n- Maintains full backward compatibility\n\n### 2. Optimized MbtSource Implementation\n- Detects and stores `MbtType` during initialization\n- Implements `get_tile_etag()` to return pre-computed hashes for supported types:\n  - `MbtType::FlatWithHash`: Uses hash from `tiles_with_hash` table\n  - `MbtType::Normalized`: Uses hash from `images` table `tile_id`\n  - `MbtType::Flat`: Returns `None` (falls back to computed hash)\n\n### 3. Updated Tile Serving Pipeline\n- Extended `Tile` struct with optional `etag` field\n- Modified tile serving logic to use pre-computed etag for single-source requests\n- Updated compression/decompression functions to preserve etag\n- Falls back to xxhash computation when no pre-computed etag is available\n\n### 4. HTTP Response Integration\n- Modified `get_http_response()` to prefer pre-computed etag over computed hash\n- Maintains identical HTTP behavior - completely transparent to clients\n\n## Performance Impact\n\n- **For mbtiles with pre-computed hashes**: Eliminates xxhash computation entirely - instant etag lookup\n- **For flat mbtiles or other sources**: No performance change - same xxhash computation as before\n- **Memory overhead**: Minimal - only adds optional `String` to `Tile` struct\n- **Network behavior**: Identical - etag headers work exactly the same\n\n## Testing\n\nAdded comprehensive tests verifying:\n- Pre-computed etag functionality with real mbtiles files\n- HTTP responses correctly use pre-computed etags\n- Backward compatibility - all existing tests continue to pass\n- Sources without pre-computed etags work normally\n\n## Backward Compatibility\n\n‚úÖ **Fully backward compatible** - no breaking changes\n- Existing sources (PostgreSQL, PMTiles, etc.) continue working exactly as before\n- Flat mbtiles files continue working with computed etags\n- All existing functionality preserved\n\n## Example Usage\n\n```rust\n// For FlatWithHash or Normalized mbtiles:\nlet etag = source.get_tile_etag(xyz, None).await?;\n// Returns Some(\"80EE46337AC006B6BD14B4FA4D6E2EF9\") - pre-computed hash\n\n// For Flat mbtiles or other sources:\nlet etag = source.get_tile_etag(xyz, None).await?;\n// Returns None - will compute xxhash as before\n```\n\nThe implementation successfully addresses the performance bottleneck described in the issue while maintaining full compatibility with existing functionality.\n\nFixes #1917.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-11T02:11:57Z",
         "2025-07-11T09:44:48Z",
         null,
         "105363726",
         "https://api.github.com/repos/maplibre/martin",
         "https://github.com/maplibre/martin/pull/1918",
         "feat"
        ],
        [
         "40",
         "3128896513",
         "38838",
         "Fix GitHub API rate limiting in chess workflow by replacing API calls with local file storage",
         "## Problem\n\nThe chess game workflow was experiencing rate limiting issues due to excessive GitHub API calls. Every time a move was made, the workflow would call `@octokit.list_issues()` to:\n\n1. Check if the same user made the previous move (consecutive move prevention)\n2. Build the \"Last few moves\" section in the README\n3. Generate the \"Top 20 Leaderboard\" with move counts\n\nWith the popularity of the chess game, these API calls were hitting GitHub's rate limits and causing the workflow to fail.\n\n## Solution\n\nThis PR eliminates the rate limiting issue by **replacing API calls with local file storage** while maintaining 100% compatibility with the existing user experience.\n\n### Key Changes\n\n**üîß Removed API Dependencies:**\n- Eliminated all `@octokit.list_issues()` calls that were causing rate limiting\n- Replaced API-based data retrieval with local file operations\n\n**üìÅ Added Local Data Storage:**\n- `chess_games/recent_moves.txt` - Stores last 5 moves with automatic rotation\n- `chess_games/leaderboard.txt` - Maintains top 20 players sorted by move count\n- `chess_games/last_mover.txt` - Tracks last player for consecutive move prevention\n\n**‚ö° Improved Performance:**\n- Instant file I/O operations instead of slow API calls\n- No more rate limiting delays or failures\n- Faster README generation\n\n**üõ°Ô∏è Robust Error Handling:**\n- Graceful fallbacks when files don't exist or are corrupted\n- Non-blocking operations that won't break gameplay\n- Consistent \"History temporarily unavailable\" messages for any issues\n\n### Before vs After\n\n**Before (Rate Limited):**\n```ruby\n# Heavy API call that causes rate limiting\nissues = @octokit.list_issues(ENV.fetch('REPOSITORY'), state: 'closed')\nmoves = issues.select{|issue| issue.title.start_with? 'chess|move|'}\n# Process hundreds/thousands of issues...\n```\n\n**After (Local Files):**\n```ruby\n# Fast local file read\nleaderboard_lines = File.readlines(\"chess_games/leaderboard.txt\")\nleaderboard_lines.each { |line| new_readme.concat \"#{line}\\n\" }\n```\n\n### Preserved Functionality\n\n‚úÖ Recent moves still display in README  \n‚úÖ Leaderboard still shows accurate player rankings  \n‚úÖ Consecutive move prevention still works  \n‚úÖ All game mechanics remain identical  \n‚úÖ Same README format and styling  \n‚úÖ All existing links and workflows preserved  \n\n### Testing\n\nThe changes have been thoroughly tested with simulations covering:\n- File operations when files exist and don't exist\n- Leaderboard updates and sorting logic\n- Recent moves rotation (maintains exactly 5 entries)\n- Consecutive move prevention with local data\n- README generation producing identical output format\n- Error handling scenarios\n\nFixes #19584.\n\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-06-09T01:42:16Z",
         "2025-06-09T02:18:37Z",
         "2025-06-09T02:18:37Z",
         "272328835",
         "https://api.github.com/repos/timburgan/timburgan",
         "https://github.com/timburgan/timburgan/pull/38838",
         "fix"
        ],
        [
         "41",
         "3129029549",
         "2799",
         "Draw down `Wrapper` components and migrate from `styled-components` to SCSS modules",
         "Successfully migrated 19 components from styled-components to SCSS modules in `packages/app/src/library`, establishing clear patterns for the remaining migration work.\n\n## Changes Made\n\n### Components Migrated (19 total)\n- **StyledSlider** - Simple wrapper conversion\n- **SideMenu/Heading** - Transient props (`$minimised`) ‚Üí CSS classes\n- **SetupSteps/Header** - Complex wrapper with nested sections\n- **EstimatedTxFee** - Simple wrapper conversion\n- **MainFooter** - Complex component with CSS variables\n- **Stat** - Transient props (`$isAddress`) ‚Üí CSS classes\n- **NotificationPrompts** - Simple wrapper conversion\n- **SelectItems** - Complex responsive layout with breakpoints\n- **Tooltip** - Simple wrapper conversion\n- **ErrorBoundary** - Multiple conditional classes\n- **Form/Warning** - Simple wrapper conversion\n- **AccountInput** - Complex conditional classes and state\n- **Nominations** - Simple wrapper conversion\n- **Account** - Conditional classes\n- **StatusLabel** - CSS variables as inline styles\n- **ActionItem** - Semantic HTML tags (h3)\n- **QrReader** - Animations and keyframes\n- **PayeeInput** - Complex transient props and state\n\n### Key Infrastructure Added\n- **`_variables.scss`** - Shared SCSS variables for breakpoints, colors, and common values\n- **Consistent patterns** - Established migration patterns for future work\n\n## Migration Patterns Established\n\n### 1. Transient Props ‚Üí CSS Classes\n```tsx\n// Before (styled-components)\n<Wrapper $isAddress={type === 'address'} />\n\n// After (CSS modules)\nconst allClasses = classNames(classes.wrapper, {\n  [classes.isAddress]: type === 'address',\n})\n<div className={allClasses} />\n```\n\n### 2. CSS Variables in SCSS\n```scss\n// _variables.scss\n$network-bar-font-size: 0.9rem;\n$two-threshold: 800px;\n$positive-color: #3eb955;\n\n// Component SCSS\n.wrapper {\n  font-size: $network-bar-font-size;\n  \n  @media (min-width: $two-threshold) {\n    // responsive styles\n  }\n}\n```\n\n### 3. Complex Responsive Layouts\n```scss\n.selectItemsWrapper {\n  &.twoCol {\n    @media (min-width: $two-threshold-min) {\n      > div:nth-child(2n) {\n        padding-right: 0;\n      }\n    }\n  }\n}\n```\n\n### 4. Animations and Keyframes\n```scss\n@keyframes fadeInScale {\n  from {\n    opacity: 0.75;\n    transform: scale(0.75);\n  }\n  to {\n    opacity: 1;\n    transform: scale(1);\n  }\n}\n\n.wrapper {\n  animation: fadeInScale 0.2s cubic-bezier(0, 1, 0, 1) forwards;\n}\n```\n\n## Benefits Achieved\n\n1. **Reduced Bundle Size** - Eliminated styled-components overhead for 19 components\n2. **Better Performance** - CSS modules provide better tree-shaking and optimization  \n3. **Improved Maintainability** - Clearer separation between styles and logic\n4. **Better Developer Experience** - CSS autocomplete, better debugging tools\n5. **Standards Compliance** - Moving towards standard CSS approaches\n6. **Type Safety** - CSS modules provide better type safety for class names\n\n## Remaining Work\n\n26 wrapper files remain to be migrated using the established patterns:\n- `Tx/Wrapper.ts`\n- `Card/Wrappers.ts` \n- `Modal/Wrappers.ts`\n- `Form/Wrappers.ts`\n- And 22 others...\n\nThe patterns established in this PR provide a clear roadmap for completing the migration.\n\nFixes #2798.\n\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-06-09T03:32:28Z",
         "2025-06-14T07:41:26Z",
         null,
         "456470362",
         "https://api.github.com/repos/polkadot-cloud/polkadot-staking-dashboard",
         "https://github.com/polkadot-cloud/polkadot-staking-dashboard/pull/2799",
         "feat"
        ],
        [
         "42",
         "3125029980",
         "1181",
         "Implement asynchronous API calls for file and message creation in environment.py",
         "This PR addresses the performance issue where API calls to create messages and files were taking too long by implementing asynchronous execution with concurrent processing.\r\n\r\n## Problem\r\nWhen agents make multiple tool calls or create multiple files, the synchronous API calls were executed sequentially, causing significant delays:\r\n- 5 tool calls √ó 200ms each = 1000ms total execution time\r\n- Multiple file uploads processed one at a time\r\n- Poor user experience due to high latency\r\n\r\n## Solution\r\nAdded comprehensive async support while maintaining full backward compatibility:\r\n\r\n### Concurrent Execution\r\n- Tool call responses now created concurrently using `asyncio`\r\n\r\n### Configuration & Fallback\r\n- New `ASYNC_API_CALLS` environment variable (default: `true`)\r\n\r\n## Backward Compatibility\r\n- ‚úÖ All original synchronous methods preserved unchanged\r\n- ‚úÖ No breaking changes to existing API\r\n- ‚úÖ Opt-in async execution via environment variable\r\n\r\n## Usage\r\n```bash\r\n# Enable async API calls (default)\r\nexport ASYNC_API_CALLS=true\r\n\r\n# Disable if needed\r\nexport ASYNC_API_CALLS=false\r\n```\r\n\r\nFixes #1180.\r\n\r\n---\r\n\r\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-06-06T14:54:51Z",
         "2025-06-07T21:04:30Z",
         "2025-06-07T21:04:30Z",
         "797493401",
         "https://api.github.com/repos/nearai/nearai",
         "https://github.com/nearai/nearai/pull/1181",
         "feat"
        ],
        [
         "43",
         "3151002300",
         "6671",
         "Use async file system APIs instead of sync APIs in install.ts",
         "Replaces synchronous file system API calls with asynchronous equivalents in `vscode/npm-package/install.ts` to improve performance and follow Node.js best practices.\n\n## Changes Made\n\n- **Added helper functions:**\n  - `checkFileExists()` - Uses `fs.promises.access()` to check file/directory existence asynchronously\n  - `isDirectoryEmpty()` - Uses `fs.promises.readdir()` to check if directory is empty asynchronously\n\n- **Replaced sync calls with async equivalents:**\n  - `fs.existsSync(installPath)` ‚Üí `await checkFileExists(installPath)`\n  - `fs.readdirSync(installPath).length === 0` ‚Üí `await isDirectoryEmpty(installPath)`\n  - `fs.existsSync(kiotaBinaryZip)` ‚Üí `await checkFileExists(kiotaBinaryZip)`\n\n## Behavior Preserved\n\nThe changes maintain exact same functional behavior:\n- Non-existent directories still trigger installation\n- Empty directories still trigger installation\n- Directories with files still skip installation\n\nAll error handling and edge cases are properly managed with the new async approach.\n\nFixes #6165.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-06-16T19:04:49Z",
         "2025-06-17T20:07:53Z",
         "2025-06-17T20:07:52Z",
         "323665366",
         "https://api.github.com/repos/microsoft/kiota",
         "https://github.com/microsoft/kiota/pull/6671",
         "perf"
        ],
        [
         "44",
         "3151242547",
         "49424",
         "Add EnableDefaultItems=false optimization for restore operations",
         "Improves restore performance by disabling default item globbing during restore operations, addressing significant performance issues on projects with large numbers of files.\n\n## Problem\n\nDuring `dotnet restore` operations, MSBuild spends excessive time on default item globbing (Compile, EmbeddedResource, None items) which can take 45+ seconds on projects with 100k+ files. Restore operations don't actually need these items to be evaluated, making this globbing unnecessary overhead.\n\n## Solution\n\nAutomatically adds `EnableDefaultItems=false` property to MSBuild arguments during restore operations while respecting user-provided values to avoid conflicts.\n\n## Changes\n\n- **`Constants.AddRestoreOptimizations()`**: New method that adds `EnableDefaultItems=false` if user hasn't already specified it\n- **`RestoreCommand.CreateForwarding()`**: Apply optimization for explicit restore commands (`dotnet restore`)\n- **`RestoringCommand.GetSeparateRestoreCommand()`**: Apply optimization for implicit restore scenarios (`dotnet build` without `--no-restore`)\n- **Comprehensive property parsing**: Handles multiple MSBuild property syntax formats (`-property:`, `-p:`, `--property:`) with case-insensitive matching\n\n## User Experience\n\n- **Transparent**: Users won't notice any behavior changes except faster restores\n- **Respects user preferences**: If user explicitly sets `EnableDefaultItems=true/false`, their value is preserved\n- **Backward compatible**: No breaking changes to existing workflows\n\n## Testing\n\nAdded comprehensive unit tests covering:\n- Basic optimization behavior\n- User override scenarios with various property syntax formats\n- Case-insensitive property matching\n- Integration with both explicit and implicit restore paths\n\n## Expected Impact\n\nBased on the original performance analysis, this should reduce restore evaluation time from ~45 seconds to ~300ms on projects with large file counts.\n\nFixes #49415.\n\n> [!WARNING]\n>\n> <details>\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\n>\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\n>\n> - `josvsblobprodcus372.vsblob.vsassets.io`\n>   - Triggering command: `/home/REDACTED/work/sdk/sdk/.dotnet/dotnet msbuild /m /nologo /clp:Summary /v:minimal /nr:true /warnaserror /p:TreatWarningsAsErrors=true /p:ContinuousIntegrationBuild=false /home/REDACTED/work/sdk/sdk/artifacts/toolset/restore.proj /t:__WriteToolsetLocation /clp:ErrorsOnly;NoSummary /p:__ToolsetLocationOutputFile=/home/REDACTED/work/sdk/sdk/artifacts/toolset/10.0.0-beta.25315.102.txt ` (dns block)\n>\n> If you need me to access, download, or install something from one of these locations, you can either:\n>\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\n>\n> </details>\n\n\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-06-16T20:33:51Z",
         "2025-06-25T14:43:43Z",
         null,
         "63984307",
         "https://api.github.com/repos/dotnet/sdk",
         "https://github.com/dotnet/sdk/pull/49424",
         "feat"
        ],
        [
         "45",
         "3151370964",
         "12025",
         "Add fast-paths for ToolLocationHelper property functions",
         "This PR adds fast-path implementations for two commonly used ToolLocationHelper property functions that were identified as performance bottlenecks in template projects:\n\n- `GetPlatformSDKLocation(String, String)`\n- `GetPlatformSDKDisplayName(String, String)`\n\n## Problem\nWhen building template projects in .NET 10.0.100-preview.5, these property functions don't have fast paths and require expensive reflection calls during project evaluation. The tracing output showed:\n\n```\nReceiverType=Microsoft.Build.Utilities.ToolLocationHelper; ObjectInstanceType=; MethodName=GetPlatformSDKLocation(String, String)\nReceiverType=Microsoft.Build.Utilities.ToolLocationHelper; ObjectInstanceType=; MethodName=GetPlatformSDKDisplayName(String, String)\n```\n\n## Solution\nAdded fast-path implementations in `WellKnownFunctions.cs` following the established pattern:\n\n1. **Added project reference** to `Microsoft.Build.Utilities.csproj` in the Build project to access ToolLocationHelper\n2. **Implemented fast-paths** for both methods with proper argument validation using `ParseArgs.TryGetArgs`\n3. **Added test coverage** to verify the implementation works correctly\n\nThe fast-paths avoid the expensive reflection mechanism and provide direct calls to the underlying methods when the signature matches exactly (two string parameters).\n\n## Changes\n- `src/Build/Microsoft.Build.csproj`: Added project reference to Utilities\n- `src/Build/Evaluation/Expander/WellKnownFunctions.cs`: Added fast-path implementations\n- `src/Build.UnitTests/Evaluation/Expander_Tests.cs`: Added test case\n\n## Testing\n- ‚úÖ Successfully built entire solution\n- ‚úÖ Added and verified test case `TestToolLocationHelperFastPaths` \n- ‚úÖ Verified existing ToolLocationHelper tests still pass\n- ‚úÖ Confirmed fast-paths execute without errors and return expected results\n\nFixes #12024.\n\n> [!WARNING]\n>\n> <details>\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\n>\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\n>\n> - `dnceng.pkgs.visualstudio.com`\n>   - Triggering command: `dotnet build src/Build/Microsoft.Build.csproj --configuration Debug --verbosity minimal ` (dns block)\n>   - Triggering command: `dotnet test src/Build.UnitTests/Microsoft.Build.Engine.UnitTests.csproj --filter TestToolLocationHelperFastPaths --configuration Debug --verbosity normal ` (dns block)\n>   - Triggering command: `/home/REDACTED/work/_temp/ghcca-node/node/bin/node /home/REDACTED/work/_temp/copilot-developer-action-main/dist/index.js ` (dns block)\n>\n> If you need me to access, download, or install something from one of these locations, you can either:\n>\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\n>\n> </details>\n\n\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "open",
         "2025-06-16T21:24:28Z",
         null,
         null,
         "32051890",
         "https://api.github.com/repos/dotnet/msbuild",
         "https://github.com/dotnet/msbuild/pull/12025",
         "perf"
        ],
        [
         "46",
         "3216159293",
         "110",
         "Add vcpkg dependency caching to Windows CI workflow",
         "## Overview\n\nThis PR implements vcpkg dependency caching for the Windows CI workflow to significantly speed up build times by avoiding full dependency rebuilds on every CI run.\n\n## Changes\n\nAdded a comprehensive caching strategy to `.github/workflows/ci-windows-minimal.yml` that:\n\n1. **Caches the `vcpkg/installed` directory** - where compiled dependencies are stored\n2. **Uses a multi-component cache key** for precise cache invalidation:\n   - `${{ runner.os }}` - OS-specific caching (Windows)\n   - `${{ steps.vcpkg-commit.outputs.hash }}` - vcpkg version/commit hash\n   - `${{ matrix.triplet }}` - Architecture-specific (x64-windows)\n   - `${{ hashFiles('vcpkg/vcpkg.json') }}` - Dependency manifest changes\n\n3. **Provides fallback restore keys** for partial cache hits:\n   ```yaml\n   restore-keys: |\n     ${{ runner.os }}-vcpkg-${{ steps.vcpkg-commit.outputs.hash }}-${{ matrix.triplet }}-\n     ${{ runner.os }}-vcpkg-${{ steps.vcpkg-commit.outputs.hash }}-\n     ${{ runner.os }}-vcpkg-\n   ```\n\n## Implementation Details\n\nThe cache step is strategically placed **after vcpkg is cloned and bootstrapped** but **before CMake configure**, ensuring:\n- The `.git/HEAD` file exists for accurate commit hash calculation\n- Dependencies are restored before CMake triggers vcpkg installation\n- Compatibility with existing GitHub Actions binary cache (`VCPKG_BINARY_SOURCES: 'clear;x-gha,readwrite'`)\n\n## Benefits\n\n- **Faster CI runs** - Dependencies only rebuild when vcpkg version or manifest changes\n- **Efficient cache utilization** - Progressive fallback strategy maximizes cache hits\n- **No breaking changes** - Works alongside existing caching mechanisms\n- **Smart invalidation** - Cache automatically invalidates when dependencies change\n\n## Example Cache Key\n\n```\nWindows-vcpkg-a1b2c3d4e5f6-x64-windows-8071ecc3\n```\n\nWhere:\n- `Windows` = OS\n- `a1b2c3d4e5f6` = vcpkg commit hash\n- `x64-windows` = triplet\n- `8071ecc3` = vcpkg.json hash\n\nThis approach ensures that CI builds will be significantly faster for incremental changes while maintaining reliability through proper cache invalidation.\n\n*This pull request was created as a result of the following prompt from Copilot chat.*\n> Add vcpkg dependency caching to the CI workflow for Windows builds. This will cache the vcpkg/installed directory in the GitHub Actions workflow, using a cache key based on the OS, vcpkg commit hash, and triplet, to prevent rebuilding all dependencies on every run. The cache step is placed after vcpkg is cloned and bootstrapped, ensuring the .git/HEAD file exists for cache key calculation. This will speed up CI runs by restoring dependencies from cache when possible.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-09T14:30:39Z",
         "2025-07-09T16:47:00Z",
         "2025-07-09T16:47:00Z",
         "564439013",
         "https://api.github.com/repos/pelicanmapping/rocky",
         "https://github.com/pelicanmapping/rocky/pull/110",
         "ci"
        ],
        [
         "47",
         "3081695764",
         "62056",
         "Small improvements to reduce allocations in validation filter logic",
         "I'm implementing improvements to reduce allocations in the validation filter logic. Here's my progress so far:\n\n- [x] Avoid allocating arrays in `ValidationEndpointFilterFactory.Create` for parameters that don't require validation\n  - Replaced fixed-size arrays with a List of structs containing only the validatable parameters\n  - Only parameters that need validation are stored, improving memory usage when most parameters don't need validation\n- [ ] Optimize `ValidationContext` reuse throughout the pipeline to avoid creating new ones per handler argument \n- [ ] Reduce closure allocations in `EndpointFilterDelegate` returned from the filter factory\n- [ ] Cache reflection calls for implemented subtypes in `ValidatableTypeInfo`\n\nThese changes will make the validation filter logic more efficient and pay-to-play, reducing allocations when users are not leveraging the feature.\n\nFixes #61222.\n\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-05-22T00:19:32Z",
         "2025-05-28T18:46:14Z",
         "2025-05-28T18:46:14Z",
         "17620347",
         "https://api.github.com/repos/dotnet/aspnetcore",
         "https://github.com/dotnet/aspnetcore/pull/62056",
         "perf"
        ],
        [
         "48",
         "3174426695",
         "166",
         "Fix Gantt performance by removing useMouse from every column",
         "Large Gantt charts were experiencing significant performance issues due to excessive re-renders. The root cause was that every `GanttColumn` component had its own `useMouse` hook for pixel-perfect Y position tracking of the `GanttAddFeatureHelper`.\n\n## Problem\n- Every mouse movement triggered re-renders of ALL columns (365+ columns in yearly view)\n- Each column ran expensive calculations: `useMouse` + `useThrottle` + `useWindowScroll` + `getBoundingClientRect()`\n- Result: 20,000+ re-renders per second, causing laggy and stuttering interface\n\n## Solution\nReplaced pixel-perfect mouse tracking with simple hover detection:\n\n### Changes Made\n- **GanttColumn**: Removed `useMouse`, `useThrottle`, `useWindowScroll` hooks\n- **GanttColumn**: Now uses only `onMouseEnter`/`onMouseLeave` events for hover state\n- **GanttAddFeatureHelper**: Removed `top` prop, simplified to center positioning (`top-1/2 -translate-y-1/2`)\n- **GanttAddFeatureHelper**: Maintains `useMouse` for X-axis date calculation on click\n\n### Performance Impact\n- **Before**: 21,900+ re-renders/second (365 columns √ó 60 mouse moves/sec)\n- **After**: Only 2 re-renders per column hover (enter + leave)\n- **Improvement**: ~10,000x reduction in re-renders\n\n### User Experience\n- **Before**: Laggy, stuttering interface on large Gantt charts\n- **After**: Smooth, responsive interface\n- **Functionality**: Fully preserved - add feature helper still appears on hover and works correctly\n\nThe solution addresses all performance concerns raised in the issue while maintaining backward compatibility and existing functionality.\n\nFixes #61.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-06-25T06:48:22Z",
         "2025-07-13T21:22:08Z",
         null,
         "847167817",
         "https://api.github.com/repos/haydenbleasel/kibo",
         "https://github.com/haydenbleasel/kibo/pull/166",
         "fix"
        ],
        [
         "49",
         "3125710825",
         "1936",
         "feat: update parts channel capacity from 1000 to 2500",
         "Updates the parts channel capacity from 1000 to 2500 to prevent blocking during processing of large blocks (128MB).\n\n## Changes\n\n- Increased `partsChan` buffer capacity from 1000 to 2500 in all relevant files:\n  - `node/node.go` - Main production code where the parts channel is created\n  - `consensus/reactor_test.go` - Test files using the parts channel\n  - `consensus/propagation/reactor_test.go`\n  - `consensus/propagation/commitment_test.go`\n  - `consensus/wal_generator.go`\n  - `consensus/byzantine_test.go`\n  - `consensus/replay_file.go`\n  - `consensus/common_test.go`\n\n## Problem\n\nThe current capacity of 1000 can cause blocking when processing large 128MB blocks, which adds unnecessary complexity to the consensus mechanism and can impact performance.\n\n## Solution\n\nIncreasing the channel capacity to 2500 provides sufficient buffer space to handle large block processing without blocking, simplifying the consensus flow and improving performance for large blocks.\n\nFixes #1923.\n\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-06-06T19:42:55Z",
         "2025-06-11T14:42:14Z",
         "2025-06-11T14:42:14Z",
         "221931137",
         "https://api.github.com/repos/celestiaorg/celestia-core",
         "https://github.com/celestiaorg/celestia-core/pull/1936",
         "feat"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 1221
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>agent</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user</th>\n",
       "      <th>state</th>\n",
       "      <th>created_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>merged_at</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3164503419</td>\n",
       "      <td>40</td>\n",
       "      <td>Fix Claude animation flickering with vt10x-ins...</td>\n",
       "      <td>## üéØ Problem: Claude's Thinking Animation Caus...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>2891702</td>\n",
       "      <td>hjanuschka</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-06-20T22:47:18Z</td>\n",
       "      <td>2025-06-21T11:51:22Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002552148</td>\n",
       "      <td>https://api.github.com/repos/amantus-ai/vibetu...</td>\n",
       "      <td>https://github.com/amantus-ai/vibetunnel/pull/40</td>\n",
       "      <td>fix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3273233066</td>\n",
       "      <td>1037</td>\n",
       "      <td>feat: implement comprehensive species tracking...</td>\n",
       "      <td>## Summary\\nThis PR implements a comprehensive...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>7030001</td>\n",
       "      <td>tphakala</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-07-29T11:21:11Z</td>\n",
       "      <td>2025-07-29T13:49:45Z</td>\n",
       "      <td>2025-07-29T13:49:45Z</td>\n",
       "      <td>707764474</td>\n",
       "      <td>https://api.github.com/repos/tphakala/birdnet-go</td>\n",
       "      <td>https://github.com/tphakala/birdnet-go/pull/1037</td>\n",
       "      <td>feat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3219880512</td>\n",
       "      <td>10340</td>\n",
       "      <td>feat(backend): Integrate GCS file storage with...</td>\n",
       "      <td>## Summary\\n\\nThis PR introduces a complete cl...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>76959103</td>\n",
       "      <td>majdyz</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-07-10T15:52:56Z</td>\n",
       "      <td>2025-07-18T03:20:54Z</td>\n",
       "      <td>2025-07-18T03:20:54Z</td>\n",
       "      <td>614765452</td>\n",
       "      <td>https://api.github.com/repos/Significant-Gravi...</td>\n",
       "      <td>https://github.com/Significant-Gravitas/AutoGP...</td>\n",
       "      <td>feat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2876006908</td>\n",
       "      <td>3375</td>\n",
       "      <td>Improve list and collection materializers perf...</td>\n",
       "      <td># Optimized Collection Materializers with Batc...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>3348134</td>\n",
       "      <td>strickvl</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-02-24T19:52:57Z</td>\n",
       "      <td>2025-04-20T19:47:42Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314197645</td>\n",
       "      <td>https://api.github.com/repos/zenml-io/zenml</td>\n",
       "      <td>https://github.com/zenml-io/zenml/pull/3375</td>\n",
       "      <td>feat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3142181649</td>\n",
       "      <td>19</td>\n",
       "      <td>Replace CLI subprocess approach with Claude Co...</td>\n",
       "      <td>## Description\\n\\nReplace the current CLI subp...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>80381</td>\n",
       "      <td>sugyan</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-06-13T04:05:15Z</td>\n",
       "      <td>2025-06-13T14:14:33Z</td>\n",
       "      <td>2025-06-13T14:14:33Z</td>\n",
       "      <td>999285986</td>\n",
       "      <td>https://api.github.com/repos/sugyan/claude-cod...</td>\n",
       "      <td>https://github.com/sugyan/claude-code-webui/pu...</td>\n",
       "      <td>feat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>3152003781</td>\n",
       "      <td>2037</td>\n",
       "      <td>Optimize Chat API/Job schema transfer by remov...</td>\n",
       "      <td># Optimize Chat API/Job schema transfer by rem...</td>\n",
       "      <td>Devin</td>\n",
       "      <td>158243242</td>\n",
       "      <td>devin-ai-integration[bot]</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-06-17T04:17:12Z</td>\n",
       "      <td>2025-06-17T07:08:49Z</td>\n",
       "      <td>2025-06-17T07:08:49Z</td>\n",
       "      <td>839216423</td>\n",
       "      <td>https://api.github.com/repos/liam-hq/liam</td>\n",
       "      <td>https://github.com/liam-hq/liam/pull/2037</td>\n",
       "      <td>perf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>2920951577</td>\n",
       "      <td>1064</td>\n",
       "      <td>feat: improve search functionality with pagina...</td>\n",
       "      <td>Closes #1063\\n\\nThis PR improves the search fu...</td>\n",
       "      <td>Devin</td>\n",
       "      <td>158243242</td>\n",
       "      <td>devin-ai-integration[bot]</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-03-14T18:07:04Z</td>\n",
       "      <td>2025-03-15T05:36:51Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442321089</td>\n",
       "      <td>https://api.github.com/repos/Cap-go/capgo</td>\n",
       "      <td>https://github.com/Cap-go/capgo/pull/1064</td>\n",
       "      <td>feat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>2920955200</td>\n",
       "      <td>1065</td>\n",
       "      <td>feat(dashboard): add improved app filtering wi...</td>\n",
       "      <td># Add search and filtering functionality to th...</td>\n",
       "      <td>Devin</td>\n",
       "      <td>158243242</td>\n",
       "      <td>devin-ai-integration[bot]</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-03-14T18:08:42Z</td>\n",
       "      <td>2025-03-15T05:37:21Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442321089</td>\n",
       "      <td>https://api.github.com/repos/Cap-go/capgo</td>\n",
       "      <td>https://github.com/Cap-go/capgo/pull/1065</td>\n",
       "      <td>feat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>2920983723</td>\n",
       "      <td>1066</td>\n",
       "      <td>perf: optimize MAU loading mechanism for bette...</td>\n",
       "      <td>Closes #1063\\n\\nThis PR optimizes the MAU load...</td>\n",
       "      <td>Devin</td>\n",
       "      <td>158243242</td>\n",
       "      <td>devin-ai-integration[bot]</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-03-14T18:19:38Z</td>\n",
       "      <td>2025-03-15T05:38:03Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442321089</td>\n",
       "      <td>https://api.github.com/repos/Cap-go/capgo</td>\n",
       "      <td>https://github.com/Cap-go/capgo/pull/1066</td>\n",
       "      <td>perf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>2978149205</td>\n",
       "      <td>2533</td>\n",
       "      <td>Add Context Caching Support</td>\n",
       "      <td>Fixes #2532\\n\\nThis PR adds support for contex...</td>\n",
       "      <td>Devin</td>\n",
       "      <td>158243242</td>\n",
       "      <td>devin-ai-integration[bot]</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-04-07T22:39:49Z</td>\n",
       "      <td>2025-04-16T15:59:50Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710601088</td>\n",
       "      <td>https://api.github.com/repos/crewAIInc/crewAI</td>\n",
       "      <td>https://github.com/crewAIInc/crewAI/pull/2533</td>\n",
       "      <td>feat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1221 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  number                                              title  \\\n",
       "0     3164503419      40  Fix Claude animation flickering with vt10x-ins...   \n",
       "1     3273233066    1037  feat: implement comprehensive species tracking...   \n",
       "2     3219880512   10340  feat(backend): Integrate GCS file storage with...   \n",
       "3     2876006908    3375  Improve list and collection materializers perf...   \n",
       "4     3142181649      19  Replace CLI subprocess approach with Claude Co...   \n",
       "...          ...     ...                                                ...   \n",
       "1216  3152003781    2037  Optimize Chat API/Job schema transfer by remov...   \n",
       "1217  2920951577    1064  feat: improve search functionality with pagina...   \n",
       "1218  2920955200    1065  feat(dashboard): add improved app filtering wi...   \n",
       "1219  2920983723    1066  perf: optimize MAU loading mechanism for bette...   \n",
       "1220  2978149205    2533                        Add Context Caching Support   \n",
       "\n",
       "                                                   body        agent  \\\n",
       "0     ## üéØ Problem: Claude's Thinking Animation Caus...  Claude_Code   \n",
       "1     ## Summary\\nThis PR implements a comprehensive...  Claude_Code   \n",
       "2     ## Summary\\n\\nThis PR introduces a complete cl...  Claude_Code   \n",
       "3     # Optimized Collection Materializers with Batc...  Claude_Code   \n",
       "4     ## Description\\n\\nReplace the current CLI subp...  Claude_Code   \n",
       "...                                                 ...          ...   \n",
       "1216  # Optimize Chat API/Job schema transfer by rem...        Devin   \n",
       "1217  Closes #1063\\n\\nThis PR improves the search fu...        Devin   \n",
       "1218  # Add search and filtering functionality to th...        Devin   \n",
       "1219  Closes #1063\\n\\nThis PR optimizes the MAU load...        Devin   \n",
       "1220  Fixes #2532\\n\\nThis PR adds support for contex...        Devin   \n",
       "\n",
       "        user_id                       user   state            created_at  \\\n",
       "0       2891702                 hjanuschka  closed  2025-06-20T22:47:18Z   \n",
       "1       7030001                   tphakala  closed  2025-07-29T11:21:11Z   \n",
       "2      76959103                     majdyz  closed  2025-07-10T15:52:56Z   \n",
       "3       3348134                   strickvl  closed  2025-02-24T19:52:57Z   \n",
       "4         80381                     sugyan  closed  2025-06-13T04:05:15Z   \n",
       "...         ...                        ...     ...                   ...   \n",
       "1216  158243242  devin-ai-integration[bot]  closed  2025-06-17T04:17:12Z   \n",
       "1217  158243242  devin-ai-integration[bot]  closed  2025-03-14T18:07:04Z   \n",
       "1218  158243242  devin-ai-integration[bot]  closed  2025-03-14T18:08:42Z   \n",
       "1219  158243242  devin-ai-integration[bot]  closed  2025-03-14T18:19:38Z   \n",
       "1220  158243242  devin-ai-integration[bot]  closed  2025-04-07T22:39:49Z   \n",
       "\n",
       "                 closed_at             merged_at     repo_id  \\\n",
       "0     2025-06-21T11:51:22Z                   NaN  1002552148   \n",
       "1     2025-07-29T13:49:45Z  2025-07-29T13:49:45Z   707764474   \n",
       "2     2025-07-18T03:20:54Z  2025-07-18T03:20:54Z   614765452   \n",
       "3     2025-04-20T19:47:42Z                   NaN   314197645   \n",
       "4     2025-06-13T14:14:33Z  2025-06-13T14:14:33Z   999285986   \n",
       "...                    ...                   ...         ...   \n",
       "1216  2025-06-17T07:08:49Z  2025-06-17T07:08:49Z   839216423   \n",
       "1217  2025-03-15T05:36:51Z                   NaN   442321089   \n",
       "1218  2025-03-15T05:37:21Z                   NaN   442321089   \n",
       "1219  2025-03-15T05:38:03Z                   NaN   442321089   \n",
       "1220  2025-04-16T15:59:50Z                   NaN   710601088   \n",
       "\n",
       "                                               repo_url  \\\n",
       "0     https://api.github.com/repos/amantus-ai/vibetu...   \n",
       "1      https://api.github.com/repos/tphakala/birdnet-go   \n",
       "2     https://api.github.com/repos/Significant-Gravi...   \n",
       "3           https://api.github.com/repos/zenml-io/zenml   \n",
       "4     https://api.github.com/repos/sugyan/claude-cod...   \n",
       "...                                                 ...   \n",
       "1216          https://api.github.com/repos/liam-hq/liam   \n",
       "1217          https://api.github.com/repos/Cap-go/capgo   \n",
       "1218          https://api.github.com/repos/Cap-go/capgo   \n",
       "1219          https://api.github.com/repos/Cap-go/capgo   \n",
       "1220      https://api.github.com/repos/crewAIInc/crewAI   \n",
       "\n",
       "                                               html_url  type  \n",
       "0      https://github.com/amantus-ai/vibetunnel/pull/40   fix  \n",
       "1      https://github.com/tphakala/birdnet-go/pull/1037  feat  \n",
       "2     https://github.com/Significant-Gravitas/AutoGP...  feat  \n",
       "3           https://github.com/zenml-io/zenml/pull/3375  feat  \n",
       "4     https://github.com/sugyan/claude-code-webui/pu...  feat  \n",
       "...                                                 ...   ...  \n",
       "1216          https://github.com/liam-hq/liam/pull/2037  perf  \n",
       "1217          https://github.com/Cap-go/capgo/pull/1064  feat  \n",
       "1218          https://github.com/Cap-go/capgo/pull/1065  feat  \n",
       "1219          https://github.com/Cap-go/capgo/pull/1066  perf  \n",
       "1220      https://github.com/crewAIInc/crewAI/pull/2533  feat  \n",
       "\n",
       "[1221 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge task type information from type_df to perf_df based on pr id\n",
    "perf_df = perf_df.merge(type_df[['id', 'type']], left_on='id', right_on='id', how='left')\n",
    "perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725340ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {}\n",
    "for topic_file in glob.glob(os.path.join(TOPIC_DIR, \"*.csv\")):\n",
    "    if \"-1\" not in topic_file:\n",
    "        topic_name = os.path.basename(topic_file).replace(\".csv\", \"\")\n",
    "        df = pd.read_csv(topic_file)\n",
    "        topics[topic_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8dd68da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development: 222 PRs\n",
      "Low-level: 257 PRs\n",
      "UI: 136 PRs\n",
      "Caching: 87 PRs\n",
      "Algorithmic: 119 PRs\n",
      "Query: 61 PRs\n",
      "Networking: 96 PRs\n",
      "Analytics: 61 PRs\n",
      "Hardware: 49 PRs\n",
      "AI: 32 PRs\n",
      "Total PRs across all categories: 1120\n"
     ]
    }
   ],
   "source": [
    "category_dfs = {}\n",
    "for category, topic_list in category_map.items():\n",
    "    dfs_to_concat = []\n",
    "    for topic in topic_list:\n",
    "        df = topics[topic].copy()\n",
    "        df['topic_name'] = topic_map.get(topic, topic)\n",
    "        df['category'] = category\n",
    "        dfs_to_concat.append(df)\n",
    "    \n",
    "    if dfs_to_concat:\n",
    "        category_dfs[category] = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "\n",
    "total = 0\n",
    "for category, df in category_dfs.items():\n",
    "    total += len(df)\n",
    "    print(f\"{category}: {len(df)} PRs\")\n",
    "print(f\"Total PRs across all categories: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f10e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories_df = pd.concat(category_dfs.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795eea35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "body",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "agent",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "closed_at",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "merged_at",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "repo_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "repo_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "html_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Topic",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Probability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Representative_document",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "topic_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "804c1ceb-d237-4b3a-8b83-ebe43fc51936",
       "rows": [
        [
         "0",
         "2912546402",
         "448",
         "Add GitHub API caching to prevent rate limiting",
         "- Create GitHub API caching script that handles authenticated and unauthenticated requests\r\n- Update Dockerfile to include the script in the container\r\n- Update init-firewall.sh to use cached GitHub API data\r\n- Modify devcontainer.json to run cache script before build and mount cache directory\r\n\r\nü§ñ Generated with [Claude Code](https://claude.ai/code)\r\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "1021104",
         "8enmann",
         "closed",
         "2025-03-12T03:51:34Z",
         "2025-05-06T17:50:00Z",
         null,
         "937253475",
         "https://api.github.com/repos/anthropics/claude-code",
         "https://github.com/anthropics/claude-code/pull/448",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "1",
         "3216159293",
         "110",
         "Add vcpkg dependency caching to Windows CI workflow",
         "## Overview\n\nThis PR implements vcpkg dependency caching for the Windows CI workflow to significantly speed up build times by avoiding full dependency rebuilds on every CI run.\n\n## Changes\n\nAdded a comprehensive caching strategy to `.github/workflows/ci-windows-minimal.yml` that:\n\n1. **Caches the `vcpkg/installed` directory** - where compiled dependencies are stored\n2. **Uses a multi-component cache key** for precise cache invalidation:\n   - `${{ runner.os }}` - OS-specific caching (Windows)\n   - `${{ steps.vcpkg-commit.outputs.hash }}` - vcpkg version/commit hash\n   - `${{ matrix.triplet }}` - Architecture-specific (x64-windows)\n   - `${{ hashFiles('vcpkg/vcpkg.json') }}` - Dependency manifest changes\n\n3. **Provides fallback restore keys** for partial cache hits:\n   ```yaml\n   restore-keys: |\n     ${{ runner.os }}-vcpkg-${{ steps.vcpkg-commit.outputs.hash }}-${{ matrix.triplet }}-\n     ${{ runner.os }}-vcpkg-${{ steps.vcpkg-commit.outputs.hash }}-\n     ${{ runner.os }}-vcpkg-\n   ```\n\n## Implementation Details\n\nThe cache step is strategically placed **after vcpkg is cloned and bootstrapped** but **before CMake configure**, ensuring:\n- The `.git/HEAD` file exists for accurate commit hash calculation\n- Dependencies are restored before CMake triggers vcpkg installation\n- Compatibility with existing GitHub Actions binary cache (`VCPKG_BINARY_SOURCES: 'clear;x-gha,readwrite'`)\n\n## Benefits\n\n- **Faster CI runs** - Dependencies only rebuild when vcpkg version or manifest changes\n- **Efficient cache utilization** - Progressive fallback strategy maximizes cache hits\n- **No breaking changes** - Works alongside existing caching mechanisms\n- **Smart invalidation** - Cache automatically invalidates when dependencies change\n\n## Example Cache Key\n\n```\nWindows-vcpkg-a1b2c3d4e5f6-x64-windows-8071ecc3\n```\n\nWhere:\n- `Windows` = OS\n- `a1b2c3d4e5f6` = vcpkg commit hash\n- `x64-windows` = triplet\n- `8071ecc3` = vcpkg.json hash\n\nThis approach ensures that CI builds will be significantly faster for incremental changes while maintaining reliability through proper cache invalidation.\n\n*This pull request was created as a result of the following prompt from Copilot chat.*\n> Add vcpkg dependency caching to the CI workflow for Windows builds. This will cache the vcpkg/installed directory in the GitHub Actions workflow, using a cache key based on the OS, vcpkg commit hash, and triplet, to prevent rebuilding all dependencies on every run. The cache step is placed after vcpkg is cloned and bootstrapped, ensuring the .git/HEAD file exists for cache key calculation. This will speed up CI runs by restoring dependencies from cache when possible.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-09T14:30:39Z",
         "2025-07-09T16:47:00Z",
         "2025-07-09T16:47:00Z",
         "564439013",
         "https://api.github.com/repos/pelicanmapping/rocky",
         "https://github.com/pelicanmapping/rocky/pull/110",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "2",
         "3195588879",
         "16531",
         "Remove duplicate yarn eslint step from .circleci/config.yml",
         "<details><summary>&#x1F6E0 DevTools &#x1F6E0</summary>\n<p>\n\n[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/Copilot/mlflow/pull/16531?quickstart=1)\n\n#### Install mlflow from this PR\n\n```\n# mlflow\npip install git+https://github.com/mlflow/mlflow.git@refs/pull/16531/merge\n# mlflow-skinny\npip install git+https://github.com/mlflow/mlflow.git@refs/pull/16531/merge#subdirectory=skinny\n```\n\nFor Databricks, use the following command:\n\n```\n%sh curl -LsSf https://raw.githubusercontent.com/mlflow/mlflow/HEAD/dev/install-skinny.sh | sh -s pull/16531/merge\n```\n\n</p>\n</details>\n\n## Summary\n\nRemoves the duplicate `yarn eslint` step from `.circleci/config.yml` to eliminate redundancy with the identical linting step in `.github/workflows/docs.yml`.\n\n## Changes Made\n\n- Removed the \"Lint\" step (lines 88-91) from the `build_doc` job in `.circleci/config.yml`\n- The CircleCI workflow now flows directly from \"Install JS dependencies\" to \"Build documentation\"\n\n## Before/After\n\n**Before**: Both CI systems were running identical linting:\n- CircleCI: `yarn eslint` in docs directory\n- GitHub Actions: `yarn eslint` in docs directory\n\n**After**: Only GitHub Actions runs the linting step, eliminating duplication while maintaining the same coverage.\n\n## Impact\n\n- ‚úÖ Reduces CI execution time and resource usage\n- ‚úÖ Eliminates duplicate linting checks  \n- ‚úÖ Maintains identical linting coverage through GitHub Actions workflow\n- ‚úÖ No impact on documentation building functionality\n- ‚úÖ No impact on documentation preview generation\n\nThe GitHub Actions workflow continues to provide the same ESLint coverage for `.md` and `.mdx` files in the docs directory, ensuring no reduction in code quality checks.\n\nFixes #16530.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-02T11:33:06Z",
         "2025-07-02T12:24:50Z",
         "2025-07-02T12:24:50Z",
         "136202695",
         "https://api.github.com/repos/mlflow/mlflow",
         "https://github.com/mlflow/mlflow/pull/16531",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "3",
         "3074681764",
         "13829",
         "Update build documentation with quick build optimization flags",
         "This PR updates the build documentation (`toolkit/docs/building/building.md`) to include the latest optimization flags and best practices for building Azure Linux more efficiently.\n\n## Changes\n- Added documentation for `QUICK_REBUILD=y` flag which optimizes builds across all stages\n- Added documentation for `QUICK_REBUILD_TOOLCHAIN=y` flag for optimizing toolchain builds\n- Added documentation for `QUICK_REBUILD_PACKAGES=y` flag for optimizing package builds\n- Updated all command examples to use these optimization flags\n- Added clear explanations of what each flag does\n- Added a note about quick build flags in the overview section for visibility\n- Fixed typos and minor grammatical issues\n\nThese changes bring the documentation up to date with the current build tools and optimization capabilities, providing developers with best practices for faster builds.\n\n### Benefits\nThese optimization flags significantly improve build performance by:\n- Using existing published components where possible\n- Enabling delta builds to avoid unnecessary rebuilds\n- Pre-fetching and caching dependencies\n- Limiting cascading rebuilds when a dependency changes\n\nFixes #13828.\n\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "open",
         "2025-05-19T18:25:04Z",
         null,
         null,
         "281765424",
         "https://api.github.com/repos/microsoft/azurelinux",
         "https://github.com/microsoft/azurelinux/pull/13829",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "4",
         "3159826481",
         "184",
         "[WIP] Support .coshrc compilation",
         "Thanks for assigning this issue to me. I'm starting to work on it and will keep this PR's description up to date as I form a plan and make progress.\n\nOriginal issue description:\n\n> To avoid having to compile it whenever the shell starts up.  Preferably by compiling it automatically whenever it changes, and then relying on the compiled version until it changes again.\n\n\nFixes #117.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-06-19T10:34:39Z",
         "2025-06-26T11:59:32Z",
         null,
         "445862991",
         "https://api.github.com/repos/tomhrr/cosh",
         "https://github.com/tomhrr/cosh/pull/184",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "5",
         "3259387186",
         "4471",
         "Fix Gradle build failures due to Maven Central rate limiting (HTTP 429)",
         "## Problem\n\nCI jobs were failing due to Maven Central rate limiting with HTTP 429 errors:\n\n```\nCould not GET 'https://repo.maven.apache.org/maven2/com/google/code/gson/gson/2.10.1/gson-2.10.1.pom'. \nReceived status code 429 from server: Your IP: 20.55.222.81 has hit the rate limit with Maven Central. \nToo many requests.\n```\n\nThis occurred because Gradle dependencies were being downloaded repeatedly in each CI run without proper caching.\n\n## Solution\n\nAdded comprehensive Gradle dependency caching to all Java-related CI workflows:\n\n### 1. Gradle Dependency Caching\n- **java.yml**: Added `~/.gradle/caches` and `~/.gradle/wrapper` caching to all Java build jobs\n- **codeql.yml**: Added Gradle caching for Java/Kotlin CodeQL analysis  \n- **java-cd.yml**: Added Gradle caching for CD pipeline builds and deployment testing\n\n### 2. Smart Cache Keys\n```yaml\nkey: ${{ runner.os }}-gradle-${{ hashFiles('java/**/*.gradle*', 'java/**/gradle-wrapper.properties') }}\nrestore-keys: |\n    ${{ runner.os }}-gradle-\n```\n\nCache keys are based on Gradle file hashes to ensure proper cache invalidation when dependencies change, with fallback restore keys for partial cache hits.\n\n### 3. Build Cache Optimization\nAdded `--build-cache` flag to all `gradlew` commands to enable Gradle's local build cache, reducing compilation time and duplicate work within the same CI run.\n\n## Impact\n\n- **Reduces Maven Central requests**: Dependencies cached across CI runs\n- **Faster builds**: ~200MB of Gradle dependencies no longer downloaded every run\n- **Rate limit resilience**: Significantly reduces likelihood of HTTP 429 errors\n- **Better CI reliability**: Less dependency on external repository availability\n\n## Testing\n\nValidated that caching configuration works correctly:\n- Gradle cache directories (`~/.gradle/caches`, `~/.gradle/wrapper`) are properly created\n- Cache keys generate correctly based on Gradle file changes\n- Build cache is enabled and functional\n\nFixes #4470.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-24T10:28:36Z",
         "2025-07-24T12:17:19Z",
         "2025-07-24T12:17:19Z",
         "511141524",
         "https://api.github.com/repos/valkey-io/valkey-glide",
         "https://github.com/valkey-io/valkey-glide/pull/4471",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "6",
         "3197896940",
         "1033",
         "ci: Add conditional testing for wef and webview crates",
         "This PR optimizes the CI workflow by implementing conditional testing for the `wef` and `webview` crates, which significantly improves CI performance while maintaining full test coverage when needed.\n\n## Problem\n\nThe current CI workflow runs `cargo test --all` which includes testing the heavy `wef` and `webview` crates on every change, even when modifications are unrelated to these components. This causes:\n\n- Slower CI runs due to CEF framework setup and heavy dependencies\n- Unnecessary resource usage when testing unrelated changes\n- Longer feedback cycles for developers working on other parts of the codebase\n\n## Solution\n\n### Main Test Job Optimization\nModified the main test steps to exclude `wef` and `webview` crates:\n\n```yaml\n# Before\ncargo test --all\n\n# After  \ncargo test --workspace --exclude wef --exclude gpui-webview\n```\n\n### Conditional Testing Jobs\nAdded two new jobs that only run when relevant files change:\n\n1. **`test-wef`** - Runs when `crates/wef/**` files are modified\n2. **`test-webview`** - Runs when `crates/webview/**` files are modified\n\nBoth jobs use `dorny/paths-filter@v2` to detect file changes and skip execution with informative messages when no relevant changes are detected.\n\n## Benefits\n\n- ‚ö° **Faster CI**: Main test suite runs significantly faster by excluding heavy crates\n- üéØ **Targeted testing**: wef/webview tests only run when their code changes\n- üíæ **Resource efficiency**: CEF dependencies only set up when needed\n- üîç **Maintained coverage**: Full test coverage preserved when changes require it\n- ‚úÖ **Clear feedback**: Skip messages clearly indicate when tests aren't needed\n\n## Example Scenarios\n\n### Scenario A: UI component change\n```\nChange: crates/ui/src/button.rs\nResult: \n- ‚úÖ Main test runs (excluding wef/webview)\n- ‚è≠Ô∏è wef tests skipped\n- ‚è≠Ô∏è webview tests skipped\n```\n\n### Scenario B: wef crate change  \n```\nChange: crates/wef/src/lib.rs\nResult:\n- ‚úÖ Main test runs (excluding wef/webview) \n- ‚úÖ wef tests run with full CEF setup\n- ‚è≠Ô∏è webview tests skipped\n```\n\n### Scenario C: webview crate change\n```\nChange: crates/webview/src/lib.rs  \nResult:\n- ‚úÖ Main test runs (excluding wef/webview)\n- ‚è≠Ô∏è wef tests skipped\n- ‚úÖ webview tests run with full CEF setup\n```\n\n## Technical Details\n\n- Uses `dorny/paths-filter@v2` for reliable file change detection\n- Maintains same matrix strategy (Linux, Windows, macOS) across all jobs\n- Preserves existing caching patterns with job-specific cache keys\n- All conditional steps use proper `if:` conditions to avoid unnecessary execution\n- YAML syntax validated and cargo command syntax verified\n\n## Testing\n\nCreated comprehensive validation script that confirms:\n- ‚úÖ Cargo exclude syntax works correctly\n- ‚úÖ Package-specific testing syntax is valid\n- ‚úÖ YAML structure is properly formatted\n- ‚úÖ All expected jobs and conditions are present\n\nThis change maintains the same level of test coverage while significantly improving CI efficiency for the majority of development work.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-03T03:46:08Z",
         "2025-07-03T06:55:38Z",
         null,
         "814684486",
         "https://api.github.com/repos/longbridge/gpui-component",
         "https://github.com/longbridge/gpui-component/pull/1033",
         "0",
         "1.0",
         "True",
         "CI/CD",
         "Development"
        ],
        [
         "7",
         "3088220705",
         "684",
         "Refactor CI workflow for parallel multi-architecture Docker builds",
         "## Changes\n\nThis PR refactors the GitHub Actions CI workflow to build Docker images for both amd64 and arm64 architectures in parallel, improving build times while maintaining multi-architecture support.\n\n### Key improvements:\n\n- Split the image build process into separate parallel jobs for amd64 and arm64 for both App and Engine images\n- Added special handling for Lambda compatibility:\n  - Push amd64 Engine image with `-lambda` tag suffix for AWS Lambda compatibility\n- Added a final job to create multi-architecture manifests combining both architectures\n- Preserved ECR cache configuration with architecture-specific cache references\n\n### Before:\n- Single job built both architectures sequentially\n- Additional step to extract amd64 image for Lambda\n- ~25-30% longer build time due to sequential multi-arch builds\n\n### After:\n- Parallel architecture-specific builds\n- Dedicated job for Lambda-compatible tags\n- Final manifest creation job\n- Architecture-specific build caching\n- Expected ~20-25% faster builds due to parallelization\n\n## Testing\n\nThis change has been validated for YAML syntax correctness. GitHub Actions will use this workflow configuration on merge, building both amd64 and arm64 images for App and Engine images, and creating multi-arch manifests.\n\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-05-24T07:39:25Z",
         "2025-06-10T21:14:55Z",
         null,
         "945671748",
         "https://api.github.com/repos/openops-cloud/openops",
         "https://github.com/openops-cloud/openops/pull/684",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "8",
         "3206330418",
         "3547",
         "Add comprehensive FrankenPHP support for phpMyFAQ",
         "This PR adds full support for [FrankenPHP](https://frankenphp.dev), a modern PHP application server built on Caddy, providing high-performance capabilities and modern web server features for phpMyFAQ.\n\n## What's Added\n\n### üê≥ Docker Configuration\n- **Complete Dockerfile** with all required PHP extensions (gd, intl, ldap, mysqli, pdo, zip, opcache, etc.)\n- **Docker Compose service** with proper environment variables and port mapping (8888:80, 8443:443)\n- **Entrypoint script** for automated PHP configuration and directory setup\n\n### ‚öôÔ∏è Configuration Files\n- **Caddyfile** with URL rewriting, security headers, and SSO support\n- **Worker script** for FrankenPHP's high-performance worker mode (optional)\n- **Environment-based configuration** matching existing Apache/PHP-FPM patterns\n\n### üìö Documentation\n- **Installation guide** with manual setup, Docker usage, and SSO configuration\n- **Development documentation** updates for FrankenPHP workflow\n- **Comprehensive README** with usage instructions and best practices\n\n## Key Features\n\n‚ú® **High Performance**: Optional worker mode keeps PHP code in memory between requests  \nüîê **Built-in HTTPS**: Automatic SSL certificate management  \nüöÄ **Modern Architecture**: HTTP/2, HTTP/3, and Server-Sent Events support  \nüõ°Ô∏è **Security**: Pre-configured security headers and SSO support  \nüîÑ **Clean URLs**: Automatic URL rewriting for phpMyFAQ routes  \n\n## Usage\n\n### Quick Start with Docker\n```bash\n# Start FrankenPHP service\ndocker-compose up frankenphp\n\n# Access phpMyFAQ at http://localhost:8888\n```\n\n### Manual Installation\n```bash\n# Install FrankenPHP\ncurl -L https://github.com/dunglas/frankenphp/releases/latest/download/frankenphp-linux-x86_64 -o frankenphp\nchmod +x frankenphp && sudo mv frankenphp /usr/local/bin/\n\n# Start with provided Caddyfile\nfrankenphp run --config /path/to/Caddyfile\n```\n\n## Testing Results\n\n‚úÖ Docker build successful  \n‚úÖ FrankenPHP container starts correctly  \n‚úÖ PHP files served properly  \n‚úÖ phpMyFAQ pages load correctly  \n‚úÖ Setup redirection works as expected  \n\n## Benefits over Traditional Setup\n\n- **Better Performance**: Worker mode eliminates PHP initialization overhead\n- **Simpler Deployment**: Single binary with built-in web server\n- **Automatic HTTPS**: No need for reverse proxy configuration  \n- **Modern Features**: Built-in support for latest web standards\n- **Easy Configuration**: Simple Caddyfile syntax vs complex Apache/nginx configs\n\nThe implementation follows existing patterns used for Apache and nginx+PHP-FPM support, making minimal changes to the core codebase while providing comprehensive Docker support and documentation.\n\nFixes #3498.\n\n> [!WARNING]\n>\n> <details>\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\n>\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\n>\n> - `127.0.0.11`\n> - `https://api.github.com/repos/DASPRiD/Enum/zipball/8dfd07c6d2cf31c8da90c53b83c026c7696dda90`\n>   - Triggering command: `/usr/bin/php8.3 -n -c /tmp/vwNFJo /usr/bin/composer install --no-dev` (http block)\n> - `https://api.github.com/repos/php-fig/log/zipball/f16e1d5863e37f8d8c2a01719f5b34baa2b714d3`\n>   - Triggering command: `/usr/bin/php8.3 -n -c /tmp/vwNFJo /usr/bin/composer install --no-dev` (http block)\n> - `pecl.php.net`\n>   - Triggering command: `/usr/local/bin/php -C -q -d include_path=/usr/local/lib/php -d date.timezone=UTC -d output_buffering=1 -d variables_order=EGPCS -d safe_mode=0 -d register_argc_argv=On /usr/local/lib/php/peclcmd.php install xdebug-3.4.2` (dns block)\n>   - Triggering command: `/usr/local/bin/php -C -q -d include_path=/usr/local/lib/php -d date.timezone=UTC -d output_buffering=1 -d variables_order=EGPCS -d safe_mode=0 -d register_argc_argv=On /usr/local/lib/php/peclcmd.php install xdebug` (dns block)\n>\n> If you need me to access, download, or install something from one of these locations, you can either:\n>\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\n>\n> </details>\n\n\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-06T09:22:25Z",
         "2025-07-06T10:00:32Z",
         "2025-07-06T10:00:32Z",
         "269027",
         "https://api.github.com/repos/thorsten/phpMyFAQ",
         "https://github.com/thorsten/phpMyFAQ/pull/3547",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "9",
         "3207427713",
         "75",
         "Fix CI workflow: Add proper Cargo cache steps to develop and s3s-e2e jobs",
         "## Summary\n\nThis PR fixes the CI workflow caching issues by adding proper `actions/cache` steps to both the `develop` and `s3s-e2e` jobs, ensuring efficient Cargo dependency caching for faster builds.\n\n## Changes Made\n\n### Added Cargo Cache Steps\n- **develop job**: Added `actions/cache@v4` step to cache Cargo dependencies before running tests, formatting, and linting\n- **s3s-e2e job**: Added `actions/cache@v4` step to cache Cargo dependencies before building and running E2E tests\n\n### Cache Configuration\n```yaml\n- name: Cache Cargo dependencies\n  uses: actions/cache@v4\n  with:\n    path: |\n      ~/.cargo/registry\n      ~/.cargo/git\n      target\n    key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}\n    restore-keys: |\n      ${{ runner.os }}-cargo-\n```\n\n### Key Features\n- **Cache Paths**: Caches `~/.cargo/registry`, `~/.cargo/git`, and `target` directories\n- **Cache Key**: Uses `Cargo.lock` file hash for precise cache invalidation\n- **Restore Keys**: Provides fallback keys for partial cache matches\n- **Positioning**: Cache steps are placed after Rust setup but before compilation steps\n\n## Benefits\n\n1. **Faster CI Builds**: Avoids re-downloading and re-compiling dependencies when `Cargo.lock` hasn't changed\n2. **Reduced Network Usage**: Minimizes registry downloads during CI runs\n3. **Consistent Caching**: Both jobs use identical cache configuration for consistency\n4. **Proper Cache Invalidation**: Cache automatically invalidates when dependencies change\n\n## Verification\n\n- ‚úÖ YAML syntax validation passes\n- ‚úÖ Cache steps properly positioned in workflow\n- ‚úÖ Both `develop` and `s3s-e2e` jobs include caching\n- ‚úÖ Uses `Cargo.lock` as cache key as requested\n- ‚úÖ Workflow file has substantial content changes (22 lines added)\n\nThis addresses the previous PR issues and ensures proper Cargo dependency caching for both critical CI jobs.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-07T03:30:11Z",
         "2025-07-07T03:31:54Z",
         null,
         "722597620",
         "https://api.github.com/repos/rustfs/rustfs",
         "https://github.com/rustfs/rustfs/pull/75",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "10",
         "3207429355",
         "76",
         "‰ºòÂåñ CI Â∑•‰ΩúÊµÅÔºö‰∏∫ develop Âíå s3s-e2e ‰Ωú‰∏öÊ∑ªÂä† Cargo ÁºìÂ≠ò",
         "## Ê¶ÇËø∞\n\nÊú¨ PR ÂØπ `.github/workflows/ci.yml` ËøõË°å‰∫Ü‰ºòÂåñÔºå‰∏∫ `develop` Âíå `s3s-e2e` ‰Ωú‰∏öÊ∑ªÂä†‰∫Ü Cargo ÁºìÂ≠òÊîØÊåÅÔºå‰ª•ÊèêÈ´ò CI ÊûÑÂª∫ÈÄüÂ∫¶„ÄÇ\n\n## ÂèòÊõ¥ÂÜÖÂÆπ\n\n### Ê∑ªÂä†ÁöÑÁºìÂ≠òÊ≠•È™§\n\nÂú®‰ª•‰∏ã‰∏§‰∏™‰Ωú‰∏ö‰∏≠Ê∑ªÂä†‰∫Ü `actions/cache` Ê≠•È™§Ôºö\n\n1. **develop ‰Ωú‰∏ö** (Á¨¨ 89-96 Ë°å)\n2. **s3s-e2e ‰Ωú‰∏ö** (Á¨¨ 117-124 Ë°å)\n\n### ÁºìÂ≠òÈÖçÁΩÆ\n\n- **ÁºìÂ≠òË∑ØÂæÑ**Ôºö\n  - `~/.cargo/registry` - Cargo ‰æùËµñÊ≥®ÂÜåË°®\n  - `~/.cargo/git` - Git ‰æùËµñ\n  - `target` - ÊûÑÂª∫ÁõÆÊ†áÁõÆÂΩï\n\n- **ÁºìÂ≠òÈîÆ**Ôºö`${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}`\n  - Âü∫‰∫éÊìç‰ΩúÁ≥ªÁªüÂíå Cargo.lock Êñá‰ª∂ÂìàÂ∏åÂÄºÁîüÊàê\n  - Á°Æ‰øù‰æùËµñÂèòÊõ¥Êó∂ÁºìÂ≠òÂ§±Êïà\n\n- **ÁºìÂ≠òÁâàÊú¨**Ôºö`actions/cache@v4`\n\n### Ê≠•È™§‰ΩçÁΩÆ\n\nÁºìÂ≠òÊ≠•È™§Ë¢´Á≤æÁ°ÆÊîæÁΩÆÂú®Ôºö\n- `uses: ./.github/actions/setup` **‰πãÂêé**\n- `cargo build/test` ÂëΩ‰ª§ **‰πãÂâç**\n\nËøôÁ°Æ‰øù‰∫ÜÂú®‰ΩøÁî®ÁºìÂ≠òÊûÑÂª∫‰∫ßÁâ©‰πãÂâçÔºåÊâÄÊúâÂøÖË¶ÅÁöÑ‰æùËµñÂíåÂ∑•ÂÖ∑ÈÉΩÂ∑≤Ê≠£Á°ÆËÆæÁΩÆ„ÄÇ\n\n## È¢ÑÊúüÊïàÊûú\n\n- üöÄ **ÊèêÈ´òÊûÑÂª∫ÈÄüÂ∫¶**ÔºöÂêéÁª≠ÊûÑÂª∫ÂèØ‰ª•Â§çÁî®Â∑≤ÁºìÂ≠òÁöÑ‰æùËµñÂíåÊûÑÂª∫‰∫ßÁâ©\n- üí∞ **ËäÇÁúÅ CI ËµÑÊ∫ê**ÔºöÂáèÂ∞ëÈáçÂ§ç‰∏ãËΩΩÂíåÁºñËØëÊó∂Èó¥\n- üîÑ **Êô∫ËÉΩÁºìÂ≠òÂ§±Êïà**ÔºöÂΩì Cargo.lock ÂèòÊõ¥Êó∂Ëá™Âä®Êõ¥Êñ∞ÁºìÂ≠ò\n\n## ÊµãËØï\n\n- ‚úÖ YAML ËØ≠Ê≥ïÈ™åËØÅÈÄöËøá\n- ‚úÖ ÁºìÂ≠òÊ≠•È™§Ê≠£Á°ÆÊîæÁΩÆÂú®Â∑•‰ΩúÊµÅ‰∏≠\n- ‚úÖ ÁºìÂ≠òÈÖçÁΩÆÁ¨¶ÂêàÊúÄ‰Ω≥ÂÆûË∑µ\n\n## ÂÖºÂÆπÊÄß\n\nÊ≠§ÂèòÊõ¥ÂÆåÂÖ®ÂêëÂêéÂÖºÂÆπÔºå‰∏ç‰ºöÂΩ±ÂìçÁé∞ÊúâÁöÑ CI Ë°å‰∏∫Ôºå‰ªÖÊ∑ªÂä†ÁºìÂ≠ò‰ºòÂåñÂäüËÉΩ„ÄÇ\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-07T03:31:32Z",
         "2025-07-07T03:31:45Z",
         null,
         "722597620",
         "https://api.github.com/repos/rustfs/rustfs",
         "https://github.com/rustfs/rustfs/pull/76",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "11",
         "3205497325",
         "3046",
         "Implement intelligent test selection for github actions",
         "## Summary\n\nThis PR implements an intelligent test selection system that reduces CI runtime from 5+ minutes to targeted windows (1-5 minutes) based on the scope of changes in a pull request. The system analyzes git diff to determine which tests are relevant and executes only those tests, providing 60-80% time savings for focused changes while maintaining comprehensive coverage for complex changes.\n\n## Problem Statement\n\nThe current CI system runs the full test suite for every PR, regardless of the scope of changes. This results in:\n- Consistent 5+ minute runtime even for documentation-only changes\n- Inefficient use of CI resources\n- Slower feedback for developers\n- No differentiation between small focused changes and large complex changes\n\n## Solution\n\n### üîß Core Components\n\n1. **`tools/test_selector.py`** - Intelligent test selection engine\n   - Analyzes git diff to categorize file changes\n   - Maps file patterns to relevant test categories\n   - Provides both human-readable and JSON output for CI integration\n   - Implements fallback to full test suite for complex changes\n\n2. **`tools/test_docs_build.py`** - Lightweight documentation testing\n   - Validates markdown and RST files for basic formatting\n   - Checks configuration files exist and are valid\n   - Completes in ~30 seconds vs full documentation build\n\n3. **`.github/workflows/intelligent-testing.yml`** - Enhanced CI workflow\n   - Dynamic test matrix generation based on change analysis\n   - Parallel execution paths for fast tests vs comprehensive tests\n   - Automatic fallback mechanism for edge cases\n\n4. **`tools/validate_test_selection.py`** - System validation\n   - Demonstrates functionality and validates correct operation\n   - Shows expected benefits and time savings\n\n### üìä Test Categories & Performance\n\n| Change Type | Previous Runtime | New Runtime | Improvement | Test Strategy |\n|-------------|-----------------|-------------|-------------|---------------|\n| **Documentation-only** | ~5+ minutes | ~1-2 minutes | **60-80% faster** | Lightweight docs validation |\n| **SuperAnimal changes** | ~5+ minutes | ~3-4 minutes | **20-40% faster** | SuperAnimal-specific tests |\n| **Focused components** | ~5+ minutes | ~2-3 minutes | **40-60% faster** | Component-specific tests |\n| **Complex/mixed changes** | ~5+ minutes | ~5+ minutes | Maintains coverage | Full test suite |\n\n### üéØ Smart Categorization\n\nThe system categorizes changes into:\n\n- **`docs`**: Documentation files (`*.md`, `*.rst`, `docs/`, config files)\n- **`superanimal`**: ModelZoo and SuperAnimal components (`deeplabcut/modelzoo/`, `*superanimal*`)\n- **`core`**: Core DeepLabCut functionality (`deeplabcut/core/`, `deeplabcut/pose_estimation_*/`)\n- **`multianimal`**: Multi-animal specific features (`*multianimal*`, `*multi*`)\n- **`video`**: Video processing components (`*video*`, prediction APIs)\n- **`tools`**: Development tools (`tools/`)\n\n## Usage Examples\n\n```bash\n# Analyze current changes and show what tests would run\npython tools/test_selector.py --dry-run\n\n# Get JSON output for CI integration\npython tools/test_selector.py --output-json --base main\n\n# Validate the system works correctly\npython tools/validate_test_selection.py\n\n# Test documentation build independently  \npython tools/test_docs_build.py\n```\n\n## Example Scenarios\n\n### Documentation-only PR\n```bash\n$ python tools/test_selector.py --dry-run\nüìÅ Found 1 changed files: docs/installation.md\nüìÇ Categories: docs\nüß™ Tests to run: python tools/test_docs_build.py\n‚è±Ô∏è  Estimated runtime: 1-2 minutes\n```\n\n### SuperAnimal model changes\n```bash\n$ python tools/test_selector.py --dry-run  \nüìÅ Found 3 changed files: deeplabcut/modelzoo/superanimal_*.py\nüìÇ Categories: superanimal\nüß™ Tests to run: pytest tests/test_predict_supermodel.py tests/pose_estimation_pytorch/modelzoo/\n‚è±Ô∏è  Estimated runtime: 3-4 minutes\n```\n\n### Mixed/complex changes\n```bash\n$ python tools/test_selector.py --dry-run\nüìÅ Found 12 changed files across multiple components\nüìÇ Categories: core, superanimal, video, uncategorized  \nüß™ Tests to run: python examples/testscript.py, pytest\n‚è±Ô∏è  Estimated runtime: 5+ minutes (full test suite)\n```\n\n## Integration\n\nThe system integrates seamlessly with the existing CI pipeline:\n\n1. **Maintains backward compatibility** - Falls back to full test suite when unsure\n2. **Zero false negatives** - Never skips tests that should run for a given change\n3. **Conservative approach** - Prefers running extra tests over missing important ones\n4. **JSON API** - Easy integration with GitHub Actions and other CI systems\n\n## Validation\n\nThe implementation includes comprehensive validation:\n\n```bash\n$ python tools/validate_test_selection.py\nüéâ SUCCESS: Intelligent test selection system is working correctly!\n\nKey Benefits:\n‚Ä¢ Documentation-only changes: ~1-2 minutes (vs 5+ minutes)\n‚Ä¢ SuperAnimal changes: ~3-4 minutes (vs 5+ minutes)  \n‚Ä¢ Focused component changes: ~2-3 minutes (vs 5+ minutes)\n‚Ä¢ Complex changes: Falls back to full test suite (~5+ minutes)\n\nüìà Expected CI time reduction: 60-80% for focused changes\n```\n\n## Expected Impact\n\n- **60-80% reduction** in CI time for focused changes (docs, single components)\n- **Faster feedback** for developers on common change types\n- **Resource efficiency** - Reduced compute usage for GitHub Actions\n- **Maintained quality** - Full test coverage preserved for complex changes\n- **Developer experience** - Quicker iteration cycles for documentation and focused feature work\n\nThis implementation addresses the core requirement of reducing test suite runtime to approximately 5 minutes while intelligently adapting to the scope of changes in each pull request.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "open",
         "2025-07-05T19:48:04Z",
         null,
         null,
         "126897385",
         "https://api.github.com/repos/DeepLabCut/DeepLabCut",
         "https://github.com/DeepLabCut/DeepLabCut/pull/3046",
         "0",
         "1.0",
         "True",
         "CI/CD",
         "Development"
        ],
        [
         "12",
         "3136224160",
         "1923",
         "Add native ARM64 GitHub Actions runner support",
         "This PR implements native ARM64 GitHub Actions runners to replace QEMU emulation for better performance and reliability.\r\n\r\n## Changes Made\r\n\r\n### üöÄ Docker Image Builds (`push-image.yml`)\r\n- **Before**: All builds ran on `ubuntu-latest` with QEMU emulation for ARM64\r\n- **After**: Native builds using appropriate runners:\r\n  - AMD64 builds: `ubuntu-latest` \r\n  - ARM64 builds: `ubuntu-24.04-arm64`\r\n- **Removed**: QEMU setup step (no longer needed for native builds)\r\n- **Result**: Faster, more reliable ARM64 Docker image builds\r\n\r\n### üß™ Testing & Validation (`build.yml`)\r\n- **Before**: Tests only ran on `ubuntu-latest` (AMD64)\r\n- **After**: Matrix testing on both architectures:\r\n  - `ubuntu-latest` (AMD64)\r\n  - `ubuntu-24.04-arm64` (ARM64)\r\n- **Result**: Comprehensive cross-platform testing ensures code compatibility\r\n\r\n## Key Benefits\r\n\r\n- üèÉ‚Äç‚ôÇÔ∏è **Performance**: Native ARM64 execution vs emulated builds\r\n- üîç **Coverage**: Testing on both AMD64 and ARM64 platforms  \r\n- üõ†Ô∏è **Maintenance**: Cleaner workflows without QEMU complexity\r\n- üîÆ **Future-ready**: Uses latest GitHub Actions ARM64 runners\r\n\r\n## Technical Details\r\n\r\nThe changes use GitHub's native ARM64 runners ([ubuntu-24.04-arm](https://github.com/actions/partner-runner-images/blob/main/images/arm-ubuntu-24-image.md)) which provide:\r\n- Better performance than QEMU emulation\r\n- Native ARM64 instruction execution\r\n- More reliable builds for ARM64 Docker images\r\n\r\n**Impact**: Minimal changes (8 additions, 8 deletions) with no breaking changes to existing functionality.\r\n\r\nFixes #1922.\r\n\r\n> [!WARNING]\r\n>\r\n> <details>\r\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\r\n>\r\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\r\n>\r\n> - `api.github.com`\r\n>   - Triggering command: `node download.js ` (dns block)\r\n> - `api.nektosact.com`\r\n>   - Triggering command: `act --list ` (dns block)\r\n>   - Triggering command: `act --list --workflows=.github/workflows/build.yml ` (dns block)\r\n>   - Triggering command: `act --list --workflows=.github/workflows/push-image.yml ` (dns block)\r\n>\r\n> If you need me to access, download, or install something from one of these locations, you can either:\r\n>\r\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\r\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\r\n>\r\n> </details>\r\n\r\n\r\n---\r\n\r\nblocked by #1926 \r\n\r\n---\r\n\r\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "open",
         "2025-06-11T09:58:23Z",
         null,
         null,
         "35017238",
         "https://api.github.com/repos/hackmdio/codimd",
         "https://github.com/hackmdio/codimd/pull/1923",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "13",
         "3081185488",
         "34496",
         "[EngSys] Enable rush build cache for @typespec/ts-http-runtime",
         "This PR enables the rush build cache for the `@typespec/ts-http-runtime` package by adding a `rush-project.json` file to the package's config directory. This configuration allows the package to benefit from Rush's build caching system, which will improve build times since many packages depend on this one.\n\n## Changes made\n\n- Added `/sdk/core/ts-http-runtime/config/rush-project.json` that extends the common rush-project.json configuration\n- Verified the build cache works by running multiple builds and confirming the cache hits\n\n## Why this matters\n\nThe `@typespec/ts-http-runtime` package is a core package that many other packages depend on. Enabling build caching for it will improve the repository's build performance, especially in CI scenarios, because the package will only need to be rebuilt when actual changes are made to it.\n\nFixes #34495.\n\n> [!WARNING]\n>\n> <details>\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\n>\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\n>\n> - `azuresdkartifacts.blob.core.windows.net`\n>   - Triggering command: `node /usr/local/bin/rush build --to @typespec/ts-http-runtime --verbose ` (dns block)\n> - `cdn.playwright.dev`\n>   - Triggering command: `/usr/local/bin/node /home/REDACTED/work/azure-sdk-for-js/azure-sdk-for-js/common/temp/node_modules/.pnpm/playwright-core@1.52.0/node_modules/playwright-core/lib/server/registry/oopDownloadBrowserMain.js ` (dns block)\n> - `playwright.download.prss.microsoft.com`\n>   - Triggering command: `/usr/local/bin/node /home/REDACTED/work/azure-sdk-for-js/azure-sdk-for-js/common/temp/node_modules/.pnpm/playwright-core@1.52.0/node_modules/playwright-core/lib/server/registry/oopDownloadBrowserMain.js ` (dns block)\n>\n> If you need me to access, download, or install something from one of these locations, you can either:\n>\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\n>\n> </details>\n\n\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-05-21T19:14:06Z",
         "2025-05-27T17:28:10Z",
         "2025-05-27T17:28:10Z",
         "108311273",
         "https://api.github.com/repos/Azure/azure-sdk-for-js",
         "https://github.com/Azure/azure-sdk-for-js/pull/34496",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "14",
         "3198732250",
         "16551",
         "Rewrite dev/preview_docs.py in JavaScript to simplify preview-docs workflow",
         "This PR rewrites the `dev/preview_docs.py` Python script in JavaScript to simplify the preview-docs workflow and eliminate unnecessary dependencies.\n\n## Problem\n\nThe current `preview-docs.yml` workflow required both Node.js (for Netlify deployment) and Python (for PR comment management), leading to:\n- Slower CI runs due to Python environment setup\n- Additional dependency management (`pip install requests`)\n- Workflow complexity with multiple language environments\n\n## Solution\n\nReplaced the Python script with a JavaScript implementation that uses the `github-script` action:\n\n### Changes Made\n\n1. **Created `.github/workflows/preview-docs.js`** - JavaScript version with identical functionality\n2. **Updated `.github/workflows/preview-docs.yml`** - Replaced Python script calls with `github-script` actions  \n3. **Removed `dev/preview_docs.py`** - Original Python script no longer needed\n\n### Key Benefits\n\n‚úÖ **Faster CI runs** - Eliminates `setup-python` action  \n‚úÖ **Fewer dependencies** - No more `pip install requests`  \n‚úÖ **Simpler workflow** - Uses built-in GitHub API access  \n‚úÖ **Consistency** - Follows existing JavaScript patterns in the repository  \n‚úÖ **100% compatibility** - Maintains same comment templates and behavior  \n\n### Technical Details\n\nThe JavaScript implementation preserves all original functionality:\n- Same `<!-- documentation preview -->` marker system\n- Handles both \"completed\" and \"failed\" stages\n- Creates/updates PR comments with identical templates\n- Uses the same GitHub API endpoints and error handling\n\n### Before/After Comparison\n\n**Before:**\n```yaml\n- uses: ./.github/actions/setup-python\n- name: Install dependencies\n  run: pip install requests\n- name: Create preview link\n  run: |\n    python dev/preview_docs.py \\\n      --commit-sha ${{ github.event.workflow_run.head_sha }} \\\n      --pull-number $PR_NUMBER \\\n      # ... other args\n```\n\n**After:**\n```yaml\n- name: Create preview link\n  uses: actions/github-script@60a0d83039c74a4aee543508d2ffcb1c3799cdea\n  env:\n    COMMIT_SHA: ${{ github.event.workflow_run.head_sha }}\n    PULL_NUMBER: ${{ github.event.workflow_run.pull_requests[0].number }}\n    # ... other env vars\n  with:\n    script: |\n      const script = require(`${process.env.GITHUB_WORKSPACE}/.github/workflows/preview-docs.js`);\n      await script({ context, github, env: process.env });\n```\n\nThis addresses the TODO comment in the original Python script:\n```python\n# TODO: rewrite this in JavaScript so we don't have to setup both node (to deploy to netlify)\n# and python (to upsert pr comments with this script)\n```\n\nFixes #16550.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-03T09:36:27Z",
         "2025-07-03T23:42:18Z",
         "2025-07-03T23:42:18Z",
         "136202695",
         "https://api.github.com/repos/mlflow/mlflow",
         "https://github.com/mlflow/mlflow/pull/16551",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "15",
         "3154652967",
         "49459",
         "Make GenerateDepsFile and GenerateRuntimeConfigurationFiles tasks internally-incremental",
         "The `GenerateDepsFile` and `GenerateRuntimeConfigurationFiles` tasks were always writing new output files, even when the content was identical to existing files. This caused unnecessary rebuilds throughout the build chain, significantly impacting build performance.\n\n## Changes Made\n\n**GenerateDepsFile.cs:**\n- Modified `WriteDepsFile()` method to generate content in memory first\n- Added XxHash64-based comparison with existing file content\n- Only writes the file when content actually differs\n- Preserves all existing validation logic\n\n**GenerateRuntimeConfigurationFiles.cs:**\n- Modified `WriteToJsonFile()` method to use the same incremental approach\n- Generates JSON content in memory before comparing with existing file\n- Uses XxHash64 for fast content comparison\n\n## Implementation Details\n\n- Uses `System.IO.Hashing.XxHash64` for efficient content comparison (package already referenced)\n- Generates output content in memory to compare against existing files\n- Maintains identical output format and all existing functionality\n- Handles edge cases: non-existent files, empty content, large files\n\n## Testing\n\nAdded comprehensive unit tests that verify:\n- Files are not rewritten when content is unchanged (timestamp preservation)\n- Files are properly updated when content changes\n- First-time file creation works correctly\n\n## Performance Impact\n\nThis change eliminates unnecessary file writes that were causing cascading rebuilds. Based on the issue description, this was identified as a major cause of rebuild performance problems in large repositories.\n\n## Example Behavior\n\n**Before:** Task always writes file, causing downstream rebuilds\n```\nGenerateDepsFile -> writes deps.json (even if identical) -> triggers dependent tasks\n```\n\n**After:** Task only writes when content changes\n```\nGenerateDepsFile -> compares content -> skips write if identical -> no unnecessary rebuilds\n```\n\nFixes #49349.\n\n> [!WARNING]\n>\n> <details>\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\n>\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\n>\n> - `7tjvsblobprodcus341.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `c78vsblobprodcus322.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `d0svsblobprodcus381.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `jd4vsblobprodcus366.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `l49vsblobprodcus358.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `lylvsblobprodcus31.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `/home/REDACTED/work/sdk/sdk/.dotnet/dotnet msbuild /m /nologo /clp:Summary /v:minimal /nr:true /warnaserror /p:TreatWarningsAsErrors=true /p:ContinuousIntegrationBuild=false /home/REDACTED/work/sdk/sdk/artifacts/toolset/restore.proj /t:__WriteToolsetLocation /clp:ErrorsOnly;NoSummary /p:__ToolsetLocationOutputFile=/home/REDACTED/work/sdk/sdk/artifacts/toolset/10.0.0-beta.25316.103.txt ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `uy6vsblobprodcus34.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `vb4vsblobprodcus33.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n>\n> If you need me to access, download, or install something from one of these locations, you can either:\n>\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\n>\n> </details>\n\n\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-06-17T20:14:14Z",
         "2025-06-27T00:02:00Z",
         "2025-06-27T00:02:00Z",
         "63984307",
         "https://api.github.com/repos/dotnet/sdk",
         "https://github.com/dotnet/sdk/pull/49459",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "16",
         "3236198682",
         "3430",
         "Improve docs asset caching and lint",
         "## Summary\n- exclude Insight browser tests from ESLint\n- cache browser assets for docs jobs and download if missing\n- build sandbox image in docs-build job\n\n## Testing\n- `pre-commit run --files .github/workflows/ci.yml .pre-commit-config.yaml`\n- `pytest -k smoke -q`\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6877b262fc2c833398e3e15d653e6495",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-16T14:25:42Z",
         "2025-07-16T14:26:03Z",
         "2025-07-16T14:26:03Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3430",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "17",
         "3226716187",
         "3305",
         "Fix Node cache paths",
         "## Summary\n- cache Node dependencies properly in build-and-test and size-check workflows\n\n## Testing\n- `pre-commit run --files .github/workflows/build-and-test.yml .github/workflows/size-check.yml .github/workflows/ci.yml .github/workflows/docs.yml`\n- `python scripts/check_python_deps.py`\n- `python check_env.py --auto-install`\n- `pytest tests/test_ping_agent.py tests/test_af_requests.py --cov --cov-report=xml`\n\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6873f7562e188333badc4c4205818047",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-13T18:23:33Z",
         "2025-07-13T18:23:43Z",
         "2025-07-13T18:23:43Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3305",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "18",
         "3265755131",
         "3785",
         "[alpha_factory] improve test cache paths",
         "## Summary\n- update `cache-dependency-path` for the tests job\n\n## Testing\n- `pre-commit run --files .github/workflows/ci.yml`\n- `pytest -q` *(fails: test suite failures)*\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6884e5cc4c1c8333939d23673c3dd6e2",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-26T14:38:04Z",
         "2025-07-26T14:38:32Z",
         "2025-07-26T14:38:32Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3785",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "19",
         "3127377495",
         "558",
         "üë∑ Enable Docker BuildKit caching",
         "## Summary\n- enable Docker Buildx cache via GitHub Actions\n- revert Dockerfile cache mounts\n- document the workflow improvement in a changeset\n\n## Testing\n- `pnpm lint`\n- `pnpm test:unit` *(fails: fetch failed)*\n\n------\nhttps://chatgpt.com/codex/tasks/task_b_684487ed13888323959b7285586b85b0",
         "OpenAI_Codex",
         "5880908",
         "wei",
         "closed",
         "2025-06-07T18:55:16Z",
         "2025-06-07T19:01:32Z",
         "2025-06-07T19:01:32Z",
         "297803332",
         "https://api.github.com/repos/wei/socialify",
         "https://github.com/wei/socialify/pull/558",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "20",
         "3207425781",
         "74",
         "Optimize CI workflow with Cargo.lock-based caching for faster builds",
         "## üöÄ Problem\n\nThe CI workflow was not utilizing optimal caching strategies, leading to:\n- Redundant dependency downloads across jobs\n- Repeated compilation of unchanged code\n- Longer build times due to lack of cache sharing between jobs\n\n## üîß Solution\n\nAdded intelligent caching to the CI workflow with the following optimizations:\n\n### 1. Cache Key Based on Cargo.lock Hash\n```yaml\n- uses: ./.github/actions/setup\n  with:\n    cache-shared-key: rustfs-ci-${{ hashFiles('**/Cargo.lock') }}\n```\n\n### 2. Consistent Cache Sharing\nBoth `develop` and `s3s-e2e` jobs now use the same cache key pattern, enabling:\n- Shared dependency cache between jobs\n- Shared compilation artifacts\n- Reduced redundant work\n\n### 3. Dependency-Based Cache Invalidation\nCache is automatically invalidated only when:\n- Dependencies change (Cargo.lock modified)\n- New commits on main branch\n\n## üìä Performance Impact\n\n**Build Time Comparison:**\n- **Cold build** (no cache): ~3m 42s\n- **Warm build** (with cache): ~0.5s\n- **Improvement**: ~99.8% reduction in cached build time\n\n## üîç Technical Details\n\nThe optimization leverages the existing `Swatinem/rust-cache@v2` action which automatically caches:\n- `~/.cargo/registry` (downloaded dependencies)\n- `~/.cargo/git` (git dependencies)\n- `target/` directory (compiled artifacts)\n\n### Before:\n```yaml\n- uses: ./.github/actions/setup\n  # No cache sharing between jobs\n```\n\n### After:\n```yaml\n- uses: ./.github/actions/setup\n  with:\n    cache-shared-key: rustfs-ci-${{ hashFiles('**/Cargo.lock') }}\n```\n\n## ‚úÖ Validation\n\n- [x] YAML syntax validation passed\n- [x] Cache key consistency verified across jobs\n- [x] Deterministic cache key generation confirmed\n- [x] Build time improvements validated locally\n\n## üéØ Expected Benefits\n\n1. **Faster CI builds** - Significant time savings on subsequent builds\n2. **Reduced GitHub Actions minutes** - Lower costs for the project\n3. **Better developer experience** - Faster feedback on PRs\n4. **Efficient cache usage** - Cache only invalidates when dependencies actually change\n\nThis change implements the optimization requirements specified in the issue while maintaining minimal, surgical modifications to the existing workflow.\n\n> [!WARNING]\n>\n> <details>\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\n>\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\n>\n> - `esm.ubuntu.com`\n>   - Triggering command: `/usr/lib/apt/methods/https` (dns block)\n>\n> If you need me to access, download, or install something from one of these locations, you can either:\n>\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\n>\n> </details>\n\n\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-07T03:29:07Z",
         "2025-07-07T03:31:54Z",
         null,
         "722597620",
         "https://api.github.com/repos/rustfs/rustfs",
         "https://github.com/rustfs/rustfs/pull/74",
         "0",
         "1.0",
         "True",
         "CI/CD",
         "Development"
        ],
        [
         "21",
         "3230266030",
         "3361",
         "[alpha_factory] cache web assets on Windows",
         "## Summary\n- cache web assets on the Windows smoke job\n\n## Testing\n- `pre-commit run --files .github/workflows/ci.yml`\n- `python scripts/check_python_deps.py`\n- `python check_env.py --auto-install`\n- `pytest tests/test_ping_agent.py tests/test_af_requests.py --cov --cov-report=xml`\n- `pytest --cov --cov-report=xml` *(fails: 84 failed, 257 passed, 58 skipped, 5 errors)*\n\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_68758c38fde883339bcf7d9327b3e2ae",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-14T23:12:48Z",
         "2025-07-14T23:12:58Z",
         "2025-07-14T23:12:58Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3361",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "22",
         "3216660550",
         "3147",
         "ci: cache docs sandbox build",
         "## Summary\n- avoid repeated installs by installing docs deps first\n- cache sandbox Docker build layers with buildx\n\n## Testing\n- `pre-commit run --files .github/workflows/docs.yml`\n- `python scripts/check_python_deps.py`\n- `pytest tests/test_ping_agent.py tests/test_af_requests.py -q`\n\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_686ea4e4659083339dbe0f6e8b68c662",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-09T17:33:21Z",
         "2025-07-09T17:33:30Z",
         "2025-07-09T17:33:30Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3147",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "23",
         "3205530993",
         "2996",
         "[alpha_factory] enable caching in docs workflow",
         "## Summary\n- reuse pip and npm caches in docs workflow\n\n## Testing\n- `python scripts/check_python_deps.py`\n- `python check_env.py --auto-install`\n- `pytest -q` *(fails: 29 errors during collection)*\n- `pre-commit run --files .github/workflows/docs.yml`\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_68698693ac188333b971a3b68821ddc9",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-05T20:15:39Z",
         "2025-07-05T20:15:57Z",
         "2025-07-05T20:15:57Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/2996",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "24",
         "3226740556",
         "3307",
         "Ensure ci.yml caches node deps correctly",
         "## Summary\n- document that ci.yml caches Node dependencies properly\n\n## Testing\n- `pre-commit run --files docs/CHANGELOG.md`\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6873fd9168608333ba696d0c2db93b0f",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-13T18:55:15Z",
         "2025-07-13T18:55:25Z",
         "2025-07-13T18:55:25Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3307",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "25",
         "3226639901",
         "3298",
         "[alpha_factory] streamline npm caching",
         "## Summary\n- use `setup-node` caching in Windows smoke job\n\n## Testing\n- `python scripts/check_python_deps.py`\n- `python check_env.py --auto-install`\n- `pytest --cov --cov-report=xml` *(failed: KeyboardInterrupt)*\n- `pre-commit run --files .github/workflows/ci.yml` *(failed: KeyboardInterrupt)*\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6873dd73c27c833397fec901347c0cdd",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-13T16:32:44Z",
         "2025-07-13T16:32:53Z",
         "2025-07-13T16:32:53Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3298",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "26",
         "3217792013",
         "3173",
         "[alpha_factory] cache pip & npm in size workflow",
         "## Summary\n- cache Python and Node dependencies in size-check workflow\n- explain new cache in README\n- note cache update in changelog\n\n## Testing\n- `pre-commit run --files .github/workflows/size-check.yml README.md docs/CHANGELOG.md`\n- `pytest -q tests/test_checksum.py` *(fails: ImportError: sentence-transformers missing)*\n\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_686f35f138608333a292795c7ed33d47",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-10T03:57:46Z",
         "2025-07-10T03:57:55Z",
         "2025-07-10T03:57:55Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3173",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "27",
         "3124462300",
         "13297",
         "Cricleci: establish babel cache",
         "inspired by https://www.charpeni.com/blog/speeding-up-eslint-even-on-ci",
         "OpenAI_Codex",
         "1683175",
         "patmmccann",
         "closed",
         "2025-06-06T11:08:50Z",
         "2025-06-06T11:11:51Z",
         null,
         "39321023",
         "https://api.github.com/repos/prebid/Prebid.js",
         "https://github.com/prebid/Prebid.js/pull/13297",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "28",
         "3239729604",
         "3469",
         "ci: cache node setup in lint job",
         "## Summary\n- update lint job to install Node.js with caching before using pre-commit\n\n## Testing\n- `pre-commit run --files .github/workflows/ci.yml` *(failed: KeyboardInterrupt during environment initialization)*\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_687900d5e2388333b4cc4e51a8c243ab",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-17T14:05:43Z",
         "2025-07-17T14:06:09Z",
         "2025-07-17T14:06:09Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3469",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "29",
         "3205789456",
         "3002",
         "[alpha_factory] add restore-keys to docs asset cache",
         "## Summary\n- allow cache fallback in docs workflow by adding `restore-keys`\n\n## Testing\n- `pre-commit run --files .github/workflows/docs.yml`\n- `python scripts/check_python_deps.py`\n- `python check_env.py --auto-install`\n- `pytest -q` *(fails: ImportError: cannot import name 'research_agent')*\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6869b2ac296c8333b3a30c40b02b045d",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-05T23:24:40Z",
         "2025-07-05T23:24:49Z",
         "2025-07-05T23:24:49Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3002",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "30",
         "3124244377",
         "13295",
         "Codex/implement eslint caching strategy on ci",
         "<!--\r\nThank you for your pull request! \r\n\r\nPlease title your pull request like this: 'Module: Change', eg 'Fraggles Bid Adapter: support fragglerock'\r\n\r\nPlease make sure this PR is scoped to one change or you may be asked to resubmit. \r\n \r\nPlease make sure any added or changed code includes tests with greater than 80% code coverage. \r\n\r\nSee https://github.com/prebid/Prebid.js/blob/master/CONTRIBUTING.md#testing-prebidjs for documentation on testing Prebid.js.\r\n\r\nFor any user facing change, submit a link to a PR on the docs repo at https://github.com/prebid/prebid.github.io/\r\n-->\r\n\r\n## Type of change\r\n<!-- Remove items that don't apply and/or select an item by changing [ ] to [x] -->\r\n- [ ] Bugfix\r\n- [ ] Feature\r\n- [ ] New bidder adapter  <!--  IMPORTANT: also submit your bidder parameter documentation as noted in https://docs.prebid.org/dev-docs/bidder-adaptor.html#submitting-your-adapter -->\r\n- [ ] Updated bidder adapter  <!--  IMPORTANT: (1) consider whether you need to upgrade your bidder parameter documentation in https://github.com/prebid/prebid.github.io/tree/master/dev-docs/bidders and (2) if you have a Prebid Server adapter, please consider whether that should be updated as well. --> \r\n- [ ] Code style update (formatting, local variables)\r\n- [ ] Refactoring (no functional changes, no api changes)\r\n- [ ] Build related changes\r\n- [ ] CI related changes\r\n\r\n- [ ] Does this change affect user-facing APIs or examples documented on http://prebid.org?\r\n- [ ] Other\r\n\r\n## Description of change\r\n<!-- Describe the change proposed in this pull request -->\r\n\r\n<!-- For new bidder adapters, please provide the following\r\n- contact email of the adapter‚Äôs maintainer\r\n- test parameters for validating bids:\r\n```\r\n{\r\n  bidder: '<bidder name>',\r\n  params: {\r\n    // ...\r\n  }\r\n}\r\n```\r\n\r\nBe sure to test the integration with your adserver using the [Hello World](https://github.com/prebid/Prebid.js/blob/master/integrationExamples/gpt/hello_world.html) sample page. -->\r\n\r\n\r\n## Other information\r\n<!-- References to related PR or issue #s, @mentions of the person or team responsible for reviewing changes, etc. -->\r\n",
         "OpenAI_Codex",
         "1683175",
         "patmmccann",
         "closed",
         "2025-06-06T09:44:20Z",
         "2025-06-06T09:44:55Z",
         null,
         "39321023",
         "https://api.github.com/repos/prebid/Prebid.js",
         "https://github.com/prebid/Prebid.js/pull/13295",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "31",
         "3218881690",
         "3176",
         "[alpha_factory] enhance browser size workflow caches",
         "## Summary\n- reuse built-in pip cache via `actions/setup-python`\n- cache npm dependencies with `actions/setup-node`\n- mention updated caching approach in README\n- document workflow improvement in CHANGELOG\n\n## Testing\n- `pre-commit run --files .github/workflows/size-check.yml README.md docs/CHANGELOG.md`\n- `pytest tests/test_ping_agent.py tests/test_af_requests.py -q`\n\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_686f7a1b1c208333954f08c34c3a1d10",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-10T11:01:36Z",
         "2025-07-10T11:01:51Z",
         "2025-07-10T11:01:51Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3176",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "32",
         "2839378596",
         "2358",
         "ci: optimize turbo build and test performance",
         "This PR optimizes the CI turbo build and test workflows to improve performance:\n\n1. Added Turbo Remote Caching to both workflows\n2. Added parallelism flags (--concurrency=10 --parallel) to build and test commands\n3. Optimized test task dependencies in turbo.json for better parallel execution\n\nCurrent performance:\n- Build time: ~4m45s\n- Test time: ~11m15s\n\nExpected improvements:\n- Build time should reduce to ~2-3m\n- Test time should reduce to ~6-7m\n\nLink to Devin run: https://app.devin.ai/sessions/0abc5bb855bf43bba64e2e62b057473d\nRequested by: Jayant",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-08T01:19:22Z",
         "2025-02-08T13:53:27Z",
         null,
         "425803244",
         "https://api.github.com/repos/pyth-network/pyth-crosschain",
         "https://github.com/pyth-network/pyth-crosschain/pull/2358",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "33",
         "2840213744",
         "2361",
         "ci: add turbo cache to build and test workflows",
         "# Add turbo cache to build and test workflows\n\nThis PR adds turborepo caching to both build and test workflows to speed up CI tasks, particularly those involving Rust compilation. The changes leverage GitHub's cache service through the turborepo caching action.\n\n## Changes\n- Added `rharkor/caching-for-turbo@v1.5` action to ci-turbo-build.yml\n- Added `rharkor/caching-for-turbo@v1.5` action to ci-turbo-test.yml\n\n## Implementation Details\n- Uses [Caching for Turborepo](https://github.com/marketplace/actions/caching-for-turborepo) GitHub action\n- Automatically sets up required environment variables (TURBO_API, TURBO_TOKEN, TURBO_TEAM)\n- Works alongside existing Rust cache for optimal performance\n- No changes to turbo configuration required\n\n## Testing Strategy\n- CI verification through existing build and test workflows\n- Cache effectiveness can be verified in workflow logs\n\nLink to Devin run: https://app.devin.ai/sessions/36cd61e59f9a4b1a970e8272ac1e29c9\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-08T19:04:24Z",
         "2025-02-08T19:43:09Z",
         "2025-02-08T19:43:09Z",
         "425803244",
         "https://api.github.com/repos/pyth-network/pyth-crosschain",
         "https://github.com/pyth-network/pyth-crosschain/pull/2361",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "34",
         "2926188053",
         "1630",
         "Migrate from chokidar to @parcel/watcher",
         "# Migrate from chokidar to @parcel/watcher\n\nThis PR migrates the file watching implementation from chokidar to @parcel/watcher in the RunManager class. The migration includes:\n\n1. Adding @parcel/watcher as a dependency\n2. Removing chokidar dependency\n3. Updating the RunManager class to use @parcel/watcher's API\n4. Modifying file watching logic to work with directories instead of individual files\n5. Updating event handling to match @parcel/watcher's event format\n\nThe migration provides improved file watching performance through native file system APIs.\n\nLink to Devin run: https://app.devin.ai/sessions/8ac6559d7e844d3a904abb0966dd468f\nRequested by: user\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-03-17T19:44:17Z",
         "2025-03-18T01:59:54Z",
         null,
         "820087727",
         "https://api.github.com/repos/onlook-dev/onlook",
         "https://github.com/onlook-dev/onlook/pull/1630",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "35",
         "2858986352",
         "1419",
         "Refactor: Implement automatic file watching",
         "# Implement automatic file watching\n\nReplace manual addFileToWatcher calls with automatic directory watching using Chokidar's built-in glob patterns. This improves efficiency while maintaining existing functionality.\n\nChanges:\n- Replace manual addFileToWatcher with glob-based watching\n- Add automatic watching of new files\n- Maintain existing file processing functionality\n- Improve performance with native glob patterns\n\nChanges were verified manually by:\n- Creating test files and verifying they're processed\n- Creating test Next.js pages and verifying they're processed\n- Starting project run and verifying all files are processed\n- Checking logs for any file watching errors\n\nLink to Devin run: https://app.devin.ai/sessions/0f7a1e1990d047f787a62ec95cd6779c\nUser: kiet@onlook.dev\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-17T23:50:05Z",
         "2025-02-26T16:48:14Z",
         null,
         "820087727",
         "https://api.github.com/repos/onlook-dev/onlook",
         "https://github.com/onlook-dev/onlook/pull/1419",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "36",
         "2838837697",
         "2351",
         "ci: add cargo caching to pre-commit workflow",
         "# Add Rust caching to pre-commit workflow\n\nThis PR adds caching for Rust dependencies and build artifacts to speed up pre-commit CI checks. The cache:\n- Stores cargo registry, git cache, and target directories\n- Uses a cache key based on:\n  - OS\n  - Cargo.lock files\n  - pre-commit config\n  - Rust toolchain versions\n- Includes fallback cache keys for partial matches\n\nLink to Devin run: https://app.devin.ai/sessions/659feaadc2d24d07854347f7ab39d3d5\nRequested by: Jayant\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-07T18:41:04Z",
         "2025-02-07T19:17:48Z",
         "2025-02-07T19:17:48Z",
         "425803244",
         "https://api.github.com/repos/pyth-network/pyth-crosschain",
         "https://github.com/pyth-network/pyth-crosschain/pull/2351",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "37",
         "2838992710",
         "2355",
         "feat: add rust-cache to all Rust workflows",
         "Added rust-cache to all workflows that run Rust commands to improve CI performance.\n\n- Added Swatinem/rust-cache@v2 to relevant workflows\n- Configured workspace paths for each workflow\n- Maintains existing workflow functionality\n- No changes to build/test logic\n\nLink to Devin run: https://app.devin.ai/sessions/4242c5568ced4883945111df80deb0c2\nRequested by: Jayant",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-07T20:02:06Z",
         "2025-02-07T20:28:54Z",
         "2025-02-07T20:28:54Z",
         "425803244",
         "https://api.github.com/repos/pyth-network/pyth-crosschain",
         "https://github.com/pyth-network/pyth-crosschain/pull/2355",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "38",
         "2759847657",
         "9356",
         "feat(ci): add Graphite CI optimizer to build-test workflow",
         "feat(ci): add Graphite CI optimizer to build-test workflow\n\nThis PR adds the Graphite CI optimizer to our build-test workflow to improve CI efficiency by skipping unnecessary jobs. Implementation follows the official Graphite documentation (https://graphite.dev/docs/stacking-and-ci).\n\nChanges:\n- Add Graphite CI optimizer job with token configuration\n- Update all jobs to depend on optimizer job\n- Add skip conditions based on optimizer output\n- Maintain existing job dependencies while adding optimizer\n\nTesting:\n- [x] Verified YAML syntax is valid\n- [x] Confirmed all jobs properly depend on the optimizer\n- [x] Maintained existing job dependencies\n- [ ] CI checks pending\n\nNote: This change requires the `GRAPHITE_CI_OPTIMIZER_TOKEN` secret to be configured in the repository settings.\n\nLink to Devin run: https://app.devin.ai/sessions/3872f4dc4c3341b899646a90c46c4fe3\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2024-12-26T14:41:32Z",
         "2024-12-27T02:52:17Z",
         null,
         "519859998",
         "https://api.github.com/repos/toeverything/AFFiNE",
         "https://github.com/toeverything/AFFiNE/pull/9356",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "39",
         "2799302285",
         "2556",
         "chore(revert): optimize pnpm cache configuration",
         "edit: reverting most pnpm caching attempts",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-01-20T13:40:18Z",
         "2025-01-20T14:16:06Z",
         "2025-01-20T14:16:06Z",
         "826170402",
         "https://api.github.com/repos/elizaOS/eliza",
         "https://github.com/elizaOS/eliza/pull/2556",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "40",
         "3125906822",
         "13951",
         "Add Turborepo configuration and scripts for improved monorepo management",
         "I implemented Turborepo support to optimize build times across the monorepo. I added `turbo@2.5.4` as a dev dependency and created a `turbo.json` configuration file with optimized task definitions for build, dev, lint, and test commands. In the root `package.json`, I added new turbo-specific scripts (`turbo:dev`, `turbo:build`, `turbo:lint`, `turbo:test`) and set the `packageManager` field to `yarn@1.22.22`. I configured caching by adding `.turbo` to `.gitignore`. The `turbo.json` includes task configurations with proper dependency chains, output caching for `.next/**` and `dist/**` directories, and environment variable handling. The setup enables parallel task execution and intelligent caching across workspaces, significantly improving build performance especially for unchanged code.",
         "Cursor",
         "23610",
         "dcramer",
         "open",
         "2025-06-06T21:29:48Z",
         null,
         null,
         "33837371",
         "https://api.github.com/repos/getsentry/sentry-docs",
         "https://github.com/getsentry/sentry-docs/pull/13951",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "41",
         "3191085425",
         "7585",
         "Improve dev server performance and report",
         "## What does this PR do?\n\nThis PR introduces several optimizations to significantly speed up the Langfuse development server startup time. It provides:\n\n*   A comprehensive guide (`FAST_DEV_SETUP.md`) detailing immediate and recommended steps to improve dev server performance.\n*   An optimized Next.js configuration (`web/next.config.fast-dev.mjs`) specifically tailored for faster development, which disables heavy monitoring tools (Sentry, OpenTelemetry, DataDog) and expensive webpack optimizations in development mode.\n*   A report on benchmark findings (`dev-server-benchmarks.md`) and analysis of performance bottlenecks.\n\nThe primary goal is to reduce the dev server startup time from ~53 seconds to an estimated 30-35 seconds (or even 15-20 seconds with all recommendations applied), improving the developer experience.\n\nFixes # (issue)\n\n## Type of change\n\n- [ ] Bug fix (non-breaking change which fixes an issue)\n- [ ] Chore (refactoring code, technical debt, workflow improvements)\n- [x] New feature (non-breaking change which adds functionality)\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\n- [x] Refactor (does not change functionality, e.g. code style improvements, linting)\n- [x] This change requires a documentation update\n\n## Mandatory Tasks\n\n- [x] Make sure you have self-reviewed the code. A decent size PR without self-review might be rejected.\n\n## Checklist\n\n- [ ] I haven't read the [contributing guide](https://github.com/langfuse/langfuse/blob/main/CONTRIBUTING.md)\n- [ ] My code doesn't follow the style guidelines of this project (`npm run prettier`)\n- [x] I haven't commented my code, particularly in hard-to-understand areas\n- [x] I haven't checked if my PR needs changes to the documentation\n- [ ] I haven't checked if my changes generate no new warnings (`npm run lint`)\n- [ ] I haven't added tests that prove my fix is effective or that my feature works\n- [ ] I haven't checked if new and existing unit tests pass locally with my changes",
         "Cursor",
         "2834609",
         "marcklingen",
         "open",
         "2025-07-01T07:19:19Z",
         null,
         null,
         "642497346",
         "https://api.github.com/repos/langfuse/langfuse",
         "https://github.com/langfuse/langfuse/pull/7585",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "42",
         "3217652543",
         "244",
         "Analyze and optimize code performance",
         "Update Gradle build configuration to enable successful builds and improve build times.\n\nThese changes resolve build failures related to an outdated JVM argument (`MaxPermSize` replaced by `MaxMetaspaceSize`) and a mandatory release signing configuration when the keystore is not present. Additionally, `org.gradle.parallel` is enabled to speed up subsequent builds.",
         "Cursor",
         "5333537",
         "gmathi",
         "closed",
         "2025-07-10T02:21:06Z",
         "2025-07-10T02:21:55Z",
         "2025-07-10T02:21:54Z",
         "92864511",
         "https://api.github.com/repos/gmathi/NovelLibrary",
         "https://github.com/gmathi/NovelLibrary/pull/244",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "43",
         "3226629209",
         "3297",
         "Update Node cache for Docker job",
         "## Summary\n- cache npm dependencies in the Docker build job\n\n## Testing\n- `pre-commit run --files .github/workflows/ci.yml`\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6873dae03e548333928a5753d030270a",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-13T16:22:50Z",
         "2025-07-13T16:23:03Z",
         "2025-07-13T16:23:03Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3297",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "44",
         "3096300821",
         "2691",
         "Update docs watcher to process changed files only",
         "NOTE: created with the help of codex\r\n\r\n## TLDR\r\nThis change updates our docs watcher to only process a single markdown file if it has been changed. The same is true for the examples. This should speed up docs development significantly.",
         "OpenAI_Codex",
         "1155738",
         "sh-rp",
         "closed",
         "2025-05-28T07:11:56Z",
         "2025-05-29T22:54:56Z",
         null,
         "452221115",
         "https://api.github.com/repos/dlt-hub/dlt",
         "https://github.com/dlt-hub/dlt/pull/2691",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "45",
         "3203378195",
         "2949",
         "[alpha_factory] cache browser assets",
         "## Summary\n- add asset cache steps to docs workflow\n- document cache usage in hosting instructions\n\n## Testing\n- `python scripts/check_python_deps.py`\n- `python check_env.py --auto-install`\n- `pytest -q` *(fails: 29 errors during collection)*\n- `pre-commit run --files .github/workflows/docs.yml docs/HOSTING_INSTRUCTIONS.md` *(failed: environment setup blocked)*\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_68680fb5b5348333885ea99b4ec2cdda",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-04T17:40:45Z",
         "2025-07-04T17:40:53Z",
         "2025-07-04T17:40:53Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/2949",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "46",
         "3124534701",
         "13298",
         "Circleci: setup persistent babel cache for tests",
         "persist babel cache between runs",
         "OpenAI_Codex",
         "1683175",
         "patmmccann",
         "closed",
         "2025-06-06T11:43:05Z",
         "2025-06-24T15:27:40Z",
         "2025-06-24T15:27:40Z",
         "39321023",
         "https://api.github.com/repos/prebid/Prebid.js",
         "https://github.com/prebid/Prebid.js/pull/13298",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "47",
         "2840011330",
         "2360",
         "ci: add rust cache to turbo test workflow",
         "# Description\nAdd Rust caching to the turbo test workflow to improve CI performance.\n\nThis PR:\n- Adds Rust caching using Swatinem/rust-cache@v2\n- Follows the same pattern as other Rust workflows in the repository\n- Does not modify the turbo build workflow as it doesn't use Rust\n\nLink to Devin run: https://app.devin.ai/sessions/6e20ec2b71cf44168007a02b34cb18be\nRequested by: Jayant",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-08T13:45:06Z",
         "2025-02-08T15:51:58Z",
         "2025-02-08T15:51:57Z",
         "425803244",
         "https://api.github.com/repos/pyth-network/pyth-crosschain",
         "https://github.com/pyth-network/pyth-crosschain/pull/2360",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "48",
         "2760327496",
         "9362",
         "ci: add graphite ci optimizer and update job dependencies",
         "feat(ci): add graphite ci optimizer and update job dependencies\n\nThis PR adds the Graphite CI optimizer to improve CI efficiency by skipping unnecessary jobs. All workflow jobs have been updated to depend on the optimizer's output.\n\nChanges:\n- Add `optimize_ci` job using graphite-ci-action\n- Update all jobs to depend on `optimize_ci`\n- Add skip conditions based on optimizer output\n- Preserve existing job dependencies while adding optimizer dependency\n- Handle Redis service configurations and command syntax updates\n\nNote: This PR requires the `GRAPHITE_CI_OPTIMIZER_TOKEN` secret to be configured in the repository settings before the optimizer can be used.\n\nTesting:\n- [x] Verified workflow file syntax\n- [x] Updated all job dependencies correctly\n- [x] Maintained existing job configurations\n\nLink to Devin run: https://app.devin.ai/sessions/3872f4dc4c3341b899646a90c46c4fe3\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2024-12-27T03:01:40Z",
         "2024-12-27T04:02:30Z",
         "2024-12-27T04:02:30Z",
         "519859998",
         "https://api.github.com/repos/toeverything/AFFiNE",
         "https://github.com/toeverything/AFFiNE/pull/9362",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "49",
         "2858841754",
         "2385",
         "chore: add cargo workspaces to rust-cache action",
         "Add all Cargo workspaces to the rust-cache action to improve cache hits.\n\nThis PR adds workspace paths for:\n- target_chains/{ethereum,cosmwasm,fuel,solana}\n- governance/remote_executor\n- lazer\n- pythnet/{message_buffer,stake_caps_parameters}\n\nLink to Devin run: https://app.devin.ai/sessions/9f3a6f18d9b74a86980bcf96f97d0e1d\nRequested by: Jayant\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-17T21:40:27Z",
         "2025-02-17T23:14:43Z",
         "2025-02-17T23:14:43Z",
         "425803244",
         "https://api.github.com/repos/pyth-network/pyth-crosschain",
         "https://github.com/pyth-network/pyth-crosschain/pull/2385",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 1120
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>agent</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user</th>\n",
       "      <th>state</th>\n",
       "      <th>created_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>merged_at</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2912546402</td>\n",
       "      <td>448</td>\n",
       "      <td>Add GitHub API caching to prevent rate limiting</td>\n",
       "      <td>- Create GitHub API caching script that handle...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>1021104</td>\n",
       "      <td>8enmann</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-03-12T03:51:34Z</td>\n",
       "      <td>2025-05-06T17:50:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>937253475</td>\n",
       "      <td>https://api.github.com/repos/anthropics/claude...</td>\n",
       "      <td>https://github.com/anthropics/claude-code/pull...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>CI/CD</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3216159293</td>\n",
       "      <td>110</td>\n",
       "      <td>Add vcpkg dependency caching to Windows CI wor...</td>\n",
       "      <td>## Overview\\n\\nThis PR implements vcpkg depend...</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>198982749</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-07-09T14:30:39Z</td>\n",
       "      <td>2025-07-09T16:47:00Z</td>\n",
       "      <td>2025-07-09T16:47:00Z</td>\n",
       "      <td>564439013</td>\n",
       "      <td>https://api.github.com/repos/pelicanmapping/rocky</td>\n",
       "      <td>https://github.com/pelicanmapping/rocky/pull/110</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>CI/CD</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3195588879</td>\n",
       "      <td>16531</td>\n",
       "      <td>Remove duplicate yarn eslint step from .circle...</td>\n",
       "      <td>&lt;details&gt;&lt;summary&gt;&amp;#x1F6E0 DevTools &amp;#x1F6E0&lt;/...</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>198982749</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-07-02T11:33:06Z</td>\n",
       "      <td>2025-07-02T12:24:50Z</td>\n",
       "      <td>2025-07-02T12:24:50Z</td>\n",
       "      <td>136202695</td>\n",
       "      <td>https://api.github.com/repos/mlflow/mlflow</td>\n",
       "      <td>https://github.com/mlflow/mlflow/pull/16531</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>CI/CD</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3074681764</td>\n",
       "      <td>13829</td>\n",
       "      <td>Update build documentation with quick build op...</td>\n",
       "      <td>This PR updates the build documentation (`tool...</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>198982749</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>open</td>\n",
       "      <td>2025-05-19T18:25:04Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281765424</td>\n",
       "      <td>https://api.github.com/repos/microsoft/azurelinux</td>\n",
       "      <td>https://github.com/microsoft/azurelinux/pull/1...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>CI/CD</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3159826481</td>\n",
       "      <td>184</td>\n",
       "      <td>[WIP] Support .coshrc compilation</td>\n",
       "      <td>Thanks for assigning this issue to me. I'm sta...</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>198982749</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-06-19T10:34:39Z</td>\n",
       "      <td>2025-06-26T11:59:32Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445862991</td>\n",
       "      <td>https://api.github.com/repos/tomhrr/cosh</td>\n",
       "      <td>https://github.com/tomhrr/cosh/pull/184</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>CI/CD</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>3144466175</td>\n",
       "      <td>4</td>\n",
       "      <td>Implement local storage persistence</td>\n",
       "      <td>A new persistence utility, `src/lib/persistenc...</td>\n",
       "      <td>Cursor</td>\n",
       "      <td>56125930</td>\n",
       "      <td>f1shy-dev</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-06-13T18:49:45Z</td>\n",
       "      <td>2025-06-13T18:49:52Z</td>\n",
       "      <td>2025-06-13T18:49:52Z</td>\n",
       "      <td>998301272</td>\n",
       "      <td>https://api.github.com/repos/intern3-chat/inte...</td>\n",
       "      <td>https://github.com/intern3-chat/intern3-chat/p...</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Chat System</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>3275952470</td>\n",
       "      <td>2777</td>\n",
       "      <td>fix: update schemaDesignTool to directly updat...</td>\n",
       "      <td>## Issue\\n\\n- resolve: Root cause issue where ...</td>\n",
       "      <td>Devin</td>\n",
       "      <td>158243242</td>\n",
       "      <td>devin-ai-integration[bot]</td>\n",
       "      <td>open</td>\n",
       "      <td>2025-07-30T07:15:24Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>839216423</td>\n",
       "      <td>https://api.github.com/repos/liam-hq/liam</td>\n",
       "      <td>https://github.com/liam-hq/liam/pull/2777</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Chat System</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>3074294403</td>\n",
       "      <td>320</td>\n",
       "      <td>Integrate chatAudioIO module</td>\n",
       "      <td># Integrate chatAudioIO module\\n\\nThis PR inte...</td>\n",
       "      <td>Devin</td>\n",
       "      <td>158243242</td>\n",
       "      <td>devin-ai-integration[bot]</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-05-19T15:42:40Z</td>\n",
       "      <td>2025-05-28T14:33:26Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374381865</td>\n",
       "      <td>https://api.github.com/repos/stack-chan/stack-...</td>\n",
       "      <td>https://github.com/stack-chan/stack-chan/pull/320</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Chat System</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>3058809612</td>\n",
       "      <td>1399</td>\n",
       "      <td>Fix: Cache system info to prevent re-fetching ...</td>\n",
       "      <td># Cache System Info to Prevent Re-fetching on ...</td>\n",
       "      <td>Devin</td>\n",
       "      <td>158243242</td>\n",
       "      <td>devin-ai-integration[bot]</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-05-13T05:33:38Z</td>\n",
       "      <td>2025-05-13T07:32:44Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>575321313</td>\n",
       "      <td>https://api.github.com/repos/langbot-app/LangBot</td>\n",
       "      <td>https://github.com/langbot-app/LangBot/pull/1399</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Chat System</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>3152003781</td>\n",
       "      <td>2037</td>\n",
       "      <td>Optimize Chat API/Job schema transfer by remov...</td>\n",
       "      <td># Optimize Chat API/Job schema transfer by rem...</td>\n",
       "      <td>Devin</td>\n",
       "      <td>158243242</td>\n",
       "      <td>devin-ai-integration[bot]</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-06-17T04:17:12Z</td>\n",
       "      <td>2025-06-17T07:08:49Z</td>\n",
       "      <td>2025-06-17T07:08:49Z</td>\n",
       "      <td>839216423</td>\n",
       "      <td>https://api.github.com/repos/liam-hq/liam</td>\n",
       "      <td>https://github.com/liam-hq/liam/pull/2037</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Chat System</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1120 rows √ó 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  number                                              title  \\\n",
       "0     2912546402     448    Add GitHub API caching to prevent rate limiting   \n",
       "1     3216159293     110  Add vcpkg dependency caching to Windows CI wor...   \n",
       "2     3195588879   16531  Remove duplicate yarn eslint step from .circle...   \n",
       "3     3074681764   13829  Update build documentation with quick build op...   \n",
       "4     3159826481     184                  [WIP] Support .coshrc compilation   \n",
       "...          ...     ...                                                ...   \n",
       "1115  3144466175       4                Implement local storage persistence   \n",
       "1116  3275952470    2777  fix: update schemaDesignTool to directly updat...   \n",
       "1117  3074294403     320                       Integrate chatAudioIO module   \n",
       "1118  3058809612    1399  Fix: Cache system info to prevent re-fetching ...   \n",
       "1119  3152003781    2037  Optimize Chat API/Job schema transfer by remov...   \n",
       "\n",
       "                                                   body        agent  \\\n",
       "0     - Create GitHub API caching script that handle...  Claude_Code   \n",
       "1     ## Overview\\n\\nThis PR implements vcpkg depend...      Copilot   \n",
       "2     <details><summary>&#x1F6E0 DevTools &#x1F6E0</...      Copilot   \n",
       "3     This PR updates the build documentation (`tool...      Copilot   \n",
       "4     Thanks for assigning this issue to me. I'm sta...      Copilot   \n",
       "...                                                 ...          ...   \n",
       "1115  A new persistence utility, `src/lib/persistenc...       Cursor   \n",
       "1116  ## Issue\\n\\n- resolve: Root cause issue where ...        Devin   \n",
       "1117  # Integrate chatAudioIO module\\n\\nThis PR inte...        Devin   \n",
       "1118  # Cache System Info to Prevent Re-fetching on ...        Devin   \n",
       "1119  # Optimize Chat API/Job schema transfer by rem...        Devin   \n",
       "\n",
       "        user_id                       user   state            created_at  \\\n",
       "0       1021104                    8enmann  closed  2025-03-12T03:51:34Z   \n",
       "1     198982749                    Copilot  closed  2025-07-09T14:30:39Z   \n",
       "2     198982749                    Copilot  closed  2025-07-02T11:33:06Z   \n",
       "3     198982749                    Copilot    open  2025-05-19T18:25:04Z   \n",
       "4     198982749                    Copilot  closed  2025-06-19T10:34:39Z   \n",
       "...         ...                        ...     ...                   ...   \n",
       "1115   56125930                  f1shy-dev  closed  2025-06-13T18:49:45Z   \n",
       "1116  158243242  devin-ai-integration[bot]    open  2025-07-30T07:15:24Z   \n",
       "1117  158243242  devin-ai-integration[bot]  closed  2025-05-19T15:42:40Z   \n",
       "1118  158243242  devin-ai-integration[bot]  closed  2025-05-13T05:33:38Z   \n",
       "1119  158243242  devin-ai-integration[bot]  closed  2025-06-17T04:17:12Z   \n",
       "\n",
       "                 closed_at             merged_at    repo_id  \\\n",
       "0     2025-05-06T17:50:00Z                   NaN  937253475   \n",
       "1     2025-07-09T16:47:00Z  2025-07-09T16:47:00Z  564439013   \n",
       "2     2025-07-02T12:24:50Z  2025-07-02T12:24:50Z  136202695   \n",
       "3                      NaN                   NaN  281765424   \n",
       "4     2025-06-26T11:59:32Z                   NaN  445862991   \n",
       "...                    ...                   ...        ...   \n",
       "1115  2025-06-13T18:49:52Z  2025-06-13T18:49:52Z  998301272   \n",
       "1116                   NaN                   NaN  839216423   \n",
       "1117  2025-05-28T14:33:26Z                   NaN  374381865   \n",
       "1118  2025-05-13T07:32:44Z                   NaN  575321313   \n",
       "1119  2025-06-17T07:08:49Z  2025-06-17T07:08:49Z  839216423   \n",
       "\n",
       "                                               repo_url  \\\n",
       "0     https://api.github.com/repos/anthropics/claude...   \n",
       "1     https://api.github.com/repos/pelicanmapping/rocky   \n",
       "2            https://api.github.com/repos/mlflow/mlflow   \n",
       "3     https://api.github.com/repos/microsoft/azurelinux   \n",
       "4              https://api.github.com/repos/tomhrr/cosh   \n",
       "...                                                 ...   \n",
       "1115  https://api.github.com/repos/intern3-chat/inte...   \n",
       "1116          https://api.github.com/repos/liam-hq/liam   \n",
       "1117  https://api.github.com/repos/stack-chan/stack-...   \n",
       "1118   https://api.github.com/repos/langbot-app/LangBot   \n",
       "1119          https://api.github.com/repos/liam-hq/liam   \n",
       "\n",
       "                                               html_url  Topic  Probability  \\\n",
       "0     https://github.com/anthropics/claude-code/pull...      0          1.0   \n",
       "1      https://github.com/pelicanmapping/rocky/pull/110      0          1.0   \n",
       "2           https://github.com/mlflow/mlflow/pull/16531      0          1.0   \n",
       "3     https://github.com/microsoft/azurelinux/pull/1...      0          1.0   \n",
       "4               https://github.com/tomhrr/cosh/pull/184      0          1.0   \n",
       "...                                                 ...    ...          ...   \n",
       "1115  https://github.com/intern3-chat/intern3-chat/p...     48          1.0   \n",
       "1116          https://github.com/liam-hq/liam/pull/2777     48          1.0   \n",
       "1117  https://github.com/stack-chan/stack-chan/pull/320     48          1.0   \n",
       "1118   https://github.com/langbot-app/LangBot/pull/1399     48          1.0   \n",
       "1119          https://github.com/liam-hq/liam/pull/2037     48          1.0   \n",
       "\n",
       "      Representative_document   topic_name     category  \n",
       "0                       False        CI/CD  Development  \n",
       "1                       False        CI/CD  Development  \n",
       "2                       False        CI/CD  Development  \n",
       "3                       False        CI/CD  Development  \n",
       "4                       False        CI/CD  Development  \n",
       "...                       ...          ...          ...  \n",
       "1115                    False  Chat System           AI  \n",
       "1116                     True  Chat System           AI  \n",
       "1117                    False  Chat System           AI  \n",
       "1118                    False  Chat System           AI  \n",
       "1119                     True  Chat System           AI  \n",
       "\n",
       "[1120 rows x 19 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "142e32b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "fill": "none",
         "name": "Claude_Code",
         "r": [
          12.5,
          4.201680672268908,
          6.557377049180328,
          1.1494252873563218,
          4.054054054054054,
          4.081632653061225,
          1.556420233463035,
          4.166666666666666,
          0,
          2.941176470588235
         ],
         "subplot": "polar",
         "theta": [
          "AI",
          "Algorithmic",
          "Analytics",
          "Caching",
          "Development",
          "Hardware",
          "Low-level",
          "Networking",
          "Query",
          "UI"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "none",
         "name": "Copilot",
         "r": [
          9.375,
          22.689075630252102,
          18.0327868852459,
          13.793103448275861,
          30.180180180180184,
          28.57142857142857,
          2.7237354085603114,
          25,
          4.918032786885246,
          20.588235294117645
         ],
         "subplot": "polar2",
         "theta": [
          "AI",
          "Algorithmic",
          "Analytics",
          "Caching",
          "Development",
          "Hardware",
          "Low-level",
          "Networking",
          "Query",
          "UI"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "none",
         "name": "Cursor",
         "r": [
          28.125,
          7.563025210084033,
          11.475409836065573,
          6.896551724137931,
          8.108108108108109,
          14.285714285714285,
          3.8910505836575875,
          9.375,
          4.918032786885246,
          8.088235294117647
         ],
         "subplot": "polar3",
         "theta": [
          "AI",
          "Algorithmic",
          "Analytics",
          "Caching",
          "Development",
          "Hardware",
          "Low-level",
          "Networking",
          "Query",
          "UI"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "none",
         "name": "Devin",
         "r": [
          25,
          21.008403361344538,
          32.78688524590164,
          20.689655172413794,
          18.01801801801802,
          6.122448979591836,
          0.38910505836575876,
          17.708333333333336,
          32.78688524590164,
          35.294117647058826
         ],
         "subplot": "polar4",
         "theta": [
          "AI",
          "Algorithmic",
          "Analytics",
          "Caching",
          "Development",
          "Hardware",
          "Low-level",
          "Networking",
          "Query",
          "UI"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "none",
         "name": "OpenAI_Codex",
         "r": [
          25,
          44.537815126050425,
          31.147540983606557,
          57.47126436781609,
          39.63963963963964,
          46.93877551020408,
          91.43968871595331,
          43.75,
          57.377049180327866,
          33.088235294117645
         ],
         "subplot": "polar5",
         "theta": [
          "AI",
          "Algorithmic",
          "Analytics",
          "Caching",
          "Development",
          "Hardware",
          "Low-level",
          "Networking",
          "Query",
          "UI"
         ],
         "type": "scatterpolar"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Claude_Code",
          "x": 0.08399999999999999,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Copilot",
          "x": 0.292,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Cursor",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Devin",
          "x": 0.708,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "OpenAI_Codex",
          "x": 0.9159999999999999,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "polar": {
         "domain": {
          "x": [
           0,
           0.16799999999999998
          ],
          "y": [
           0,
           1
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ]
         }
        },
        "polar2": {
         "domain": {
          "x": [
           0.208,
           0.376
          ],
          "y": [
           0,
           1
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ]
         }
        },
        "polar3": {
         "domain": {
          "x": [
           0.416,
           0.584
          ],
          "y": [
           0,
           1
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ]
         }
        },
        "polar4": {
         "domain": {
          "x": [
           0.624,
           0.792
          ],
          "y": [
           0,
           1
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ]
         }
        },
        "polar5": {
         "domain": {
          "x": [
           0.832,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "radialaxis": {
          "range": [
           0,
           100
          ]
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f",
           "family": "Times New Roman, Times, DejaVu Serif",
           "size": 14
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "legend": {
           "font": {
            "size": 14
           },
           "title": {
            "font": {
             "size": 14
            }
           }
          },
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "font": {
            "size": 14
           },
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "tickfont": {
            "size": 14
           },
           "ticks": "",
           "title": {
            "font": {
             "size": 14
            },
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "tickfont": {
            "size": 14
           },
           "ticks": "",
           "title": {
            "font": {
             "size": 14
            },
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = make_subplots(rows=1, cols=5, specs=[[{'type': 'polar'}]*5], subplot_titles=sorted(all_categories_df['agent'].unique()))\n",
    "#fig = go.Figure()\n",
    "\n",
    "i = 1\n",
    "for agent in sorted(all_categories_df['agent'].unique()):\n",
    "    sub = all_categories_df[all_categories_df[\"agent\"] == agent]\n",
    "    cat_groups = sub.groupby(\"category\")['id'].nunique().reset_index(name=\"count\").sort_values(by=\"category\", ascending=True)\n",
    "      \n",
    "    categories = []\n",
    "    counts = []\n",
    "\n",
    "    for cat in sorted(category_map.keys()):\n",
    "        if cat not in cat_groups['category'].values:\n",
    "            categories.append(cat)\n",
    "            counts.append(0)\n",
    "        else:\n",
    "            cat_count = cat_groups[cat_groups['category'] == cat]['count'].values[0]\n",
    "            categories.append(cat)\n",
    "            \n",
    "            total = all_categories_df[all_categories_df[\"category\"] == cat]['id'].nunique()\n",
    "            counts.append(cat_count/total * 100)\n",
    "        \n",
    "\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=counts,\n",
    "        theta=categories,\n",
    "        fill='none',\n",
    "        name=agent\n",
    "    ), row=1, col=i)\n",
    "    i += 1\n",
    "\n",
    "fig.update_polars(radialaxis=dict(range=[0, 100]))\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "# fig.update_layout(\n",
    "#     polar=dict(\n",
    "#         radialaxis=dict(\n",
    "#             visible=True,\n",
    "#             range=[0, 100]\n",
    "#         )\n",
    "#     ),\n",
    "#     showlegend=True,\n",
    "#     title_text=\"Comparison of Agent Performance Across Categories\"\n",
    "# )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cb3a52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "fill": "none",
         "line": {
          "color": "#CC79A7",
          "width": 3
         },
         "marker": {
          "size": 5,
          "symbol": "triangle-down"
         },
         "name": "Claude_Code",
         "r": [
          12.5,
          4.201680672268908,
          6.557377049180328,
          1.1494252873563218,
          4.054054054054054,
          4.081632653061225,
          1.556420233463035,
          4.166666666666666,
          0,
          2.941176470588235
         ],
         "theta": [
          "AI",
          "Algorithmic",
          "Analytics",
          "Caching",
          "Development",
          "Hardware",
          "Low-level",
          "Networking",
          "Query",
          "UI"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "none",
         "line": {
          "color": "#0072B2",
          "width": 3
         },
         "marker": {
          "size": 5,
          "symbol": "triangle-up"
         },
         "name": "Copilot",
         "r": [
          9.375,
          22.689075630252102,
          18.0327868852459,
          13.793103448275861,
          30.180180180180184,
          28.57142857142857,
          2.7237354085603114,
          25,
          4.918032786885246,
          20.588235294117645
         ],
         "theta": [
          "AI",
          "Algorithmic",
          "Analytics",
          "Caching",
          "Development",
          "Hardware",
          "Low-level",
          "Networking",
          "Query",
          "UI"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "none",
         "line": {
          "color": "#56B4E9",
          "width": 3
         },
         "marker": {
          "size": 5,
          "symbol": "x"
         },
         "name": "Cursor",
         "r": [
          28.125,
          7.563025210084033,
          11.475409836065573,
          6.896551724137931,
          8.108108108108109,
          14.285714285714285,
          3.8910505836575875,
          9.375,
          4.918032786885246,
          8.088235294117647
         ],
         "theta": [
          "AI",
          "Algorithmic",
          "Analytics",
          "Caching",
          "Development",
          "Hardware",
          "Low-level",
          "Networking",
          "Query",
          "UI"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "none",
         "line": {
          "color": "#009E73",
          "width": 3
         },
         "marker": {
          "size": 5,
          "symbol": "cross"
         },
         "name": "Devin",
         "r": [
          25,
          21.008403361344538,
          32.78688524590164,
          20.689655172413794,
          18.01801801801802,
          6.122448979591836,
          0.38910505836575876,
          17.708333333333336,
          32.78688524590164,
          35.294117647058826
         ],
         "theta": [
          "AI",
          "Algorithmic",
          "Analytics",
          "Caching",
          "Development",
          "Hardware",
          "Low-level",
          "Networking",
          "Query",
          "UI"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "none",
         "line": {
          "color": "#D55E00",
          "width": 3
         },
         "marker": {
          "size": 5,
          "symbol": "square"
         },
         "name": "OpenAI_Codex",
         "r": [
          25,
          44.537815126050425,
          31.147540983606557,
          57.47126436781609,
          39.63963963963964,
          46.93877551020408,
          91.43968871595331,
          43.75,
          57.377049180327866,
          33.088235294117645
         ],
         "theta": [
          "AI",
          "Algorithmic",
          "Analytics",
          "Caching",
          "Development",
          "Hardware",
          "Low-level",
          "Networking",
          "Query",
          "UI"
         ],
         "type": "scatterpolar"
        }
       ],
       "layout": {
        "legend": {
         "orientation": "h",
         "x": 0.5,
         "xanchor": "center",
         "y": -0.05,
         "yanchor": "top"
        },
        "margin": {
         "b": 40,
         "l": 0,
         "r": 0,
         "t": 30
        },
        "polar": {
         "radialaxis": {
          "range": [
           0,
           100
          ],
          "visible": true
         }
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f",
           "family": "Times New Roman, Times, DejaVu Serif",
           "size": 14
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "legend": {
           "font": {
            "size": 14
           },
           "title": {
            "font": {
             "size": 14
            }
           }
          },
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "font": {
            "size": 14
           },
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "tickfont": {
            "size": 14
           },
           "ticks": "",
           "title": {
            "font": {
             "size": 14
            },
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "tickfont": {
            "size": 14
           },
           "ticks": "",
           "title": {
            "font": {
             "size": 14
            },
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "i = 1\n",
    "for agent in sorted(all_categories_df['agent'].unique()):\n",
    "    sub = all_categories_df[all_categories_df[\"agent\"] == agent]\n",
    "    cat_groups = sub.groupby(\"category\")['id'].nunique().reset_index(name=\"count\").sort_values(by=\"category\", ascending=True)\n",
    "      \n",
    "    categories = []\n",
    "    counts = []\n",
    "\n",
    "    for cat in sorted(category_map.keys()):\n",
    "        if cat not in cat_groups['category'].values:\n",
    "            categories.append(cat)\n",
    "            counts.append(0)\n",
    "        else:\n",
    "            cat_count = cat_groups[cat_groups['category'] == cat]['count'].values[0]\n",
    "            categories.append(cat)\n",
    "            \n",
    "            total = all_categories_df[all_categories_df[\"category\"] == cat]['id'].nunique()\n",
    "            counts.append(cat_count/total * 100)\n",
    "        \n",
    "\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=counts,\n",
    "        theta=categories,\n",
    "        fill='none',\n",
    "        line=dict(\n",
    "                color=COLOR_MAP[agent],\n",
    "                width=3\n",
    "            ),\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            symbol=MARKER_MAP[agent],\n",
    "        ),\n",
    "        name=agent,\n",
    "    ))\n",
    "\n",
    "    i += 1\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 100]\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=-0.05,          # pulls legend closer to plot\n",
    "        xanchor=\"center\",\n",
    "        x=0.5\n",
    "    ),\n",
    "\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        t=30,\n",
    "        b=40              # just enough for legend\n",
    "    ),\n",
    "\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"./Outputs/Figures/RQ3_Agent_Performance_Comparison.pdf\", scale=20, format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1ce3bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "body",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "agent",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "closed_at",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "merged_at",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "repo_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "repo_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "html_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Topic",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Probability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Representative_document",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "topic_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4055524c-0e4b-4ab6-8f31-f7d4516afe58",
       "rows": [
        [
         "0",
         "2912546402",
         "448",
         "Add GitHub API caching to prevent rate limiting",
         "- Create GitHub API caching script that handles authenticated and unauthenticated requests\r\n- Update Dockerfile to include the script in the container\r\n- Update init-firewall.sh to use cached GitHub API data\r\n- Modify devcontainer.json to run cache script before build and mount cache directory\r\n\r\nü§ñ Generated with [Claude Code](https://claude.ai/code)\r\nCo-Authored-By: Claude <noreply@anthropic.com>",
         "Claude_Code",
         "1021104",
         "8enmann",
         "closed",
         "2025-03-12T03:51:34Z",
         "2025-05-06T17:50:00Z",
         null,
         "937253475",
         "https://api.github.com/repos/anthropics/claude-code",
         "https://github.com/anthropics/claude-code/pull/448",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "1",
         "3216159293",
         "110",
         "Add vcpkg dependency caching to Windows CI workflow",
         "## Overview\n\nThis PR implements vcpkg dependency caching for the Windows CI workflow to significantly speed up build times by avoiding full dependency rebuilds on every CI run.\n\n## Changes\n\nAdded a comprehensive caching strategy to `.github/workflows/ci-windows-minimal.yml` that:\n\n1. **Caches the `vcpkg/installed` directory** - where compiled dependencies are stored\n2. **Uses a multi-component cache key** for precise cache invalidation:\n   - `${{ runner.os }}` - OS-specific caching (Windows)\n   - `${{ steps.vcpkg-commit.outputs.hash }}` - vcpkg version/commit hash\n   - `${{ matrix.triplet }}` - Architecture-specific (x64-windows)\n   - `${{ hashFiles('vcpkg/vcpkg.json') }}` - Dependency manifest changes\n\n3. **Provides fallback restore keys** for partial cache hits:\n   ```yaml\n   restore-keys: |\n     ${{ runner.os }}-vcpkg-${{ steps.vcpkg-commit.outputs.hash }}-${{ matrix.triplet }}-\n     ${{ runner.os }}-vcpkg-${{ steps.vcpkg-commit.outputs.hash }}-\n     ${{ runner.os }}-vcpkg-\n   ```\n\n## Implementation Details\n\nThe cache step is strategically placed **after vcpkg is cloned and bootstrapped** but **before CMake configure**, ensuring:\n- The `.git/HEAD` file exists for accurate commit hash calculation\n- Dependencies are restored before CMake triggers vcpkg installation\n- Compatibility with existing GitHub Actions binary cache (`VCPKG_BINARY_SOURCES: 'clear;x-gha,readwrite'`)\n\n## Benefits\n\n- **Faster CI runs** - Dependencies only rebuild when vcpkg version or manifest changes\n- **Efficient cache utilization** - Progressive fallback strategy maximizes cache hits\n- **No breaking changes** - Works alongside existing caching mechanisms\n- **Smart invalidation** - Cache automatically invalidates when dependencies change\n\n## Example Cache Key\n\n```\nWindows-vcpkg-a1b2c3d4e5f6-x64-windows-8071ecc3\n```\n\nWhere:\n- `Windows` = OS\n- `a1b2c3d4e5f6` = vcpkg commit hash\n- `x64-windows` = triplet\n- `8071ecc3` = vcpkg.json hash\n\nThis approach ensures that CI builds will be significantly faster for incremental changes while maintaining reliability through proper cache invalidation.\n\n*This pull request was created as a result of the following prompt from Copilot chat.*\n> Add vcpkg dependency caching to the CI workflow for Windows builds. This will cache the vcpkg/installed directory in the GitHub Actions workflow, using a cache key based on the OS, vcpkg commit hash, and triplet, to prevent rebuilding all dependencies on every run. The cache step is placed after vcpkg is cloned and bootstrapped, ensuring the .git/HEAD file exists for cache key calculation. This will speed up CI runs by restoring dependencies from cache when possible.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-09T14:30:39Z",
         "2025-07-09T16:47:00Z",
         "2025-07-09T16:47:00Z",
         "564439013",
         "https://api.github.com/repos/pelicanmapping/rocky",
         "https://github.com/pelicanmapping/rocky/pull/110",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "2",
         "3195588879",
         "16531",
         "Remove duplicate yarn eslint step from .circleci/config.yml",
         "<details><summary>&#x1F6E0 DevTools &#x1F6E0</summary>\n<p>\n\n[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/Copilot/mlflow/pull/16531?quickstart=1)\n\n#### Install mlflow from this PR\n\n```\n# mlflow\npip install git+https://github.com/mlflow/mlflow.git@refs/pull/16531/merge\n# mlflow-skinny\npip install git+https://github.com/mlflow/mlflow.git@refs/pull/16531/merge#subdirectory=skinny\n```\n\nFor Databricks, use the following command:\n\n```\n%sh curl -LsSf https://raw.githubusercontent.com/mlflow/mlflow/HEAD/dev/install-skinny.sh | sh -s pull/16531/merge\n```\n\n</p>\n</details>\n\n## Summary\n\nRemoves the duplicate `yarn eslint` step from `.circleci/config.yml` to eliminate redundancy with the identical linting step in `.github/workflows/docs.yml`.\n\n## Changes Made\n\n- Removed the \"Lint\" step (lines 88-91) from the `build_doc` job in `.circleci/config.yml`\n- The CircleCI workflow now flows directly from \"Install JS dependencies\" to \"Build documentation\"\n\n## Before/After\n\n**Before**: Both CI systems were running identical linting:\n- CircleCI: `yarn eslint` in docs directory\n- GitHub Actions: `yarn eslint` in docs directory\n\n**After**: Only GitHub Actions runs the linting step, eliminating duplication while maintaining the same coverage.\n\n## Impact\n\n- ‚úÖ Reduces CI execution time and resource usage\n- ‚úÖ Eliminates duplicate linting checks  \n- ‚úÖ Maintains identical linting coverage through GitHub Actions workflow\n- ‚úÖ No impact on documentation building functionality\n- ‚úÖ No impact on documentation preview generation\n\nThe GitHub Actions workflow continues to provide the same ESLint coverage for `.md` and `.mdx` files in the docs directory, ensuring no reduction in code quality checks.\n\nFixes #16530.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-02T11:33:06Z",
         "2025-07-02T12:24:50Z",
         "2025-07-02T12:24:50Z",
         "136202695",
         "https://api.github.com/repos/mlflow/mlflow",
         "https://github.com/mlflow/mlflow/pull/16531",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "3",
         "3074681764",
         "13829",
         "Update build documentation with quick build optimization flags",
         "This PR updates the build documentation (`toolkit/docs/building/building.md`) to include the latest optimization flags and best practices for building Azure Linux more efficiently.\n\n## Changes\n- Added documentation for `QUICK_REBUILD=y` flag which optimizes builds across all stages\n- Added documentation for `QUICK_REBUILD_TOOLCHAIN=y` flag for optimizing toolchain builds\n- Added documentation for `QUICK_REBUILD_PACKAGES=y` flag for optimizing package builds\n- Updated all command examples to use these optimization flags\n- Added clear explanations of what each flag does\n- Added a note about quick build flags in the overview section for visibility\n- Fixed typos and minor grammatical issues\n\nThese changes bring the documentation up to date with the current build tools and optimization capabilities, providing developers with best practices for faster builds.\n\n### Benefits\nThese optimization flags significantly improve build performance by:\n- Using existing published components where possible\n- Enabling delta builds to avoid unnecessary rebuilds\n- Pre-fetching and caching dependencies\n- Limiting cascading rebuilds when a dependency changes\n\nFixes #13828.\n\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "open",
         "2025-05-19T18:25:04Z",
         null,
         null,
         "281765424",
         "https://api.github.com/repos/microsoft/azurelinux",
         "https://github.com/microsoft/azurelinux/pull/13829",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "4",
         "3159826481",
         "184",
         "[WIP] Support .coshrc compilation",
         "Thanks for assigning this issue to me. I'm starting to work on it and will keep this PR's description up to date as I form a plan and make progress.\n\nOriginal issue description:\n\n> To avoid having to compile it whenever the shell starts up.  Preferably by compiling it automatically whenever it changes, and then relying on the compiled version until it changes again.\n\n\nFixes #117.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-06-19T10:34:39Z",
         "2025-06-26T11:59:32Z",
         null,
         "445862991",
         "https://api.github.com/repos/tomhrr/cosh",
         "https://github.com/tomhrr/cosh/pull/184",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "5",
         "3259387186",
         "4471",
         "Fix Gradle build failures due to Maven Central rate limiting (HTTP 429)",
         "## Problem\n\nCI jobs were failing due to Maven Central rate limiting with HTTP 429 errors:\n\n```\nCould not GET 'https://repo.maven.apache.org/maven2/com/google/code/gson/gson/2.10.1/gson-2.10.1.pom'. \nReceived status code 429 from server: Your IP: 20.55.222.81 has hit the rate limit with Maven Central. \nToo many requests.\n```\n\nThis occurred because Gradle dependencies were being downloaded repeatedly in each CI run without proper caching.\n\n## Solution\n\nAdded comprehensive Gradle dependency caching to all Java-related CI workflows:\n\n### 1. Gradle Dependency Caching\n- **java.yml**: Added `~/.gradle/caches` and `~/.gradle/wrapper` caching to all Java build jobs\n- **codeql.yml**: Added Gradle caching for Java/Kotlin CodeQL analysis  \n- **java-cd.yml**: Added Gradle caching for CD pipeline builds and deployment testing\n\n### 2. Smart Cache Keys\n```yaml\nkey: ${{ runner.os }}-gradle-${{ hashFiles('java/**/*.gradle*', 'java/**/gradle-wrapper.properties') }}\nrestore-keys: |\n    ${{ runner.os }}-gradle-\n```\n\nCache keys are based on Gradle file hashes to ensure proper cache invalidation when dependencies change, with fallback restore keys for partial cache hits.\n\n### 3. Build Cache Optimization\nAdded `--build-cache` flag to all `gradlew` commands to enable Gradle's local build cache, reducing compilation time and duplicate work within the same CI run.\n\n## Impact\n\n- **Reduces Maven Central requests**: Dependencies cached across CI runs\n- **Faster builds**: ~200MB of Gradle dependencies no longer downloaded every run\n- **Rate limit resilience**: Significantly reduces likelihood of HTTP 429 errors\n- **Better CI reliability**: Less dependency on external repository availability\n\n## Testing\n\nValidated that caching configuration works correctly:\n- Gradle cache directories (`~/.gradle/caches`, `~/.gradle/wrapper`) are properly created\n- Cache keys generate correctly based on Gradle file changes\n- Build cache is enabled and functional\n\nFixes #4470.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-24T10:28:36Z",
         "2025-07-24T12:17:19Z",
         "2025-07-24T12:17:19Z",
         "511141524",
         "https://api.github.com/repos/valkey-io/valkey-glide",
         "https://github.com/valkey-io/valkey-glide/pull/4471",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "6",
         "3197896940",
         "1033",
         "ci: Add conditional testing for wef and webview crates",
         "This PR optimizes the CI workflow by implementing conditional testing for the `wef` and `webview` crates, which significantly improves CI performance while maintaining full test coverage when needed.\n\n## Problem\n\nThe current CI workflow runs `cargo test --all` which includes testing the heavy `wef` and `webview` crates on every change, even when modifications are unrelated to these components. This causes:\n\n- Slower CI runs due to CEF framework setup and heavy dependencies\n- Unnecessary resource usage when testing unrelated changes\n- Longer feedback cycles for developers working on other parts of the codebase\n\n## Solution\n\n### Main Test Job Optimization\nModified the main test steps to exclude `wef` and `webview` crates:\n\n```yaml\n# Before\ncargo test --all\n\n# After  \ncargo test --workspace --exclude wef --exclude gpui-webview\n```\n\n### Conditional Testing Jobs\nAdded two new jobs that only run when relevant files change:\n\n1. **`test-wef`** - Runs when `crates/wef/**` files are modified\n2. **`test-webview`** - Runs when `crates/webview/**` files are modified\n\nBoth jobs use `dorny/paths-filter@v2` to detect file changes and skip execution with informative messages when no relevant changes are detected.\n\n## Benefits\n\n- ‚ö° **Faster CI**: Main test suite runs significantly faster by excluding heavy crates\n- üéØ **Targeted testing**: wef/webview tests only run when their code changes\n- üíæ **Resource efficiency**: CEF dependencies only set up when needed\n- üîç **Maintained coverage**: Full test coverage preserved when changes require it\n- ‚úÖ **Clear feedback**: Skip messages clearly indicate when tests aren't needed\n\n## Example Scenarios\n\n### Scenario A: UI component change\n```\nChange: crates/ui/src/button.rs\nResult: \n- ‚úÖ Main test runs (excluding wef/webview)\n- ‚è≠Ô∏è wef tests skipped\n- ‚è≠Ô∏è webview tests skipped\n```\n\n### Scenario B: wef crate change  \n```\nChange: crates/wef/src/lib.rs\nResult:\n- ‚úÖ Main test runs (excluding wef/webview) \n- ‚úÖ wef tests run with full CEF setup\n- ‚è≠Ô∏è webview tests skipped\n```\n\n### Scenario C: webview crate change\n```\nChange: crates/webview/src/lib.rs  \nResult:\n- ‚úÖ Main test runs (excluding wef/webview)\n- ‚è≠Ô∏è wef tests skipped\n- ‚úÖ webview tests run with full CEF setup\n```\n\n## Technical Details\n\n- Uses `dorny/paths-filter@v2` for reliable file change detection\n- Maintains same matrix strategy (Linux, Windows, macOS) across all jobs\n- Preserves existing caching patterns with job-specific cache keys\n- All conditional steps use proper `if:` conditions to avoid unnecessary execution\n- YAML syntax validated and cargo command syntax verified\n\n## Testing\n\nCreated comprehensive validation script that confirms:\n- ‚úÖ Cargo exclude syntax works correctly\n- ‚úÖ Package-specific testing syntax is valid\n- ‚úÖ YAML structure is properly formatted\n- ‚úÖ All expected jobs and conditions are present\n\nThis change maintains the same level of test coverage while significantly improving CI efficiency for the majority of development work.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-03T03:46:08Z",
         "2025-07-03T06:55:38Z",
         null,
         "814684486",
         "https://api.github.com/repos/longbridge/gpui-component",
         "https://github.com/longbridge/gpui-component/pull/1033",
         "0",
         "1.0",
         "True",
         "CI/CD",
         "Development"
        ],
        [
         "7",
         "3088220705",
         "684",
         "Refactor CI workflow for parallel multi-architecture Docker builds",
         "## Changes\n\nThis PR refactors the GitHub Actions CI workflow to build Docker images for both amd64 and arm64 architectures in parallel, improving build times while maintaining multi-architecture support.\n\n### Key improvements:\n\n- Split the image build process into separate parallel jobs for amd64 and arm64 for both App and Engine images\n- Added special handling for Lambda compatibility:\n  - Push amd64 Engine image with `-lambda` tag suffix for AWS Lambda compatibility\n- Added a final job to create multi-architecture manifests combining both architectures\n- Preserved ECR cache configuration with architecture-specific cache references\n\n### Before:\n- Single job built both architectures sequentially\n- Additional step to extract amd64 image for Lambda\n- ~25-30% longer build time due to sequential multi-arch builds\n\n### After:\n- Parallel architecture-specific builds\n- Dedicated job for Lambda-compatible tags\n- Final manifest creation job\n- Architecture-specific build caching\n- Expected ~20-25% faster builds due to parallelization\n\n## Testing\n\nThis change has been validated for YAML syntax correctness. GitHub Actions will use this workflow configuration on merge, building both amd64 and arm64 images for App and Engine images, and creating multi-arch manifests.\n\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-05-24T07:39:25Z",
         "2025-06-10T21:14:55Z",
         null,
         "945671748",
         "https://api.github.com/repos/openops-cloud/openops",
         "https://github.com/openops-cloud/openops/pull/684",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "8",
         "3206330418",
         "3547",
         "Add comprehensive FrankenPHP support for phpMyFAQ",
         "This PR adds full support for [FrankenPHP](https://frankenphp.dev), a modern PHP application server built on Caddy, providing high-performance capabilities and modern web server features for phpMyFAQ.\n\n## What's Added\n\n### üê≥ Docker Configuration\n- **Complete Dockerfile** with all required PHP extensions (gd, intl, ldap, mysqli, pdo, zip, opcache, etc.)\n- **Docker Compose service** with proper environment variables and port mapping (8888:80, 8443:443)\n- **Entrypoint script** for automated PHP configuration and directory setup\n\n### ‚öôÔ∏è Configuration Files\n- **Caddyfile** with URL rewriting, security headers, and SSO support\n- **Worker script** for FrankenPHP's high-performance worker mode (optional)\n- **Environment-based configuration** matching existing Apache/PHP-FPM patterns\n\n### üìö Documentation\n- **Installation guide** with manual setup, Docker usage, and SSO configuration\n- **Development documentation** updates for FrankenPHP workflow\n- **Comprehensive README** with usage instructions and best practices\n\n## Key Features\n\n‚ú® **High Performance**: Optional worker mode keeps PHP code in memory between requests  \nüîê **Built-in HTTPS**: Automatic SSL certificate management  \nüöÄ **Modern Architecture**: HTTP/2, HTTP/3, and Server-Sent Events support  \nüõ°Ô∏è **Security**: Pre-configured security headers and SSO support  \nüîÑ **Clean URLs**: Automatic URL rewriting for phpMyFAQ routes  \n\n## Usage\n\n### Quick Start with Docker\n```bash\n# Start FrankenPHP service\ndocker-compose up frankenphp\n\n# Access phpMyFAQ at http://localhost:8888\n```\n\n### Manual Installation\n```bash\n# Install FrankenPHP\ncurl -L https://github.com/dunglas/frankenphp/releases/latest/download/frankenphp-linux-x86_64 -o frankenphp\nchmod +x frankenphp && sudo mv frankenphp /usr/local/bin/\n\n# Start with provided Caddyfile\nfrankenphp run --config /path/to/Caddyfile\n```\n\n## Testing Results\n\n‚úÖ Docker build successful  \n‚úÖ FrankenPHP container starts correctly  \n‚úÖ PHP files served properly  \n‚úÖ phpMyFAQ pages load correctly  \n‚úÖ Setup redirection works as expected  \n\n## Benefits over Traditional Setup\n\n- **Better Performance**: Worker mode eliminates PHP initialization overhead\n- **Simpler Deployment**: Single binary with built-in web server\n- **Automatic HTTPS**: No need for reverse proxy configuration  \n- **Modern Features**: Built-in support for latest web standards\n- **Easy Configuration**: Simple Caddyfile syntax vs complex Apache/nginx configs\n\nThe implementation follows existing patterns used for Apache and nginx+PHP-FPM support, making minimal changes to the core codebase while providing comprehensive Docker support and documentation.\n\nFixes #3498.\n\n> [!WARNING]\n>\n> <details>\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\n>\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\n>\n> - `127.0.0.11`\n> - `https://api.github.com/repos/DASPRiD/Enum/zipball/8dfd07c6d2cf31c8da90c53b83c026c7696dda90`\n>   - Triggering command: `/usr/bin/php8.3 -n -c /tmp/vwNFJo /usr/bin/composer install --no-dev` (http block)\n> - `https://api.github.com/repos/php-fig/log/zipball/f16e1d5863e37f8d8c2a01719f5b34baa2b714d3`\n>   - Triggering command: `/usr/bin/php8.3 -n -c /tmp/vwNFJo /usr/bin/composer install --no-dev` (http block)\n> - `pecl.php.net`\n>   - Triggering command: `/usr/local/bin/php -C -q -d include_path=/usr/local/lib/php -d date.timezone=UTC -d output_buffering=1 -d variables_order=EGPCS -d safe_mode=0 -d register_argc_argv=On /usr/local/lib/php/peclcmd.php install xdebug-3.4.2` (dns block)\n>   - Triggering command: `/usr/local/bin/php -C -q -d include_path=/usr/local/lib/php -d date.timezone=UTC -d output_buffering=1 -d variables_order=EGPCS -d safe_mode=0 -d register_argc_argv=On /usr/local/lib/php/peclcmd.php install xdebug` (dns block)\n>\n> If you need me to access, download, or install something from one of these locations, you can either:\n>\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\n>\n> </details>\n\n\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-06T09:22:25Z",
         "2025-07-06T10:00:32Z",
         "2025-07-06T10:00:32Z",
         "269027",
         "https://api.github.com/repos/thorsten/phpMyFAQ",
         "https://github.com/thorsten/phpMyFAQ/pull/3547",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "9",
         "3207427713",
         "75",
         "Fix CI workflow: Add proper Cargo cache steps to develop and s3s-e2e jobs",
         "## Summary\n\nThis PR fixes the CI workflow caching issues by adding proper `actions/cache` steps to both the `develop` and `s3s-e2e` jobs, ensuring efficient Cargo dependency caching for faster builds.\n\n## Changes Made\n\n### Added Cargo Cache Steps\n- **develop job**: Added `actions/cache@v4` step to cache Cargo dependencies before running tests, formatting, and linting\n- **s3s-e2e job**: Added `actions/cache@v4` step to cache Cargo dependencies before building and running E2E tests\n\n### Cache Configuration\n```yaml\n- name: Cache Cargo dependencies\n  uses: actions/cache@v4\n  with:\n    path: |\n      ~/.cargo/registry\n      ~/.cargo/git\n      target\n    key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}\n    restore-keys: |\n      ${{ runner.os }}-cargo-\n```\n\n### Key Features\n- **Cache Paths**: Caches `~/.cargo/registry`, `~/.cargo/git`, and `target` directories\n- **Cache Key**: Uses `Cargo.lock` file hash for precise cache invalidation\n- **Restore Keys**: Provides fallback keys for partial cache matches\n- **Positioning**: Cache steps are placed after Rust setup but before compilation steps\n\n## Benefits\n\n1. **Faster CI Builds**: Avoids re-downloading and re-compiling dependencies when `Cargo.lock` hasn't changed\n2. **Reduced Network Usage**: Minimizes registry downloads during CI runs\n3. **Consistent Caching**: Both jobs use identical cache configuration for consistency\n4. **Proper Cache Invalidation**: Cache automatically invalidates when dependencies change\n\n## Verification\n\n- ‚úÖ YAML syntax validation passes\n- ‚úÖ Cache steps properly positioned in workflow\n- ‚úÖ Both `develop` and `s3s-e2e` jobs include caching\n- ‚úÖ Uses `Cargo.lock` as cache key as requested\n- ‚úÖ Workflow file has substantial content changes (22 lines added)\n\nThis addresses the previous PR issues and ensures proper Cargo dependency caching for both critical CI jobs.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-07T03:30:11Z",
         "2025-07-07T03:31:54Z",
         null,
         "722597620",
         "https://api.github.com/repos/rustfs/rustfs",
         "https://github.com/rustfs/rustfs/pull/75",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "10",
         "3207429355",
         "76",
         "‰ºòÂåñ CI Â∑•‰ΩúÊµÅÔºö‰∏∫ develop Âíå s3s-e2e ‰Ωú‰∏öÊ∑ªÂä† Cargo ÁºìÂ≠ò",
         "## Ê¶ÇËø∞\n\nÊú¨ PR ÂØπ `.github/workflows/ci.yml` ËøõË°å‰∫Ü‰ºòÂåñÔºå‰∏∫ `develop` Âíå `s3s-e2e` ‰Ωú‰∏öÊ∑ªÂä†‰∫Ü Cargo ÁºìÂ≠òÊîØÊåÅÔºå‰ª•ÊèêÈ´ò CI ÊûÑÂª∫ÈÄüÂ∫¶„ÄÇ\n\n## ÂèòÊõ¥ÂÜÖÂÆπ\n\n### Ê∑ªÂä†ÁöÑÁºìÂ≠òÊ≠•È™§\n\nÂú®‰ª•‰∏ã‰∏§‰∏™‰Ωú‰∏ö‰∏≠Ê∑ªÂä†‰∫Ü `actions/cache` Ê≠•È™§Ôºö\n\n1. **develop ‰Ωú‰∏ö** (Á¨¨ 89-96 Ë°å)\n2. **s3s-e2e ‰Ωú‰∏ö** (Á¨¨ 117-124 Ë°å)\n\n### ÁºìÂ≠òÈÖçÁΩÆ\n\n- **ÁºìÂ≠òË∑ØÂæÑ**Ôºö\n  - `~/.cargo/registry` - Cargo ‰æùËµñÊ≥®ÂÜåË°®\n  - `~/.cargo/git` - Git ‰æùËµñ\n  - `target` - ÊûÑÂª∫ÁõÆÊ†áÁõÆÂΩï\n\n- **ÁºìÂ≠òÈîÆ**Ôºö`${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}`\n  - Âü∫‰∫éÊìç‰ΩúÁ≥ªÁªüÂíå Cargo.lock Êñá‰ª∂ÂìàÂ∏åÂÄºÁîüÊàê\n  - Á°Æ‰øù‰æùËµñÂèòÊõ¥Êó∂ÁºìÂ≠òÂ§±Êïà\n\n- **ÁºìÂ≠òÁâàÊú¨**Ôºö`actions/cache@v4`\n\n### Ê≠•È™§‰ΩçÁΩÆ\n\nÁºìÂ≠òÊ≠•È™§Ë¢´Á≤æÁ°ÆÊîæÁΩÆÂú®Ôºö\n- `uses: ./.github/actions/setup` **‰πãÂêé**\n- `cargo build/test` ÂëΩ‰ª§ **‰πãÂâç**\n\nËøôÁ°Æ‰øù‰∫ÜÂú®‰ΩøÁî®ÁºìÂ≠òÊûÑÂª∫‰∫ßÁâ©‰πãÂâçÔºåÊâÄÊúâÂøÖË¶ÅÁöÑ‰æùËµñÂíåÂ∑•ÂÖ∑ÈÉΩÂ∑≤Ê≠£Á°ÆËÆæÁΩÆ„ÄÇ\n\n## È¢ÑÊúüÊïàÊûú\n\n- üöÄ **ÊèêÈ´òÊûÑÂª∫ÈÄüÂ∫¶**ÔºöÂêéÁª≠ÊûÑÂª∫ÂèØ‰ª•Â§çÁî®Â∑≤ÁºìÂ≠òÁöÑ‰æùËµñÂíåÊûÑÂª∫‰∫ßÁâ©\n- üí∞ **ËäÇÁúÅ CI ËµÑÊ∫ê**ÔºöÂáèÂ∞ëÈáçÂ§ç‰∏ãËΩΩÂíåÁºñËØëÊó∂Èó¥\n- üîÑ **Êô∫ËÉΩÁºìÂ≠òÂ§±Êïà**ÔºöÂΩì Cargo.lock ÂèòÊõ¥Êó∂Ëá™Âä®Êõ¥Êñ∞ÁºìÂ≠ò\n\n## ÊµãËØï\n\n- ‚úÖ YAML ËØ≠Ê≥ïÈ™åËØÅÈÄöËøá\n- ‚úÖ ÁºìÂ≠òÊ≠•È™§Ê≠£Á°ÆÊîæÁΩÆÂú®Â∑•‰ΩúÊµÅ‰∏≠\n- ‚úÖ ÁºìÂ≠òÈÖçÁΩÆÁ¨¶ÂêàÊúÄ‰Ω≥ÂÆûË∑µ\n\n## ÂÖºÂÆπÊÄß\n\nÊ≠§ÂèòÊõ¥ÂÆåÂÖ®ÂêëÂêéÂÖºÂÆπÔºå‰∏ç‰ºöÂΩ±ÂìçÁé∞ÊúâÁöÑ CI Ë°å‰∏∫Ôºå‰ªÖÊ∑ªÂä†ÁºìÂ≠ò‰ºòÂåñÂäüËÉΩ„ÄÇ\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-07T03:31:32Z",
         "2025-07-07T03:31:45Z",
         null,
         "722597620",
         "https://api.github.com/repos/rustfs/rustfs",
         "https://github.com/rustfs/rustfs/pull/76",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "11",
         "3205497325",
         "3046",
         "Implement intelligent test selection for github actions",
         "## Summary\n\nThis PR implements an intelligent test selection system that reduces CI runtime from 5+ minutes to targeted windows (1-5 minutes) based on the scope of changes in a pull request. The system analyzes git diff to determine which tests are relevant and executes only those tests, providing 60-80% time savings for focused changes while maintaining comprehensive coverage for complex changes.\n\n## Problem Statement\n\nThe current CI system runs the full test suite for every PR, regardless of the scope of changes. This results in:\n- Consistent 5+ minute runtime even for documentation-only changes\n- Inefficient use of CI resources\n- Slower feedback for developers\n- No differentiation between small focused changes and large complex changes\n\n## Solution\n\n### üîß Core Components\n\n1. **`tools/test_selector.py`** - Intelligent test selection engine\n   - Analyzes git diff to categorize file changes\n   - Maps file patterns to relevant test categories\n   - Provides both human-readable and JSON output for CI integration\n   - Implements fallback to full test suite for complex changes\n\n2. **`tools/test_docs_build.py`** - Lightweight documentation testing\n   - Validates markdown and RST files for basic formatting\n   - Checks configuration files exist and are valid\n   - Completes in ~30 seconds vs full documentation build\n\n3. **`.github/workflows/intelligent-testing.yml`** - Enhanced CI workflow\n   - Dynamic test matrix generation based on change analysis\n   - Parallel execution paths for fast tests vs comprehensive tests\n   - Automatic fallback mechanism for edge cases\n\n4. **`tools/validate_test_selection.py`** - System validation\n   - Demonstrates functionality and validates correct operation\n   - Shows expected benefits and time savings\n\n### üìä Test Categories & Performance\n\n| Change Type | Previous Runtime | New Runtime | Improvement | Test Strategy |\n|-------------|-----------------|-------------|-------------|---------------|\n| **Documentation-only** | ~5+ minutes | ~1-2 minutes | **60-80% faster** | Lightweight docs validation |\n| **SuperAnimal changes** | ~5+ minutes | ~3-4 minutes | **20-40% faster** | SuperAnimal-specific tests |\n| **Focused components** | ~5+ minutes | ~2-3 minutes | **40-60% faster** | Component-specific tests |\n| **Complex/mixed changes** | ~5+ minutes | ~5+ minutes | Maintains coverage | Full test suite |\n\n### üéØ Smart Categorization\n\nThe system categorizes changes into:\n\n- **`docs`**: Documentation files (`*.md`, `*.rst`, `docs/`, config files)\n- **`superanimal`**: ModelZoo and SuperAnimal components (`deeplabcut/modelzoo/`, `*superanimal*`)\n- **`core`**: Core DeepLabCut functionality (`deeplabcut/core/`, `deeplabcut/pose_estimation_*/`)\n- **`multianimal`**: Multi-animal specific features (`*multianimal*`, `*multi*`)\n- **`video`**: Video processing components (`*video*`, prediction APIs)\n- **`tools`**: Development tools (`tools/`)\n\n## Usage Examples\n\n```bash\n# Analyze current changes and show what tests would run\npython tools/test_selector.py --dry-run\n\n# Get JSON output for CI integration\npython tools/test_selector.py --output-json --base main\n\n# Validate the system works correctly\npython tools/validate_test_selection.py\n\n# Test documentation build independently  \npython tools/test_docs_build.py\n```\n\n## Example Scenarios\n\n### Documentation-only PR\n```bash\n$ python tools/test_selector.py --dry-run\nüìÅ Found 1 changed files: docs/installation.md\nüìÇ Categories: docs\nüß™ Tests to run: python tools/test_docs_build.py\n‚è±Ô∏è  Estimated runtime: 1-2 minutes\n```\n\n### SuperAnimal model changes\n```bash\n$ python tools/test_selector.py --dry-run  \nüìÅ Found 3 changed files: deeplabcut/modelzoo/superanimal_*.py\nüìÇ Categories: superanimal\nüß™ Tests to run: pytest tests/test_predict_supermodel.py tests/pose_estimation_pytorch/modelzoo/\n‚è±Ô∏è  Estimated runtime: 3-4 minutes\n```\n\n### Mixed/complex changes\n```bash\n$ python tools/test_selector.py --dry-run\nüìÅ Found 12 changed files across multiple components\nüìÇ Categories: core, superanimal, video, uncategorized  \nüß™ Tests to run: python examples/testscript.py, pytest\n‚è±Ô∏è  Estimated runtime: 5+ minutes (full test suite)\n```\n\n## Integration\n\nThe system integrates seamlessly with the existing CI pipeline:\n\n1. **Maintains backward compatibility** - Falls back to full test suite when unsure\n2. **Zero false negatives** - Never skips tests that should run for a given change\n3. **Conservative approach** - Prefers running extra tests over missing important ones\n4. **JSON API** - Easy integration with GitHub Actions and other CI systems\n\n## Validation\n\nThe implementation includes comprehensive validation:\n\n```bash\n$ python tools/validate_test_selection.py\nüéâ SUCCESS: Intelligent test selection system is working correctly!\n\nKey Benefits:\n‚Ä¢ Documentation-only changes: ~1-2 minutes (vs 5+ minutes)\n‚Ä¢ SuperAnimal changes: ~3-4 minutes (vs 5+ minutes)  \n‚Ä¢ Focused component changes: ~2-3 minutes (vs 5+ minutes)\n‚Ä¢ Complex changes: Falls back to full test suite (~5+ minutes)\n\nüìà Expected CI time reduction: 60-80% for focused changes\n```\n\n## Expected Impact\n\n- **60-80% reduction** in CI time for focused changes (docs, single components)\n- **Faster feedback** for developers on common change types\n- **Resource efficiency** - Reduced compute usage for GitHub Actions\n- **Maintained quality** - Full test coverage preserved for complex changes\n- **Developer experience** - Quicker iteration cycles for documentation and focused feature work\n\nThis implementation addresses the core requirement of reducing test suite runtime to approximately 5 minutes while intelligently adapting to the scope of changes in each pull request.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "open",
         "2025-07-05T19:48:04Z",
         null,
         null,
         "126897385",
         "https://api.github.com/repos/DeepLabCut/DeepLabCut",
         "https://github.com/DeepLabCut/DeepLabCut/pull/3046",
         "0",
         "1.0",
         "True",
         "CI/CD",
         "Development"
        ],
        [
         "12",
         "3136224160",
         "1923",
         "Add native ARM64 GitHub Actions runner support",
         "This PR implements native ARM64 GitHub Actions runners to replace QEMU emulation for better performance and reliability.\r\n\r\n## Changes Made\r\n\r\n### üöÄ Docker Image Builds (`push-image.yml`)\r\n- **Before**: All builds ran on `ubuntu-latest` with QEMU emulation for ARM64\r\n- **After**: Native builds using appropriate runners:\r\n  - AMD64 builds: `ubuntu-latest` \r\n  - ARM64 builds: `ubuntu-24.04-arm64`\r\n- **Removed**: QEMU setup step (no longer needed for native builds)\r\n- **Result**: Faster, more reliable ARM64 Docker image builds\r\n\r\n### üß™ Testing & Validation (`build.yml`)\r\n- **Before**: Tests only ran on `ubuntu-latest` (AMD64)\r\n- **After**: Matrix testing on both architectures:\r\n  - `ubuntu-latest` (AMD64)\r\n  - `ubuntu-24.04-arm64` (ARM64)\r\n- **Result**: Comprehensive cross-platform testing ensures code compatibility\r\n\r\n## Key Benefits\r\n\r\n- üèÉ‚Äç‚ôÇÔ∏è **Performance**: Native ARM64 execution vs emulated builds\r\n- üîç **Coverage**: Testing on both AMD64 and ARM64 platforms  \r\n- üõ†Ô∏è **Maintenance**: Cleaner workflows without QEMU complexity\r\n- üîÆ **Future-ready**: Uses latest GitHub Actions ARM64 runners\r\n\r\n## Technical Details\r\n\r\nThe changes use GitHub's native ARM64 runners ([ubuntu-24.04-arm](https://github.com/actions/partner-runner-images/blob/main/images/arm-ubuntu-24-image.md)) which provide:\r\n- Better performance than QEMU emulation\r\n- Native ARM64 instruction execution\r\n- More reliable builds for ARM64 Docker images\r\n\r\n**Impact**: Minimal changes (8 additions, 8 deletions) with no breaking changes to existing functionality.\r\n\r\nFixes #1922.\r\n\r\n> [!WARNING]\r\n>\r\n> <details>\r\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\r\n>\r\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\r\n>\r\n> - `api.github.com`\r\n>   - Triggering command: `node download.js ` (dns block)\r\n> - `api.nektosact.com`\r\n>   - Triggering command: `act --list ` (dns block)\r\n>   - Triggering command: `act --list --workflows=.github/workflows/build.yml ` (dns block)\r\n>   - Triggering command: `act --list --workflows=.github/workflows/push-image.yml ` (dns block)\r\n>\r\n> If you need me to access, download, or install something from one of these locations, you can either:\r\n>\r\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\r\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\r\n>\r\n> </details>\r\n\r\n\r\n---\r\n\r\nblocked by #1926 \r\n\r\n---\r\n\r\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "open",
         "2025-06-11T09:58:23Z",
         null,
         null,
         "35017238",
         "https://api.github.com/repos/hackmdio/codimd",
         "https://github.com/hackmdio/codimd/pull/1923",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "13",
         "3081185488",
         "34496",
         "[EngSys] Enable rush build cache for @typespec/ts-http-runtime",
         "This PR enables the rush build cache for the `@typespec/ts-http-runtime` package by adding a `rush-project.json` file to the package's config directory. This configuration allows the package to benefit from Rush's build caching system, which will improve build times since many packages depend on this one.\n\n## Changes made\n\n- Added `/sdk/core/ts-http-runtime/config/rush-project.json` that extends the common rush-project.json configuration\n- Verified the build cache works by running multiple builds and confirming the cache hits\n\n## Why this matters\n\nThe `@typespec/ts-http-runtime` package is a core package that many other packages depend on. Enabling build caching for it will improve the repository's build performance, especially in CI scenarios, because the package will only need to be rebuilt when actual changes are made to it.\n\nFixes #34495.\n\n> [!WARNING]\n>\n> <details>\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\n>\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\n>\n> - `azuresdkartifacts.blob.core.windows.net`\n>   - Triggering command: `node /usr/local/bin/rush build --to @typespec/ts-http-runtime --verbose ` (dns block)\n> - `cdn.playwright.dev`\n>   - Triggering command: `/usr/local/bin/node /home/REDACTED/work/azure-sdk-for-js/azure-sdk-for-js/common/temp/node_modules/.pnpm/playwright-core@1.52.0/node_modules/playwright-core/lib/server/registry/oopDownloadBrowserMain.js ` (dns block)\n> - `playwright.download.prss.microsoft.com`\n>   - Triggering command: `/usr/local/bin/node /home/REDACTED/work/azure-sdk-for-js/azure-sdk-for-js/common/temp/node_modules/.pnpm/playwright-core@1.52.0/node_modules/playwright-core/lib/server/registry/oopDownloadBrowserMain.js ` (dns block)\n>\n> If you need me to access, download, or install something from one of these locations, you can either:\n>\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\n>\n> </details>\n\n\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-05-21T19:14:06Z",
         "2025-05-27T17:28:10Z",
         "2025-05-27T17:28:10Z",
         "108311273",
         "https://api.github.com/repos/Azure/azure-sdk-for-js",
         "https://github.com/Azure/azure-sdk-for-js/pull/34496",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "14",
         "3198732250",
         "16551",
         "Rewrite dev/preview_docs.py in JavaScript to simplify preview-docs workflow",
         "This PR rewrites the `dev/preview_docs.py` Python script in JavaScript to simplify the preview-docs workflow and eliminate unnecessary dependencies.\n\n## Problem\n\nThe current `preview-docs.yml` workflow required both Node.js (for Netlify deployment) and Python (for PR comment management), leading to:\n- Slower CI runs due to Python environment setup\n- Additional dependency management (`pip install requests`)\n- Workflow complexity with multiple language environments\n\n## Solution\n\nReplaced the Python script with a JavaScript implementation that uses the `github-script` action:\n\n### Changes Made\n\n1. **Created `.github/workflows/preview-docs.js`** - JavaScript version with identical functionality\n2. **Updated `.github/workflows/preview-docs.yml`** - Replaced Python script calls with `github-script` actions  \n3. **Removed `dev/preview_docs.py`** - Original Python script no longer needed\n\n### Key Benefits\n\n‚úÖ **Faster CI runs** - Eliminates `setup-python` action  \n‚úÖ **Fewer dependencies** - No more `pip install requests`  \n‚úÖ **Simpler workflow** - Uses built-in GitHub API access  \n‚úÖ **Consistency** - Follows existing JavaScript patterns in the repository  \n‚úÖ **100% compatibility** - Maintains same comment templates and behavior  \n\n### Technical Details\n\nThe JavaScript implementation preserves all original functionality:\n- Same `<!-- documentation preview -->` marker system\n- Handles both \"completed\" and \"failed\" stages\n- Creates/updates PR comments with identical templates\n- Uses the same GitHub API endpoints and error handling\n\n### Before/After Comparison\n\n**Before:**\n```yaml\n- uses: ./.github/actions/setup-python\n- name: Install dependencies\n  run: pip install requests\n- name: Create preview link\n  run: |\n    python dev/preview_docs.py \\\n      --commit-sha ${{ github.event.workflow_run.head_sha }} \\\n      --pull-number $PR_NUMBER \\\n      # ... other args\n```\n\n**After:**\n```yaml\n- name: Create preview link\n  uses: actions/github-script@60a0d83039c74a4aee543508d2ffcb1c3799cdea\n  env:\n    COMMIT_SHA: ${{ github.event.workflow_run.head_sha }}\n    PULL_NUMBER: ${{ github.event.workflow_run.pull_requests[0].number }}\n    # ... other env vars\n  with:\n    script: |\n      const script = require(`${process.env.GITHUB_WORKSPACE}/.github/workflows/preview-docs.js`);\n      await script({ context, github, env: process.env });\n```\n\nThis addresses the TODO comment in the original Python script:\n```python\n# TODO: rewrite this in JavaScript so we don't have to setup both node (to deploy to netlify)\n# and python (to upsert pr comments with this script)\n```\n\nFixes #16550.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí¨ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-03T09:36:27Z",
         "2025-07-03T23:42:18Z",
         "2025-07-03T23:42:18Z",
         "136202695",
         "https://api.github.com/repos/mlflow/mlflow",
         "https://github.com/mlflow/mlflow/pull/16551",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "15",
         "3154652967",
         "49459",
         "Make GenerateDepsFile and GenerateRuntimeConfigurationFiles tasks internally-incremental",
         "The `GenerateDepsFile` and `GenerateRuntimeConfigurationFiles` tasks were always writing new output files, even when the content was identical to existing files. This caused unnecessary rebuilds throughout the build chain, significantly impacting build performance.\n\n## Changes Made\n\n**GenerateDepsFile.cs:**\n- Modified `WriteDepsFile()` method to generate content in memory first\n- Added XxHash64-based comparison with existing file content\n- Only writes the file when content actually differs\n- Preserves all existing validation logic\n\n**GenerateRuntimeConfigurationFiles.cs:**\n- Modified `WriteToJsonFile()` method to use the same incremental approach\n- Generates JSON content in memory before comparing with existing file\n- Uses XxHash64 for fast content comparison\n\n## Implementation Details\n\n- Uses `System.IO.Hashing.XxHash64` for efficient content comparison (package already referenced)\n- Generates output content in memory to compare against existing files\n- Maintains identical output format and all existing functionality\n- Handles edge cases: non-existent files, empty content, large files\n\n## Testing\n\nAdded comprehensive unit tests that verify:\n- Files are not rewritten when content is unchanged (timestamp preservation)\n- Files are properly updated when content changes\n- First-time file creation works correctly\n\n## Performance Impact\n\nThis change eliminates unnecessary file writes that were causing cascading rebuilds. Based on the issue description, this was identified as a major cause of rebuild performance problems in large repositories.\n\n## Example Behavior\n\n**Before:** Task always writes file, causing downstream rebuilds\n```\nGenerateDepsFile -> writes deps.json (even if identical) -> triggers dependent tasks\n```\n\n**After:** Task only writes when content changes\n```\nGenerateDepsFile -> compares content -> skips write if identical -> no unnecessary rebuilds\n```\n\nFixes #49349.\n\n> [!WARNING]\n>\n> <details>\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\n>\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\n>\n> - `7tjvsblobprodcus341.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `c78vsblobprodcus322.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `d0svsblobprodcus381.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `jd4vsblobprodcus366.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `l49vsblobprodcus358.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `lylvsblobprodcus31.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `/home/REDACTED/work/sdk/sdk/.dotnet/dotnet msbuild /m /nologo /clp:Summary /v:minimal /nr:true /warnaserror /p:TreatWarningsAsErrors=true /p:ContinuousIntegrationBuild=false /home/REDACTED/work/sdk/sdk/artifacts/toolset/restore.proj /t:__WriteToolsetLocation /clp:ErrorsOnly;NoSummary /p:__ToolsetLocationOutputFile=/home/REDACTED/work/sdk/sdk/artifacts/toolset/10.0.0-beta.25316.103.txt ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `uy6vsblobprodcus34.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n> - `vb4vsblobprodcus33.vsblob.vsassets.io`\n>   - Triggering command: `dotnet test src/Tasks/Microsoft.NET.Build.Tasks.UnitTests/Microsoft.NET.Build.Tasks.UnitTests.csproj --filter ItDoesNotOverwriteFileWithSameContent --no-build --verbosity normal ` (dns block)\n>   - Triggering command: `dotnet build src/Tasks/Microsoft.NET.Build.Tasks/Microsoft.NET.Build.Tasks.csproj --verbosity minimal --no-restore ` (dns block)\n>\n> If you need me to access, download, or install something from one of these locations, you can either:\n>\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\n>\n> </details>\n\n\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-06-17T20:14:14Z",
         "2025-06-27T00:02:00Z",
         "2025-06-27T00:02:00Z",
         "63984307",
         "https://api.github.com/repos/dotnet/sdk",
         "https://github.com/dotnet/sdk/pull/49459",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "16",
         "3236198682",
         "3430",
         "Improve docs asset caching and lint",
         "## Summary\n- exclude Insight browser tests from ESLint\n- cache browser assets for docs jobs and download if missing\n- build sandbox image in docs-build job\n\n## Testing\n- `pre-commit run --files .github/workflows/ci.yml .pre-commit-config.yaml`\n- `pytest -k smoke -q`\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6877b262fc2c833398e3e15d653e6495",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-16T14:25:42Z",
         "2025-07-16T14:26:03Z",
         "2025-07-16T14:26:03Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3430",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "17",
         "3226716187",
         "3305",
         "Fix Node cache paths",
         "## Summary\n- cache Node dependencies properly in build-and-test and size-check workflows\n\n## Testing\n- `pre-commit run --files .github/workflows/build-and-test.yml .github/workflows/size-check.yml .github/workflows/ci.yml .github/workflows/docs.yml`\n- `python scripts/check_python_deps.py`\n- `python check_env.py --auto-install`\n- `pytest tests/test_ping_agent.py tests/test_af_requests.py --cov --cov-report=xml`\n\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6873f7562e188333badc4c4205818047",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-13T18:23:33Z",
         "2025-07-13T18:23:43Z",
         "2025-07-13T18:23:43Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3305",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "18",
         "3265755131",
         "3785",
         "[alpha_factory] improve test cache paths",
         "## Summary\n- update `cache-dependency-path` for the tests job\n\n## Testing\n- `pre-commit run --files .github/workflows/ci.yml`\n- `pytest -q` *(fails: test suite failures)*\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6884e5cc4c1c8333939d23673c3dd6e2",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-26T14:38:04Z",
         "2025-07-26T14:38:32Z",
         "2025-07-26T14:38:32Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3785",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "19",
         "3127377495",
         "558",
         "üë∑ Enable Docker BuildKit caching",
         "## Summary\n- enable Docker Buildx cache via GitHub Actions\n- revert Dockerfile cache mounts\n- document the workflow improvement in a changeset\n\n## Testing\n- `pnpm lint`\n- `pnpm test:unit` *(fails: fetch failed)*\n\n------\nhttps://chatgpt.com/codex/tasks/task_b_684487ed13888323959b7285586b85b0",
         "OpenAI_Codex",
         "5880908",
         "wei",
         "closed",
         "2025-06-07T18:55:16Z",
         "2025-06-07T19:01:32Z",
         "2025-06-07T19:01:32Z",
         "297803332",
         "https://api.github.com/repos/wei/socialify",
         "https://github.com/wei/socialify/pull/558",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "20",
         "3207425781",
         "74",
         "Optimize CI workflow with Cargo.lock-based caching for faster builds",
         "## üöÄ Problem\n\nThe CI workflow was not utilizing optimal caching strategies, leading to:\n- Redundant dependency downloads across jobs\n- Repeated compilation of unchanged code\n- Longer build times due to lack of cache sharing between jobs\n\n## üîß Solution\n\nAdded intelligent caching to the CI workflow with the following optimizations:\n\n### 1. Cache Key Based on Cargo.lock Hash\n```yaml\n- uses: ./.github/actions/setup\n  with:\n    cache-shared-key: rustfs-ci-${{ hashFiles('**/Cargo.lock') }}\n```\n\n### 2. Consistent Cache Sharing\nBoth `develop` and `s3s-e2e` jobs now use the same cache key pattern, enabling:\n- Shared dependency cache between jobs\n- Shared compilation artifacts\n- Reduced redundant work\n\n### 3. Dependency-Based Cache Invalidation\nCache is automatically invalidated only when:\n- Dependencies change (Cargo.lock modified)\n- New commits on main branch\n\n## üìä Performance Impact\n\n**Build Time Comparison:**\n- **Cold build** (no cache): ~3m 42s\n- **Warm build** (with cache): ~0.5s\n- **Improvement**: ~99.8% reduction in cached build time\n\n## üîç Technical Details\n\nThe optimization leverages the existing `Swatinem/rust-cache@v2` action which automatically caches:\n- `~/.cargo/registry` (downloaded dependencies)\n- `~/.cargo/git` (git dependencies)\n- `target/` directory (compiled artifacts)\n\n### Before:\n```yaml\n- uses: ./.github/actions/setup\n  # No cache sharing between jobs\n```\n\n### After:\n```yaml\n- uses: ./.github/actions/setup\n  with:\n    cache-shared-key: rustfs-ci-${{ hashFiles('**/Cargo.lock') }}\n```\n\n## ‚úÖ Validation\n\n- [x] YAML syntax validation passed\n- [x] Cache key consistency verified across jobs\n- [x] Deterministic cache key generation confirmed\n- [x] Build time improvements validated locally\n\n## üéØ Expected Benefits\n\n1. **Faster CI builds** - Significant time savings on subsequent builds\n2. **Reduced GitHub Actions minutes** - Lower costs for the project\n3. **Better developer experience** - Faster feedback on PRs\n4. **Efficient cache usage** - Cache only invalidates when dependencies actually change\n\nThis change implements the optimization requirements specified in the issue while maintaining minimal, surgical modifications to the existing workflow.\n\n> [!WARNING]\n>\n> <details>\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\n>\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\n>\n> - `esm.ubuntu.com`\n>   - Triggering command: `/usr/lib/apt/methods/https` (dns block)\n>\n> If you need me to access, download, or install something from one of these locations, you can either:\n>\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\n>\n> </details>\n\n\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nüí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.",
         "Copilot",
         "198982749",
         "Copilot",
         "closed",
         "2025-07-07T03:29:07Z",
         "2025-07-07T03:31:54Z",
         null,
         "722597620",
         "https://api.github.com/repos/rustfs/rustfs",
         "https://github.com/rustfs/rustfs/pull/74",
         "0",
         "1.0",
         "True",
         "CI/CD",
         "Development"
        ],
        [
         "21",
         "3230266030",
         "3361",
         "[alpha_factory] cache web assets on Windows",
         "## Summary\n- cache web assets on the Windows smoke job\n\n## Testing\n- `pre-commit run --files .github/workflows/ci.yml`\n- `python scripts/check_python_deps.py`\n- `python check_env.py --auto-install`\n- `pytest tests/test_ping_agent.py tests/test_af_requests.py --cov --cov-report=xml`\n- `pytest --cov --cov-report=xml` *(fails: 84 failed, 257 passed, 58 skipped, 5 errors)*\n\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_68758c38fde883339bcf7d9327b3e2ae",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-14T23:12:48Z",
         "2025-07-14T23:12:58Z",
         "2025-07-14T23:12:58Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3361",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "22",
         "3216660550",
         "3147",
         "ci: cache docs sandbox build",
         "## Summary\n- avoid repeated installs by installing docs deps first\n- cache sandbox Docker build layers with buildx\n\n## Testing\n- `pre-commit run --files .github/workflows/docs.yml`\n- `python scripts/check_python_deps.py`\n- `pytest tests/test_ping_agent.py tests/test_af_requests.py -q`\n\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_686ea4e4659083339dbe0f6e8b68c662",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-09T17:33:21Z",
         "2025-07-09T17:33:30Z",
         "2025-07-09T17:33:30Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3147",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "23",
         "3205530993",
         "2996",
         "[alpha_factory] enable caching in docs workflow",
         "## Summary\n- reuse pip and npm caches in docs workflow\n\n## Testing\n- `python scripts/check_python_deps.py`\n- `python check_env.py --auto-install`\n- `pytest -q` *(fails: 29 errors during collection)*\n- `pre-commit run --files .github/workflows/docs.yml`\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_68698693ac188333b971a3b68821ddc9",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-05T20:15:39Z",
         "2025-07-05T20:15:57Z",
         "2025-07-05T20:15:57Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/2996",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "24",
         "3226740556",
         "3307",
         "Ensure ci.yml caches node deps correctly",
         "## Summary\n- document that ci.yml caches Node dependencies properly\n\n## Testing\n- `pre-commit run --files docs/CHANGELOG.md`\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6873fd9168608333ba696d0c2db93b0f",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-13T18:55:15Z",
         "2025-07-13T18:55:25Z",
         "2025-07-13T18:55:25Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3307",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "25",
         "3226639901",
         "3298",
         "[alpha_factory] streamline npm caching",
         "## Summary\n- use `setup-node` caching in Windows smoke job\n\n## Testing\n- `python scripts/check_python_deps.py`\n- `python check_env.py --auto-install`\n- `pytest --cov --cov-report=xml` *(failed: KeyboardInterrupt)*\n- `pre-commit run --files .github/workflows/ci.yml` *(failed: KeyboardInterrupt)*\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6873dd73c27c833397fec901347c0cdd",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-13T16:32:44Z",
         "2025-07-13T16:32:53Z",
         "2025-07-13T16:32:53Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3298",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "26",
         "3217792013",
         "3173",
         "[alpha_factory] cache pip & npm in size workflow",
         "## Summary\n- cache Python and Node dependencies in size-check workflow\n- explain new cache in README\n- note cache update in changelog\n\n## Testing\n- `pre-commit run --files .github/workflows/size-check.yml README.md docs/CHANGELOG.md`\n- `pytest -q tests/test_checksum.py` *(fails: ImportError: sentence-transformers missing)*\n\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_686f35f138608333a292795c7ed33d47",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-10T03:57:46Z",
         "2025-07-10T03:57:55Z",
         "2025-07-10T03:57:55Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3173",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "27",
         "3124462300",
         "13297",
         "Cricleci: establish babel cache",
         "inspired by https://www.charpeni.com/blog/speeding-up-eslint-even-on-ci",
         "OpenAI_Codex",
         "1683175",
         "patmmccann",
         "closed",
         "2025-06-06T11:08:50Z",
         "2025-06-06T11:11:51Z",
         null,
         "39321023",
         "https://api.github.com/repos/prebid/Prebid.js",
         "https://github.com/prebid/Prebid.js/pull/13297",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "28",
         "3239729604",
         "3469",
         "ci: cache node setup in lint job",
         "## Summary\n- update lint job to install Node.js with caching before using pre-commit\n\n## Testing\n- `pre-commit run --files .github/workflows/ci.yml` *(failed: KeyboardInterrupt during environment initialization)*\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_687900d5e2388333b4cc4e51a8c243ab",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-17T14:05:43Z",
         "2025-07-17T14:06:09Z",
         "2025-07-17T14:06:09Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3469",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "29",
         "3205789456",
         "3002",
         "[alpha_factory] add restore-keys to docs asset cache",
         "## Summary\n- allow cache fallback in docs workflow by adding `restore-keys`\n\n## Testing\n- `pre-commit run --files .github/workflows/docs.yml`\n- `python scripts/check_python_deps.py`\n- `python check_env.py --auto-install`\n- `pytest -q` *(fails: ImportError: cannot import name 'research_agent')*\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6869b2ac296c8333b3a30c40b02b045d",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-05T23:24:40Z",
         "2025-07-05T23:24:49Z",
         "2025-07-05T23:24:49Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3002",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "30",
         "3124244377",
         "13295",
         "Codex/implement eslint caching strategy on ci",
         "<!--\r\nThank you for your pull request! \r\n\r\nPlease title your pull request like this: 'Module: Change', eg 'Fraggles Bid Adapter: support fragglerock'\r\n\r\nPlease make sure this PR is scoped to one change or you may be asked to resubmit. \r\n \r\nPlease make sure any added or changed code includes tests with greater than 80% code coverage. \r\n\r\nSee https://github.com/prebid/Prebid.js/blob/master/CONTRIBUTING.md#testing-prebidjs for documentation on testing Prebid.js.\r\n\r\nFor any user facing change, submit a link to a PR on the docs repo at https://github.com/prebid/prebid.github.io/\r\n-->\r\n\r\n## Type of change\r\n<!-- Remove items that don't apply and/or select an item by changing [ ] to [x] -->\r\n- [ ] Bugfix\r\n- [ ] Feature\r\n- [ ] New bidder adapter  <!--  IMPORTANT: also submit your bidder parameter documentation as noted in https://docs.prebid.org/dev-docs/bidder-adaptor.html#submitting-your-adapter -->\r\n- [ ] Updated bidder adapter  <!--  IMPORTANT: (1) consider whether you need to upgrade your bidder parameter documentation in https://github.com/prebid/prebid.github.io/tree/master/dev-docs/bidders and (2) if you have a Prebid Server adapter, please consider whether that should be updated as well. --> \r\n- [ ] Code style update (formatting, local variables)\r\n- [ ] Refactoring (no functional changes, no api changes)\r\n- [ ] Build related changes\r\n- [ ] CI related changes\r\n\r\n- [ ] Does this change affect user-facing APIs or examples documented on http://prebid.org?\r\n- [ ] Other\r\n\r\n## Description of change\r\n<!-- Describe the change proposed in this pull request -->\r\n\r\n<!-- For new bidder adapters, please provide the following\r\n- contact email of the adapter‚Äôs maintainer\r\n- test parameters for validating bids:\r\n```\r\n{\r\n  bidder: '<bidder name>',\r\n  params: {\r\n    // ...\r\n  }\r\n}\r\n```\r\n\r\nBe sure to test the integration with your adserver using the [Hello World](https://github.com/prebid/Prebid.js/blob/master/integrationExamples/gpt/hello_world.html) sample page. -->\r\n\r\n\r\n## Other information\r\n<!-- References to related PR or issue #s, @mentions of the person or team responsible for reviewing changes, etc. -->\r\n",
         "OpenAI_Codex",
         "1683175",
         "patmmccann",
         "closed",
         "2025-06-06T09:44:20Z",
         "2025-06-06T09:44:55Z",
         null,
         "39321023",
         "https://api.github.com/repos/prebid/Prebid.js",
         "https://github.com/prebid/Prebid.js/pull/13295",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "31",
         "3218881690",
         "3176",
         "[alpha_factory] enhance browser size workflow caches",
         "## Summary\n- reuse built-in pip cache via `actions/setup-python`\n- cache npm dependencies with `actions/setup-node`\n- mention updated caching approach in README\n- document workflow improvement in CHANGELOG\n\n## Testing\n- `pre-commit run --files .github/workflows/size-check.yml README.md docs/CHANGELOG.md`\n- `pytest tests/test_ping_agent.py tests/test_af_requests.py -q`\n\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_686f7a1b1c208333954f08c34c3a1d10",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-10T11:01:36Z",
         "2025-07-10T11:01:51Z",
         "2025-07-10T11:01:51Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3176",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "32",
         "2839378596",
         "2358",
         "ci: optimize turbo build and test performance",
         "This PR optimizes the CI turbo build and test workflows to improve performance:\n\n1. Added Turbo Remote Caching to both workflows\n2. Added parallelism flags (--concurrency=10 --parallel) to build and test commands\n3. Optimized test task dependencies in turbo.json for better parallel execution\n\nCurrent performance:\n- Build time: ~4m45s\n- Test time: ~11m15s\n\nExpected improvements:\n- Build time should reduce to ~2-3m\n- Test time should reduce to ~6-7m\n\nLink to Devin run: https://app.devin.ai/sessions/0abc5bb855bf43bba64e2e62b057473d\nRequested by: Jayant",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-08T01:19:22Z",
         "2025-02-08T13:53:27Z",
         null,
         "425803244",
         "https://api.github.com/repos/pyth-network/pyth-crosschain",
         "https://github.com/pyth-network/pyth-crosschain/pull/2358",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "33",
         "2840213744",
         "2361",
         "ci: add turbo cache to build and test workflows",
         "# Add turbo cache to build and test workflows\n\nThis PR adds turborepo caching to both build and test workflows to speed up CI tasks, particularly those involving Rust compilation. The changes leverage GitHub's cache service through the turborepo caching action.\n\n## Changes\n- Added `rharkor/caching-for-turbo@v1.5` action to ci-turbo-build.yml\n- Added `rharkor/caching-for-turbo@v1.5` action to ci-turbo-test.yml\n\n## Implementation Details\n- Uses [Caching for Turborepo](https://github.com/marketplace/actions/caching-for-turborepo) GitHub action\n- Automatically sets up required environment variables (TURBO_API, TURBO_TOKEN, TURBO_TEAM)\n- Works alongside existing Rust cache for optimal performance\n- No changes to turbo configuration required\n\n## Testing Strategy\n- CI verification through existing build and test workflows\n- Cache effectiveness can be verified in workflow logs\n\nLink to Devin run: https://app.devin.ai/sessions/36cd61e59f9a4b1a970e8272ac1e29c9\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-08T19:04:24Z",
         "2025-02-08T19:43:09Z",
         "2025-02-08T19:43:09Z",
         "425803244",
         "https://api.github.com/repos/pyth-network/pyth-crosschain",
         "https://github.com/pyth-network/pyth-crosschain/pull/2361",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "34",
         "2926188053",
         "1630",
         "Migrate from chokidar to @parcel/watcher",
         "# Migrate from chokidar to @parcel/watcher\n\nThis PR migrates the file watching implementation from chokidar to @parcel/watcher in the RunManager class. The migration includes:\n\n1. Adding @parcel/watcher as a dependency\n2. Removing chokidar dependency\n3. Updating the RunManager class to use @parcel/watcher's API\n4. Modifying file watching logic to work with directories instead of individual files\n5. Updating event handling to match @parcel/watcher's event format\n\nThe migration provides improved file watching performance through native file system APIs.\n\nLink to Devin run: https://app.devin.ai/sessions/8ac6559d7e844d3a904abb0966dd468f\nRequested by: user\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-03-17T19:44:17Z",
         "2025-03-18T01:59:54Z",
         null,
         "820087727",
         "https://api.github.com/repos/onlook-dev/onlook",
         "https://github.com/onlook-dev/onlook/pull/1630",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "35",
         "2858986352",
         "1419",
         "Refactor: Implement automatic file watching",
         "# Implement automatic file watching\n\nReplace manual addFileToWatcher calls with automatic directory watching using Chokidar's built-in glob patterns. This improves efficiency while maintaining existing functionality.\n\nChanges:\n- Replace manual addFileToWatcher with glob-based watching\n- Add automatic watching of new files\n- Maintain existing file processing functionality\n- Improve performance with native glob patterns\n\nChanges were verified manually by:\n- Creating test files and verifying they're processed\n- Creating test Next.js pages and verifying they're processed\n- Starting project run and verifying all files are processed\n- Checking logs for any file watching errors\n\nLink to Devin run: https://app.devin.ai/sessions/0f7a1e1990d047f787a62ec95cd6779c\nUser: kiet@onlook.dev\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-17T23:50:05Z",
         "2025-02-26T16:48:14Z",
         null,
         "820087727",
         "https://api.github.com/repos/onlook-dev/onlook",
         "https://github.com/onlook-dev/onlook/pull/1419",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "36",
         "2838837697",
         "2351",
         "ci: add cargo caching to pre-commit workflow",
         "# Add Rust caching to pre-commit workflow\n\nThis PR adds caching for Rust dependencies and build artifacts to speed up pre-commit CI checks. The cache:\n- Stores cargo registry, git cache, and target directories\n- Uses a cache key based on:\n  - OS\n  - Cargo.lock files\n  - pre-commit config\n  - Rust toolchain versions\n- Includes fallback cache keys for partial matches\n\nLink to Devin run: https://app.devin.ai/sessions/659feaadc2d24d07854347f7ab39d3d5\nRequested by: Jayant\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-07T18:41:04Z",
         "2025-02-07T19:17:48Z",
         "2025-02-07T19:17:48Z",
         "425803244",
         "https://api.github.com/repos/pyth-network/pyth-crosschain",
         "https://github.com/pyth-network/pyth-crosschain/pull/2351",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "37",
         "2838992710",
         "2355",
         "feat: add rust-cache to all Rust workflows",
         "Added rust-cache to all workflows that run Rust commands to improve CI performance.\n\n- Added Swatinem/rust-cache@v2 to relevant workflows\n- Configured workspace paths for each workflow\n- Maintains existing workflow functionality\n- No changes to build/test logic\n\nLink to Devin run: https://app.devin.ai/sessions/4242c5568ced4883945111df80deb0c2\nRequested by: Jayant",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-07T20:02:06Z",
         "2025-02-07T20:28:54Z",
         "2025-02-07T20:28:54Z",
         "425803244",
         "https://api.github.com/repos/pyth-network/pyth-crosschain",
         "https://github.com/pyth-network/pyth-crosschain/pull/2355",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "38",
         "2759847657",
         "9356",
         "feat(ci): add Graphite CI optimizer to build-test workflow",
         "feat(ci): add Graphite CI optimizer to build-test workflow\n\nThis PR adds the Graphite CI optimizer to our build-test workflow to improve CI efficiency by skipping unnecessary jobs. Implementation follows the official Graphite documentation (https://graphite.dev/docs/stacking-and-ci).\n\nChanges:\n- Add Graphite CI optimizer job with token configuration\n- Update all jobs to depend on optimizer job\n- Add skip conditions based on optimizer output\n- Maintain existing job dependencies while adding optimizer\n\nTesting:\n- [x] Verified YAML syntax is valid\n- [x] Confirmed all jobs properly depend on the optimizer\n- [x] Maintained existing job dependencies\n- [ ] CI checks pending\n\nNote: This change requires the `GRAPHITE_CI_OPTIMIZER_TOKEN` secret to be configured in the repository settings.\n\nLink to Devin run: https://app.devin.ai/sessions/3872f4dc4c3341b899646a90c46c4fe3\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2024-12-26T14:41:32Z",
         "2024-12-27T02:52:17Z",
         null,
         "519859998",
         "https://api.github.com/repos/toeverything/AFFiNE",
         "https://github.com/toeverything/AFFiNE/pull/9356",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "39",
         "2799302285",
         "2556",
         "chore(revert): optimize pnpm cache configuration",
         "edit: reverting most pnpm caching attempts",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-01-20T13:40:18Z",
         "2025-01-20T14:16:06Z",
         "2025-01-20T14:16:06Z",
         "826170402",
         "https://api.github.com/repos/elizaOS/eliza",
         "https://github.com/elizaOS/eliza/pull/2556",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "40",
         "3125906822",
         "13951",
         "Add Turborepo configuration and scripts for improved monorepo management",
         "I implemented Turborepo support to optimize build times across the monorepo. I added `turbo@2.5.4` as a dev dependency and created a `turbo.json` configuration file with optimized task definitions for build, dev, lint, and test commands. In the root `package.json`, I added new turbo-specific scripts (`turbo:dev`, `turbo:build`, `turbo:lint`, `turbo:test`) and set the `packageManager` field to `yarn@1.22.22`. I configured caching by adding `.turbo` to `.gitignore`. The `turbo.json` includes task configurations with proper dependency chains, output caching for `.next/**` and `dist/**` directories, and environment variable handling. The setup enables parallel task execution and intelligent caching across workspaces, significantly improving build performance especially for unchanged code.",
         "Cursor",
         "23610",
         "dcramer",
         "open",
         "2025-06-06T21:29:48Z",
         null,
         null,
         "33837371",
         "https://api.github.com/repos/getsentry/sentry-docs",
         "https://github.com/getsentry/sentry-docs/pull/13951",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "41",
         "3191085425",
         "7585",
         "Improve dev server performance and report",
         "## What does this PR do?\n\nThis PR introduces several optimizations to significantly speed up the Langfuse development server startup time. It provides:\n\n*   A comprehensive guide (`FAST_DEV_SETUP.md`) detailing immediate and recommended steps to improve dev server performance.\n*   An optimized Next.js configuration (`web/next.config.fast-dev.mjs`) specifically tailored for faster development, which disables heavy monitoring tools (Sentry, OpenTelemetry, DataDog) and expensive webpack optimizations in development mode.\n*   A report on benchmark findings (`dev-server-benchmarks.md`) and analysis of performance bottlenecks.\n\nThe primary goal is to reduce the dev server startup time from ~53 seconds to an estimated 30-35 seconds (or even 15-20 seconds with all recommendations applied), improving the developer experience.\n\nFixes # (issue)\n\n## Type of change\n\n- [ ] Bug fix (non-breaking change which fixes an issue)\n- [ ] Chore (refactoring code, technical debt, workflow improvements)\n- [x] New feature (non-breaking change which adds functionality)\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\n- [x] Refactor (does not change functionality, e.g. code style improvements, linting)\n- [x] This change requires a documentation update\n\n## Mandatory Tasks\n\n- [x] Make sure you have self-reviewed the code. A decent size PR without self-review might be rejected.\n\n## Checklist\n\n- [ ] I haven't read the [contributing guide](https://github.com/langfuse/langfuse/blob/main/CONTRIBUTING.md)\n- [ ] My code doesn't follow the style guidelines of this project (`npm run prettier`)\n- [x] I haven't commented my code, particularly in hard-to-understand areas\n- [x] I haven't checked if my PR needs changes to the documentation\n- [ ] I haven't checked if my changes generate no new warnings (`npm run lint`)\n- [ ] I haven't added tests that prove my fix is effective or that my feature works\n- [ ] I haven't checked if new and existing unit tests pass locally with my changes",
         "Cursor",
         "2834609",
         "marcklingen",
         "open",
         "2025-07-01T07:19:19Z",
         null,
         null,
         "642497346",
         "https://api.github.com/repos/langfuse/langfuse",
         "https://github.com/langfuse/langfuse/pull/7585",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "42",
         "3217652543",
         "244",
         "Analyze and optimize code performance",
         "Update Gradle build configuration to enable successful builds and improve build times.\n\nThese changes resolve build failures related to an outdated JVM argument (`MaxPermSize` replaced by `MaxMetaspaceSize`) and a mandatory release signing configuration when the keystore is not present. Additionally, `org.gradle.parallel` is enabled to speed up subsequent builds.",
         "Cursor",
         "5333537",
         "gmathi",
         "closed",
         "2025-07-10T02:21:06Z",
         "2025-07-10T02:21:55Z",
         "2025-07-10T02:21:54Z",
         "92864511",
         "https://api.github.com/repos/gmathi/NovelLibrary",
         "https://github.com/gmathi/NovelLibrary/pull/244",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "43",
         "3226629209",
         "3297",
         "Update Node cache for Docker job",
         "## Summary\n- cache npm dependencies in the Docker build job\n\n## Testing\n- `pre-commit run --files .github/workflows/ci.yml`\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_6873dae03e548333928a5753d030270a",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-13T16:22:50Z",
         "2025-07-13T16:23:03Z",
         "2025-07-13T16:23:03Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/3297",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "44",
         "3096300821",
         "2691",
         "Update docs watcher to process changed files only",
         "NOTE: created with the help of codex\r\n\r\n## TLDR\r\nThis change updates our docs watcher to only process a single markdown file if it has been changed. The same is true for the examples. This should speed up docs development significantly.",
         "OpenAI_Codex",
         "1155738",
         "sh-rp",
         "closed",
         "2025-05-28T07:11:56Z",
         "2025-05-29T22:54:56Z",
         null,
         "452221115",
         "https://api.github.com/repos/dlt-hub/dlt",
         "https://github.com/dlt-hub/dlt/pull/2691",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "45",
         "3203378195",
         "2949",
         "[alpha_factory] cache browser assets",
         "## Summary\n- add asset cache steps to docs workflow\n- document cache usage in hosting instructions\n\n## Testing\n- `python scripts/check_python_deps.py`\n- `python check_env.py --auto-install`\n- `pytest -q` *(fails: 29 errors during collection)*\n- `pre-commit run --files .github/workflows/docs.yml docs/HOSTING_INSTRUCTIONS.md` *(failed: environment setup blocked)*\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_68680fb5b5348333885ea99b4ec2cdda",
         "OpenAI_Codex",
         "24208299",
         "MontrealAI",
         "closed",
         "2025-07-04T17:40:45Z",
         "2025-07-04T17:40:53Z",
         "2025-07-04T17:40:53Z",
         "922805069",
         "https://api.github.com/repos/MontrealAI/AGI-Alpha-Agent-v0",
         "https://github.com/MontrealAI/AGI-Alpha-Agent-v0/pull/2949",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "46",
         "3124534701",
         "13298",
         "Circleci: setup persistent babel cache for tests",
         "persist babel cache between runs",
         "OpenAI_Codex",
         "1683175",
         "patmmccann",
         "closed",
         "2025-06-06T11:43:05Z",
         "2025-06-24T15:27:40Z",
         "2025-06-24T15:27:40Z",
         "39321023",
         "https://api.github.com/repos/prebid/Prebid.js",
         "https://github.com/prebid/Prebid.js/pull/13298",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "47",
         "2840011330",
         "2360",
         "ci: add rust cache to turbo test workflow",
         "# Description\nAdd Rust caching to the turbo test workflow to improve CI performance.\n\nThis PR:\n- Adds Rust caching using Swatinem/rust-cache@v2\n- Follows the same pattern as other Rust workflows in the repository\n- Does not modify the turbo build workflow as it doesn't use Rust\n\nLink to Devin run: https://app.devin.ai/sessions/6e20ec2b71cf44168007a02b34cb18be\nRequested by: Jayant",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-08T13:45:06Z",
         "2025-02-08T15:51:58Z",
         "2025-02-08T15:51:57Z",
         "425803244",
         "https://api.github.com/repos/pyth-network/pyth-crosschain",
         "https://github.com/pyth-network/pyth-crosschain/pull/2360",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "48",
         "2760327496",
         "9362",
         "ci: add graphite ci optimizer and update job dependencies",
         "feat(ci): add graphite ci optimizer and update job dependencies\n\nThis PR adds the Graphite CI optimizer to improve CI efficiency by skipping unnecessary jobs. All workflow jobs have been updated to depend on the optimizer's output.\n\nChanges:\n- Add `optimize_ci` job using graphite-ci-action\n- Update all jobs to depend on `optimize_ci`\n- Add skip conditions based on optimizer output\n- Preserve existing job dependencies while adding optimizer dependency\n- Handle Redis service configurations and command syntax updates\n\nNote: This PR requires the `GRAPHITE_CI_OPTIMIZER_TOKEN` secret to be configured in the repository settings before the optimizer can be used.\n\nTesting:\n- [x] Verified workflow file syntax\n- [x] Updated all job dependencies correctly\n- [x] Maintained existing job configurations\n\nLink to Devin run: https://app.devin.ai/sessions/3872f4dc4c3341b899646a90c46c4fe3\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2024-12-27T03:01:40Z",
         "2024-12-27T04:02:30Z",
         "2024-12-27T04:02:30Z",
         "519859998",
         "https://api.github.com/repos/toeverything/AFFiNE",
         "https://github.com/toeverything/AFFiNE/pull/9362",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ],
        [
         "49",
         "2858841754",
         "2385",
         "chore: add cargo workspaces to rust-cache action",
         "Add all Cargo workspaces to the rust-cache action to improve cache hits.\n\nThis PR adds workspace paths for:\n- target_chains/{ethereum,cosmwasm,fuel,solana}\n- governance/remote_executor\n- lazer\n- pythnet/{message_buffer,stake_caps_parameters}\n\nLink to Devin run: https://app.devin.ai/sessions/9f3a6f18d9b74a86980bcf96f97d0e1d\nRequested by: Jayant\n",
         "Devin",
         "158243242",
         "devin-ai-integration[bot]",
         "closed",
         "2025-02-17T21:40:27Z",
         "2025-02-17T23:14:43Z",
         "2025-02-17T23:14:43Z",
         "425803244",
         "https://api.github.com/repos/pyth-network/pyth-crosschain",
         "https://github.com/pyth-network/pyth-crosschain/pull/2385",
         "0",
         "1.0",
         "False",
         "CI/CD",
         "Development"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 1120
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>agent</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user</th>\n",
       "      <th>state</th>\n",
       "      <th>created_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>merged_at</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2912546402</td>\n",
       "      <td>448</td>\n",
       "      <td>Add GitHub API caching to prevent rate limiting</td>\n",
       "      <td>- Create GitHub API caching script that handle...</td>\n",
       "      <td>Claude_Code</td>\n",
       "      <td>1021104</td>\n",
       "      <td>8enmann</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-03-12T03:51:34Z</td>\n",
       "      <td>2025-05-06T17:50:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>937253475</td>\n",
       "      <td>https://api.github.com/repos/anthropics/claude...</td>\n",
       "      <td>https://github.com/anthropics/claude-code/pull...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>CI/CD</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3216159293</td>\n",
       "      <td>110</td>\n",
       "      <td>Add vcpkg dependency caching to Windows CI wor...</td>\n",
       "      <td>## Overview\\n\\nThis PR implements vcpkg depend...</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>198982749</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-07-09T14:30:39Z</td>\n",
       "      <td>2025-07-09T16:47:00Z</td>\n",
       "      <td>2025-07-09T16:47:00Z</td>\n",
       "      <td>564439013</td>\n",
       "      <td>https://api.github.com/repos/pelicanmapping/rocky</td>\n",
       "      <td>https://github.com/pelicanmapping/rocky/pull/110</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>CI/CD</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3195588879</td>\n",
       "      <td>16531</td>\n",
       "      <td>Remove duplicate yarn eslint step from .circle...</td>\n",
       "      <td>&lt;details&gt;&lt;summary&gt;&amp;#x1F6E0 DevTools &amp;#x1F6E0&lt;/...</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>198982749</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-07-02T11:33:06Z</td>\n",
       "      <td>2025-07-02T12:24:50Z</td>\n",
       "      <td>2025-07-02T12:24:50Z</td>\n",
       "      <td>136202695</td>\n",
       "      <td>https://api.github.com/repos/mlflow/mlflow</td>\n",
       "      <td>https://github.com/mlflow/mlflow/pull/16531</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>CI/CD</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3074681764</td>\n",
       "      <td>13829</td>\n",
       "      <td>Update build documentation with quick build op...</td>\n",
       "      <td>This PR updates the build documentation (`tool...</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>198982749</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>open</td>\n",
       "      <td>2025-05-19T18:25:04Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281765424</td>\n",
       "      <td>https://api.github.com/repos/microsoft/azurelinux</td>\n",
       "      <td>https://github.com/microsoft/azurelinux/pull/1...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>CI/CD</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3159826481</td>\n",
       "      <td>184</td>\n",
       "      <td>[WIP] Support .coshrc compilation</td>\n",
       "      <td>Thanks for assigning this issue to me. I'm sta...</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>198982749</td>\n",
       "      <td>Copilot</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-06-19T10:34:39Z</td>\n",
       "      <td>2025-06-26T11:59:32Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445862991</td>\n",
       "      <td>https://api.github.com/repos/tomhrr/cosh</td>\n",
       "      <td>https://github.com/tomhrr/cosh/pull/184</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>CI/CD</td>\n",
       "      <td>Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>3144466175</td>\n",
       "      <td>4</td>\n",
       "      <td>Implement local storage persistence</td>\n",
       "      <td>A new persistence utility, `src/lib/persistenc...</td>\n",
       "      <td>Cursor</td>\n",
       "      <td>56125930</td>\n",
       "      <td>f1shy-dev</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-06-13T18:49:45Z</td>\n",
       "      <td>2025-06-13T18:49:52Z</td>\n",
       "      <td>2025-06-13T18:49:52Z</td>\n",
       "      <td>998301272</td>\n",
       "      <td>https://api.github.com/repos/intern3-chat/inte...</td>\n",
       "      <td>https://github.com/intern3-chat/intern3-chat/p...</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Chat System</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>3275952470</td>\n",
       "      <td>2777</td>\n",
       "      <td>fix: update schemaDesignTool to directly updat...</td>\n",
       "      <td>## Issue\\n\\n- resolve: Root cause issue where ...</td>\n",
       "      <td>Devin</td>\n",
       "      <td>158243242</td>\n",
       "      <td>devin-ai-integration[bot]</td>\n",
       "      <td>open</td>\n",
       "      <td>2025-07-30T07:15:24Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>839216423</td>\n",
       "      <td>https://api.github.com/repos/liam-hq/liam</td>\n",
       "      <td>https://github.com/liam-hq/liam/pull/2777</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Chat System</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>3074294403</td>\n",
       "      <td>320</td>\n",
       "      <td>Integrate chatAudioIO module</td>\n",
       "      <td># Integrate chatAudioIO module\\n\\nThis PR inte...</td>\n",
       "      <td>Devin</td>\n",
       "      <td>158243242</td>\n",
       "      <td>devin-ai-integration[bot]</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-05-19T15:42:40Z</td>\n",
       "      <td>2025-05-28T14:33:26Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374381865</td>\n",
       "      <td>https://api.github.com/repos/stack-chan/stack-...</td>\n",
       "      <td>https://github.com/stack-chan/stack-chan/pull/320</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Chat System</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>3058809612</td>\n",
       "      <td>1399</td>\n",
       "      <td>Fix: Cache system info to prevent re-fetching ...</td>\n",
       "      <td># Cache System Info to Prevent Re-fetching on ...</td>\n",
       "      <td>Devin</td>\n",
       "      <td>158243242</td>\n",
       "      <td>devin-ai-integration[bot]</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-05-13T05:33:38Z</td>\n",
       "      <td>2025-05-13T07:32:44Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>575321313</td>\n",
       "      <td>https://api.github.com/repos/langbot-app/LangBot</td>\n",
       "      <td>https://github.com/langbot-app/LangBot/pull/1399</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Chat System</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>3152003781</td>\n",
       "      <td>2037</td>\n",
       "      <td>Optimize Chat API/Job schema transfer by remov...</td>\n",
       "      <td># Optimize Chat API/Job schema transfer by rem...</td>\n",
       "      <td>Devin</td>\n",
       "      <td>158243242</td>\n",
       "      <td>devin-ai-integration[bot]</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-06-17T04:17:12Z</td>\n",
       "      <td>2025-06-17T07:08:49Z</td>\n",
       "      <td>2025-06-17T07:08:49Z</td>\n",
       "      <td>839216423</td>\n",
       "      <td>https://api.github.com/repos/liam-hq/liam</td>\n",
       "      <td>https://github.com/liam-hq/liam/pull/2037</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Chat System</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1120 rows √ó 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  number                                              title  \\\n",
       "0     2912546402     448    Add GitHub API caching to prevent rate limiting   \n",
       "1     3216159293     110  Add vcpkg dependency caching to Windows CI wor...   \n",
       "2     3195588879   16531  Remove duplicate yarn eslint step from .circle...   \n",
       "3     3074681764   13829  Update build documentation with quick build op...   \n",
       "4     3159826481     184                  [WIP] Support .coshrc compilation   \n",
       "...          ...     ...                                                ...   \n",
       "1115  3144466175       4                Implement local storage persistence   \n",
       "1116  3275952470    2777  fix: update schemaDesignTool to directly updat...   \n",
       "1117  3074294403     320                       Integrate chatAudioIO module   \n",
       "1118  3058809612    1399  Fix: Cache system info to prevent re-fetching ...   \n",
       "1119  3152003781    2037  Optimize Chat API/Job schema transfer by remov...   \n",
       "\n",
       "                                                   body        agent  \\\n",
       "0     - Create GitHub API caching script that handle...  Claude_Code   \n",
       "1     ## Overview\\n\\nThis PR implements vcpkg depend...      Copilot   \n",
       "2     <details><summary>&#x1F6E0 DevTools &#x1F6E0</...      Copilot   \n",
       "3     This PR updates the build documentation (`tool...      Copilot   \n",
       "4     Thanks for assigning this issue to me. I'm sta...      Copilot   \n",
       "...                                                 ...          ...   \n",
       "1115  A new persistence utility, `src/lib/persistenc...       Cursor   \n",
       "1116  ## Issue\\n\\n- resolve: Root cause issue where ...        Devin   \n",
       "1117  # Integrate chatAudioIO module\\n\\nThis PR inte...        Devin   \n",
       "1118  # Cache System Info to Prevent Re-fetching on ...        Devin   \n",
       "1119  # Optimize Chat API/Job schema transfer by rem...        Devin   \n",
       "\n",
       "        user_id                       user   state            created_at  \\\n",
       "0       1021104                    8enmann  closed  2025-03-12T03:51:34Z   \n",
       "1     198982749                    Copilot  closed  2025-07-09T14:30:39Z   \n",
       "2     198982749                    Copilot  closed  2025-07-02T11:33:06Z   \n",
       "3     198982749                    Copilot    open  2025-05-19T18:25:04Z   \n",
       "4     198982749                    Copilot  closed  2025-06-19T10:34:39Z   \n",
       "...         ...                        ...     ...                   ...   \n",
       "1115   56125930                  f1shy-dev  closed  2025-06-13T18:49:45Z   \n",
       "1116  158243242  devin-ai-integration[bot]    open  2025-07-30T07:15:24Z   \n",
       "1117  158243242  devin-ai-integration[bot]  closed  2025-05-19T15:42:40Z   \n",
       "1118  158243242  devin-ai-integration[bot]  closed  2025-05-13T05:33:38Z   \n",
       "1119  158243242  devin-ai-integration[bot]  closed  2025-06-17T04:17:12Z   \n",
       "\n",
       "                 closed_at             merged_at    repo_id  \\\n",
       "0     2025-05-06T17:50:00Z                   NaN  937253475   \n",
       "1     2025-07-09T16:47:00Z  2025-07-09T16:47:00Z  564439013   \n",
       "2     2025-07-02T12:24:50Z  2025-07-02T12:24:50Z  136202695   \n",
       "3                      NaN                   NaN  281765424   \n",
       "4     2025-06-26T11:59:32Z                   NaN  445862991   \n",
       "...                    ...                   ...        ...   \n",
       "1115  2025-06-13T18:49:52Z  2025-06-13T18:49:52Z  998301272   \n",
       "1116                   NaN                   NaN  839216423   \n",
       "1117  2025-05-28T14:33:26Z                   NaN  374381865   \n",
       "1118  2025-05-13T07:32:44Z                   NaN  575321313   \n",
       "1119  2025-06-17T07:08:49Z  2025-06-17T07:08:49Z  839216423   \n",
       "\n",
       "                                               repo_url  \\\n",
       "0     https://api.github.com/repos/anthropics/claude...   \n",
       "1     https://api.github.com/repos/pelicanmapping/rocky   \n",
       "2            https://api.github.com/repos/mlflow/mlflow   \n",
       "3     https://api.github.com/repos/microsoft/azurelinux   \n",
       "4              https://api.github.com/repos/tomhrr/cosh   \n",
       "...                                                 ...   \n",
       "1115  https://api.github.com/repos/intern3-chat/inte...   \n",
       "1116          https://api.github.com/repos/liam-hq/liam   \n",
       "1117  https://api.github.com/repos/stack-chan/stack-...   \n",
       "1118   https://api.github.com/repos/langbot-app/LangBot   \n",
       "1119          https://api.github.com/repos/liam-hq/liam   \n",
       "\n",
       "                                               html_url  Topic  Probability  \\\n",
       "0     https://github.com/anthropics/claude-code/pull...      0          1.0   \n",
       "1      https://github.com/pelicanmapping/rocky/pull/110      0          1.0   \n",
       "2           https://github.com/mlflow/mlflow/pull/16531      0          1.0   \n",
       "3     https://github.com/microsoft/azurelinux/pull/1...      0          1.0   \n",
       "4               https://github.com/tomhrr/cosh/pull/184      0          1.0   \n",
       "...                                                 ...    ...          ...   \n",
       "1115  https://github.com/intern3-chat/intern3-chat/p...     48          1.0   \n",
       "1116          https://github.com/liam-hq/liam/pull/2777     48          1.0   \n",
       "1117  https://github.com/stack-chan/stack-chan/pull/320     48          1.0   \n",
       "1118   https://github.com/langbot-app/LangBot/pull/1399     48          1.0   \n",
       "1119          https://github.com/liam-hq/liam/pull/2037     48          1.0   \n",
       "\n",
       "      Representative_document   topic_name     category  \n",
       "0                       False        CI/CD  Development  \n",
       "1                       False        CI/CD  Development  \n",
       "2                       False        CI/CD  Development  \n",
       "3                       False        CI/CD  Development  \n",
       "4                       False        CI/CD  Development  \n",
       "...                       ...          ...          ...  \n",
       "1115                    False  Chat System           AI  \n",
       "1116                     True  Chat System           AI  \n",
       "1117                    False  Chat System           AI  \n",
       "1118                    False  Chat System           AI  \n",
       "1119                     True  Chat System           AI  \n",
       "\n",
       "[1120 rows x 19 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categories_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
